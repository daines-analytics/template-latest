{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Deep Learning Model for [Project Name] Using Keras Version 3\n",
    "### David Lowe\n",
    "### November 1, 2019\n",
    "Template Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery. [https://machinelearningmastery.com/]\n",
    "\n",
    "SUMMARY: [Sample Paragraph - The purpose of this project is to construct a predictive model using various machine learning algorithms and to document the end-to-end steps using a template. The Connectionist Bench dataset is a binary classification situation where we are trying to predict one of the two possible outcomes.]\n",
    "\n",
    "INTRODUCTION: [Sample Paragraph - The data file patterns obtained by bouncing sonar signals off a metal cylinder or a rock at various angles and under various conditions. The transmitted sonar signal is a frequency-modulated chirp, rising in frequency. The data set contains signals obtained from a variety of different aspect angles, spanning 90 degrees for the cylinder and 180 degrees for the rock. Each pattern is a set of 60 numbers in the range 0.0 to 1.0. Each number represents the energy within a particular frequency band, integrated over a certain period of time.]\n",
    "\n",
    "ANALYSIS: [Sample Paragraph - The baseline performance of the model achieved an average accuracy score of 79.48%. Using the same training parameters, the model processed the test dataset with an accuracy of 82.69%, which was even better than results from the training data.]\n",
    "\n",
    "CONCLUSION: [Sample Paragraph - For this dataset, the model built using Keras and TensorFlow achieved a satisfactory result and should be considered for future modeling activities]\n",
    "\n",
    "Dataset Used: [Connectionist Bench (Sonar, Mines vs. Rocks) Data Set]\n",
    "\n",
    "Dataset ML Model: Binary classification with numerical attributes\n",
    "\n",
    "Dataset Reference: [https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+%28Sonar,+Mines+vs.+Rocks%29]\n",
    "\n",
    "One potential source of performance benchmarks: [https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/]\n",
    "\n",
    "Any deep-learning modeling project genrally can be broken down into about six major tasks:\n",
    "0. Prepare Environment\n",
    "1. Load Data\n",
    "2. Define Model\n",
    "3. Fit and Evaluate Model\n",
    "4. Optimize Model\n",
    "5. Finalize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 0. Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random seed numbers for reproducible results\n",
    "seedNum = 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and packages\n",
    "import random\n",
    "random.seed(seedNum)\n",
    "import numpy as np\n",
    "np.random.seed(seedNum)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(seedNum)\n",
    "import pandas as pd\n",
    "import os\n",
    "import smtplib\n",
    "from datetime import datetime\n",
    "from email.message import EmailMessage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a new global `tensorflow` session\n",
    "import keras as K\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin the timer for the script processing\n",
    "startTimeScript = datetime.now()\n",
    "\n",
    "# Set up the flag to stop sending progress emails (setting to True will send status emails!)\n",
    "notifyStatus = False\n",
    "\n",
    "# Set the flag for splitting the dataset\n",
    "splitDataset = True\n",
    "splitPercentage = 0.25\n",
    "\n",
    "# Set various default Keras modeling parameters\n",
    "default_kernel_init = K.initializers.RandomNormal(seed=seedNum)\n",
    "default_loss = 'binary_crossentropy'\n",
    "default_optimizer = 'adam'\n",
    "default_epochs = 100\n",
    "default_batches = 5\n",
    "default_metrics = ['accuracy']\n",
    "\n",
    "# Set the number of folds for cross validation\n",
    "folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the email notification function\n",
    "def email_notify(msg_text):\n",
    "    sender = os.environ.get('MAIL_SENDER')\n",
    "    receiver = os.environ.get('MAIL_RECEIVER')\n",
    "    gateway = os.environ.get('SMTP_GATEWAY')\n",
    "    smtpuser = os.environ.get('SMTP_USERNAME')\n",
    "    password = os.environ.get('SMTP_PASSWORD')\n",
    "    if sender==None or receiver==None or gateway==None or smtpuser==None or password==None:\n",
    "        sys.exit(\"Incomplete email setup info. Script Processing Aborted!!!\")\n",
    "    msg = EmailMessage()\n",
    "    msg.set_content(msg_text)\n",
    "    msg['Subject'] = 'Notification from Keras Binary Classification Script'\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = receiver\n",
    "    server = smtplib.SMTP(gateway, 587)\n",
    "    server.starttls()\n",
    "    server.login(smtpuser, password)\n",
    "    server.send_message(msg)\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 0 Prepare Environment completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 1 Load Data has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02 0.0371 0.0428 ... 0.009 0.0032 'R']\n",
      " [0.0453 0.0523 0.0843 ... 0.0052 0.0044 'R']\n",
      " [0.0262 0.0582 0.1099 ... 0.0095 0.0078 'R']\n",
      " ...\n",
      " [0.0522 0.0437 0.018 ... 0.0077 0.0031 'M']\n",
      " [0.0303 0.0353 0.049 ... 0.0036 0.0048 'M']\n",
      " [0.026 0.0363 0.0136 ... 0.0061 0.0115 'M']]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df_original = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\", header=None)\n",
    "dataset = df_original.values\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_original: (208, 60) | Shape of y_original: (208,)\n"
     ]
    }
   ],
   "source": [
    "# Split the original dataset into input (X) and output (y) variables\n",
    "X_original = dataset[:,0:60].astype(float)\n",
    "y_original = dataset[:,60]\n",
    "print('Shape of X_original:', X_original.shape, '| Shape of y_original:', y_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Encode class values as integers and perform one-hot-encoding\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_original)\n",
    "y_encoded = encoder.transform(y_original)\n",
    "print(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (156, 60) | Shape of y_train: (156,)\n",
      "Shape of X_test: (52, 60) | Shape of y_test: (52,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data further into training and test datasets\n",
    "if (splitDataset):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_original, y_encoded, test_size=splitPercentage, random_state=seedNum)\n",
    "else:\n",
    "    X_train, y_train = X_original, y_encoded\n",
    "    X_test, y_test = X_original, y_encoded\n",
    "print('Shape of X_train:', X_train.shape, '| Shape of y_train:', y_train.shape)\n",
    "print('Shape of X_test:', X_test.shape, '| Shape of y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 1 Load Data completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 2 Define Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras model required for KerasClassifier\n",
    "def create_cv_model():\n",
    "    model = K.models.Sequential()\n",
    "    model.add(Dense(60, input_dim=60, kernel_initializer=default_kernel_init, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=default_kernel_init, activation='sigmoid'))\n",
    "    model.compile(loss=default_loss, optimizer=default_optimizer, metrics=default_metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Keras model\n",
    "cv_model = KerasClassifier(build_fn=create_cv_model, epochs=default_epochs, batch_size=default_batches, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 2 Define Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3. Fit and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 3 Fit and Evaluate Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and evaluate the Keras model using 10-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seedNum)\n",
    "results = cross_val_score(cv_model, X_train, y_train, cv=kfold)\n",
    "print('Generating results using the metrics of', default_metrics)\n",
    "print('All cross-Validate results:', results)\n",
    "print('Baseline results [mean (std)]: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Pb01NDTS44-"
   },
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 3 Fit and Evaluate Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4. Optimize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 4 Optimize Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras model required for KerasClassifier\n",
    "def create_grid_model(optimizer, kernel_init):\n",
    "    model = K.models.Sequential()\n",
    "    model.add(Dense(60, input_dim=60, kernel_initializer=kernel_init, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=kernel_init, activation='sigmoid'))\n",
    "    model.compile(loss=default_loss, optimizer=optimizer, metrics=default_metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create model\n",
    "# grid_model = KerasClassifier(build_fn=create_grid_model, verbose=0)\n",
    "\n",
    "# # Perform grid search using different epochs, batch sizes, and optimizers\n",
    "# optimizer_grid = ['rmsprop', 'adam']\n",
    "# init_grid = ['Constant', 'RandomNormal', 'RandomUniform']\n",
    "# epoch_grid = [100, 150, 200]\n",
    "# batch_grid = [5, 10, 15]\n",
    "# param_grid = dict(optimizer=optimizer_grid, kernel_init=init_grid, epochs=epoch_grid, batch_size=batch_grid)\n",
    "# # param_grid = dict(optimizer=optimizer_grid, epochs=epoch_grid, batch_size=batch_grid)\n",
    "# grid = GridSearchCV(estimator=grid_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# # summarize results\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "# \tprint(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimizer = 'rmsprop'\n",
    "best_kernel_init = 'RandomNormal'\n",
    "best_epoch = 150\n",
    "best_batch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final model for evaluating the test dataset\n",
    "final_model = create_grid_model(best_optimizer, best_kernel_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "156/156 [==============================] - 8s 48ms/step - loss: 0.6895 - acc: 0.5256\n",
      "Epoch 2/150\n",
      "156/156 [==============================] - 0s 603us/step - loss: 0.6819 - acc: 0.5449\n",
      "Epoch 3/150\n",
      "156/156 [==============================] - 0s 514us/step - loss: 0.6763 - acc: 0.5449\n",
      "Epoch 4/150\n",
      "156/156 [==============================] - 0s 504us/step - loss: 0.6709 - acc: 0.5449\n",
      "Epoch 5/150\n",
      "156/156 [==============================] - 0s 538us/step - loss: 0.6647 - acc: 0.5449\n",
      "Epoch 6/150\n",
      "156/156 [==============================] - 0s 508us/step - loss: 0.6570 - acc: 0.5769\n",
      "Epoch 7/150\n",
      "156/156 [==============================] - 0s 503us/step - loss: 0.6499 - acc: 0.6026\n",
      "Epoch 8/150\n",
      "156/156 [==============================] - 0s 507us/step - loss: 0.6413 - acc: 0.6474\n",
      "Epoch 9/150\n",
      "156/156 [==============================] - 0s 516us/step - loss: 0.6325 - acc: 0.6731\n",
      "Epoch 10/150\n",
      "156/156 [==============================] - 0s 519us/step - loss: 0.6223 - acc: 0.6731\n",
      "Epoch 11/150\n",
      "156/156 [==============================] - 0s 496us/step - loss: 0.6134 - acc: 0.6987\n",
      "Epoch 12/150\n",
      "156/156 [==============================] - 0s 506us/step - loss: 0.6011 - acc: 0.6987\n",
      "Epoch 13/150\n",
      "156/156 [==============================] - 0s 576us/step - loss: 0.5952 - acc: 0.7244\n",
      "Epoch 14/150\n",
      "156/156 [==============================] - 0s 501us/step - loss: 0.5834 - acc: 0.7628\n",
      "Epoch 15/150\n",
      "156/156 [==============================] - 0s 515us/step - loss: 0.5716 - acc: 0.7564\n",
      "Epoch 16/150\n",
      "156/156 [==============================] - 0s 552us/step - loss: 0.5656 - acc: 0.7628\n",
      "Epoch 17/150\n",
      "156/156 [==============================] - 0s 562us/step - loss: 0.5529 - acc: 0.7821\n",
      "Epoch 18/150\n",
      "156/156 [==============================] - 0s 597us/step - loss: 0.5469 - acc: 0.7372\n",
      "Epoch 19/150\n",
      "156/156 [==============================] - 0s 496us/step - loss: 0.5386 - acc: 0.7756\n",
      "Epoch 20/150\n",
      "156/156 [==============================] - 0s 538us/step - loss: 0.5305 - acc: 0.7692\n",
      "Epoch 21/150\n",
      "156/156 [==============================] - 0s 528us/step - loss: 0.5217 - acc: 0.7949\n",
      "Epoch 22/150\n",
      "156/156 [==============================] - 0s 515us/step - loss: 0.5162 - acc: 0.8013\n",
      "Epoch 23/150\n",
      "156/156 [==============================] - 0s 510us/step - loss: 0.5095 - acc: 0.7821\n",
      "Epoch 24/150\n",
      "156/156 [==============================] - 0s 527us/step - loss: 0.4992 - acc: 0.7949\n",
      "Epoch 25/150\n",
      "156/156 [==============================] - 0s 496us/step - loss: 0.4924 - acc: 0.8205\n",
      "Epoch 26/150\n",
      "156/156 [==============================] - 0s 532us/step - loss: 0.4823 - acc: 0.8333\n",
      "Epoch 27/150\n",
      "156/156 [==============================] - 0s 503us/step - loss: 0.4823 - acc: 0.8333\n",
      "Epoch 28/150\n",
      "156/156 [==============================] - 0s 502us/step - loss: 0.4740 - acc: 0.8141\n",
      "Epoch 29/150\n",
      "156/156 [==============================] - 0s 507us/step - loss: 0.4691 - acc: 0.8141\n",
      "Epoch 30/150\n",
      "156/156 [==============================] - 0s 504us/step - loss: 0.4680 - acc: 0.8013\n",
      "Epoch 31/150\n",
      "156/156 [==============================] - 0s 513us/step - loss: 0.4626 - acc: 0.8205\n",
      "Epoch 32/150\n",
      "156/156 [==============================] - 0s 500us/step - loss: 0.4558 - acc: 0.8333\n",
      "Epoch 33/150\n",
      "156/156 [==============================] - 0s 490us/step - loss: 0.4532 - acc: 0.8397\n",
      "Epoch 34/150\n",
      "156/156 [==============================] - 0s 527us/step - loss: 0.4488 - acc: 0.8269\n",
      "Epoch 35/150\n",
      "156/156 [==============================] - 0s 494us/step - loss: 0.4482 - acc: 0.8269\n",
      "Epoch 36/150\n",
      "156/156 [==============================] - 0s 498us/step - loss: 0.4455 - acc: 0.8141\n",
      "Epoch 37/150\n",
      "156/156 [==============================] - 0s 513us/step - loss: 0.4391 - acc: 0.8269\n",
      "Epoch 38/150\n",
      "156/156 [==============================] - 0s 501us/step - loss: 0.4335 - acc: 0.8141\n",
      "Epoch 39/150\n",
      "156/156 [==============================] - 0s 501us/step - loss: 0.4361 - acc: 0.8205\n",
      "Epoch 40/150\n",
      "156/156 [==============================] - 0s 485us/step - loss: 0.4301 - acc: 0.8269\n",
      "Epoch 41/150\n",
      "156/156 [==============================] - 0s 488us/step - loss: 0.4278 - acc: 0.8269\n",
      "Epoch 42/150\n",
      "156/156 [==============================] - 0s 496us/step - loss: 0.4214 - acc: 0.8526\n",
      "Epoch 43/150\n",
      "156/156 [==============================] - 0s 494us/step - loss: 0.4240 - acc: 0.8205\n",
      "Epoch 44/150\n",
      "156/156 [==============================] - 0s 491us/step - loss: 0.4201 - acc: 0.8269\n",
      "Epoch 45/150\n",
      "156/156 [==============================] - 0s 490us/step - loss: 0.4165 - acc: 0.8333\n",
      "Epoch 46/150\n",
      "156/156 [==============================] - 0s 492us/step - loss: 0.4159 - acc: 0.8397\n",
      "Epoch 47/150\n",
      "156/156 [==============================] - 0s 505us/step - loss: 0.4156 - acc: 0.8397\n",
      "Epoch 48/150\n",
      "156/156 [==============================] - 0s 515us/step - loss: 0.4100 - acc: 0.8269\n",
      "Epoch 49/150\n",
      "156/156 [==============================] - 0s 493us/step - loss: 0.4194 - acc: 0.8397\n",
      "Epoch 50/150\n",
      "156/156 [==============================] - 0s 513us/step - loss: 0.4045 - acc: 0.8462\n",
      "Epoch 51/150\n",
      "156/156 [==============================] - 0s 582us/step - loss: 0.4099 - acc: 0.8269\n",
      "Epoch 52/150\n",
      "156/156 [==============================] - 0s 501us/step - loss: 0.4012 - acc: 0.8333\n",
      "Epoch 53/150\n",
      "156/156 [==============================] - 0s 515us/step - loss: 0.4033 - acc: 0.8077\n",
      "Epoch 54/150\n",
      "156/156 [==============================] - 0s 526us/step - loss: 0.4052 - acc: 0.8333\n",
      "Epoch 55/150\n",
      "156/156 [==============================] - 0s 577us/step - loss: 0.4018 - acc: 0.8269\n",
      "Epoch 56/150\n",
      "156/156 [==============================] - 0s 483us/step - loss: 0.3987 - acc: 0.8269\n",
      "Epoch 57/150\n",
      "156/156 [==============================] - 0s 495us/step - loss: 0.3972 - acc: 0.8333\n",
      "Epoch 58/150\n",
      "156/156 [==============================] - 0s 505us/step - loss: 0.3940 - acc: 0.8397\n",
      "Epoch 59/150\n",
      "156/156 [==============================] - 0s 531us/step - loss: 0.3997 - acc: 0.8141\n",
      "Epoch 60/150\n",
      "156/156 [==============================] - 0s 520us/step - loss: 0.3927 - acc: 0.8269\n",
      "Epoch 61/150\n",
      "156/156 [==============================] - 0s 511us/step - loss: 0.3926 - acc: 0.8333\n",
      "Epoch 62/150\n",
      "156/156 [==============================] - 0s 512us/step - loss: 0.3898 - acc: 0.8141\n",
      "Epoch 63/150\n",
      "156/156 [==============================] - 0s 516us/step - loss: 0.3874 - acc: 0.8333\n",
      "Epoch 64/150\n",
      "156/156 [==============================] - 0s 512us/step - loss: 0.3835 - acc: 0.8205\n",
      "Epoch 65/150\n",
      "156/156 [==============================] - 0s 500us/step - loss: 0.3865 - acc: 0.8141\n",
      "Epoch 66/150\n",
      "156/156 [==============================] - 0s 484us/step - loss: 0.3881 - acc: 0.8141\n",
      "Epoch 67/150\n",
      "156/156 [==============================] - 0s 514us/step - loss: 0.3822 - acc: 0.8333\n",
      "Epoch 68/150\n",
      "156/156 [==============================] - 0s 545us/step - loss: 0.3784 - acc: 0.8141\n",
      "Epoch 69/150\n",
      "156/156 [==============================] - 0s 520us/step - loss: 0.3824 - acc: 0.8462\n",
      "Epoch 70/150\n",
      "156/156 [==============================] - 0s 518us/step - loss: 0.3790 - acc: 0.8333\n",
      "Epoch 71/150\n",
      "156/156 [==============================] - 0s 512us/step - loss: 0.3778 - acc: 0.8333\n",
      "Epoch 72/150\n",
      "156/156 [==============================] - 0s 510us/step - loss: 0.3716 - acc: 0.8205\n",
      "Epoch 73/150\n",
      "156/156 [==============================] - 0s 513us/step - loss: 0.3805 - acc: 0.8013\n",
      "Epoch 74/150\n",
      "156/156 [==============================] - 0s 527us/step - loss: 0.3730 - acc: 0.8141\n",
      "Epoch 75/150\n",
      "156/156 [==============================] - 0s 526us/step - loss: 0.3709 - acc: 0.8333\n",
      "Epoch 76/150\n",
      "156/156 [==============================] - 0s 507us/step - loss: 0.3707 - acc: 0.8462\n",
      "Epoch 77/150\n",
      "156/156 [==============================] - 0s 510us/step - loss: 0.3515 - acc: 0.8526\n",
      "Epoch 78/150\n",
      "156/156 [==============================] - 0s 488us/step - loss: 0.3757 - acc: 0.8077\n",
      "Epoch 79/150\n",
      "156/156 [==============================] - 0s 499us/step - loss: 0.3690 - acc: 0.8462\n",
      "Epoch 80/150\n",
      "156/156 [==============================] - 0s 542us/step - loss: 0.3649 - acc: 0.8333\n",
      "Epoch 81/150\n",
      "156/156 [==============================] - 0s 514us/step - loss: 0.3584 - acc: 0.8333\n",
      "Epoch 82/150\n",
      "156/156 [==============================] - 0s 511us/step - loss: 0.3640 - acc: 0.8269\n",
      "Epoch 83/150\n",
      "156/156 [==============================] - 0s 493us/step - loss: 0.3602 - acc: 0.8397\n",
      "Epoch 84/150\n",
      "156/156 [==============================] - 0s 507us/step - loss: 0.3690 - acc: 0.8205\n",
      "Epoch 85/150\n",
      "156/156 [==============================] - 0s 549us/step - loss: 0.3613 - acc: 0.8077\n",
      "Epoch 86/150\n",
      "156/156 [==============================] - 0s 502us/step - loss: 0.3546 - acc: 0.8526\n",
      "Epoch 87/150\n",
      "156/156 [==============================] - 0s 495us/step - loss: 0.3556 - acc: 0.8333\n",
      "Epoch 88/150\n",
      "156/156 [==============================] - 0s 520us/step - loss: 0.3590 - acc: 0.8462\n",
      "Epoch 89/150\n",
      "156/156 [==============================] - 0s 517us/step - loss: 0.3564 - acc: 0.8269\n",
      "Epoch 90/150\n",
      "156/156 [==============================] - 0s 508us/step - loss: 0.3558 - acc: 0.8269\n",
      "Epoch 91/150\n",
      "156/156 [==============================] - 0s 522us/step - loss: 0.3538 - acc: 0.8590\n",
      "Epoch 92/150\n",
      "156/156 [==============================] - 0s 524us/step - loss: 0.3554 - acc: 0.8462\n",
      "Epoch 93/150\n",
      "156/156 [==============================] - 0s 523us/step - loss: 0.3500 - acc: 0.8526\n",
      "Epoch 94/150\n",
      "156/156 [==============================] - 0s 480us/step - loss: 0.3537 - acc: 0.8526\n",
      "Epoch 95/150\n",
      "156/156 [==============================] - 0s 493us/step - loss: 0.3447 - acc: 0.8397\n",
      "Epoch 96/150\n",
      "156/156 [==============================] - 0s 512us/step - loss: 0.3508 - acc: 0.8333\n",
      "Epoch 97/150\n",
      "156/156 [==============================] - 0s 559us/step - loss: 0.3451 - acc: 0.8462\n",
      "Epoch 98/150\n",
      "156/156 [==============================] - 0s 518us/step - loss: 0.3558 - acc: 0.8333\n",
      "Epoch 99/150\n",
      "156/156 [==============================] - 0s 490us/step - loss: 0.3406 - acc: 0.8397\n",
      "Epoch 100/150\n",
      "156/156 [==============================] - 0s 504us/step - loss: 0.3490 - acc: 0.8397\n",
      "Epoch 101/150\n",
      "156/156 [==============================] - 0s 501us/step - loss: 0.3434 - acc: 0.8462\n",
      "Epoch 102/150\n",
      "156/156 [==============================] - 0s 493us/step - loss: 0.3417 - acc: 0.8590\n",
      "Epoch 103/150\n",
      "156/156 [==============================] - 0s 496us/step - loss: 0.3435 - acc: 0.8141\n",
      "Epoch 104/150\n",
      "156/156 [==============================] - 0s 477us/step - loss: 0.3442 - acc: 0.8590\n",
      "Epoch 105/150\n",
      "156/156 [==============================] - 0s 489us/step - loss: 0.3413 - acc: 0.8333\n",
      "Epoch 106/150\n",
      "156/156 [==============================] - 0s 479us/step - loss: 0.3323 - acc: 0.8397\n",
      "Epoch 107/150\n",
      "156/156 [==============================] - 0s 518us/step - loss: 0.3417 - acc: 0.8397\n",
      "Epoch 108/150\n",
      "156/156 [==============================] - 0s 490us/step - loss: 0.3394 - acc: 0.8397\n",
      "Epoch 109/150\n",
      "156/156 [==============================] - 0s 538us/step - loss: 0.3314 - acc: 0.8654\n",
      "Epoch 110/150\n",
      "156/156 [==============================] - 0s 501us/step - loss: 0.3320 - acc: 0.8782\n",
      "Epoch 111/150\n",
      "156/156 [==============================] - 0s 488us/step - loss: 0.3331 - acc: 0.8526\n",
      "Epoch 112/150\n",
      "156/156 [==============================] - 0s 494us/step - loss: 0.3296 - acc: 0.8462\n",
      "Epoch 113/150\n",
      "156/156 [==============================] - 0s 498us/step - loss: 0.3255 - acc: 0.8590\n",
      "Epoch 114/150\n",
      "156/156 [==============================] - 0s 494us/step - loss: 0.3288 - acc: 0.8526\n",
      "Epoch 115/150\n",
      "156/156 [==============================] - 0s 502us/step - loss: 0.3294 - acc: 0.8526\n",
      "Epoch 116/150\n",
      "156/156 [==============================] - 0s 496us/step - loss: 0.3283 - acc: 0.8526\n",
      "Epoch 117/150\n",
      "156/156 [==============================] - 0s 507us/step - loss: 0.3269 - acc: 0.8526\n",
      "Epoch 118/150\n",
      "156/156 [==============================] - 0s 503us/step - loss: 0.3197 - acc: 0.8782\n",
      "Epoch 119/150\n",
      "156/156 [==============================] - 0s 492us/step - loss: 0.3197 - acc: 0.8590\n",
      "Epoch 120/150\n",
      "156/156 [==============================] - 0s 502us/step - loss: 0.3170 - acc: 0.8782\n",
      "Epoch 121/150\n",
      "156/156 [==============================] - 0s 539us/step - loss: 0.3286 - acc: 0.8526\n",
      "Epoch 122/150\n",
      "156/156 [==============================] - 0s 489us/step - loss: 0.3237 - acc: 0.8590\n",
      "Epoch 123/150\n",
      "156/156 [==============================] - 0s 516us/step - loss: 0.3165 - acc: 0.8526\n",
      "Epoch 124/150\n",
      "156/156 [==============================] - 0s 498us/step - loss: 0.3226 - acc: 0.8590\n",
      "Epoch 125/150\n",
      "156/156 [==============================] - 0s 590us/step - loss: 0.3140 - acc: 0.8590\n",
      "Epoch 126/150\n",
      "156/156 [==============================] - 0s 508us/step - loss: 0.3192 - acc: 0.8526\n",
      "Epoch 127/150\n",
      "156/156 [==============================] - 0s 510us/step - loss: 0.3235 - acc: 0.8397\n",
      "Epoch 128/150\n",
      "156/156 [==============================] - 0s 516us/step - loss: 0.3155 - acc: 0.8590\n",
      "Epoch 129/150\n",
      "156/156 [==============================] - 0s 498us/step - loss: 0.3144 - acc: 0.8654\n",
      "Epoch 130/150\n",
      "156/156 [==============================] - 0s 516us/step - loss: 0.3214 - acc: 0.8590\n",
      "Epoch 131/150\n",
      "156/156 [==============================] - 0s 493us/step - loss: 0.3116 - acc: 0.8782\n",
      "Epoch 132/150\n",
      "156/156 [==============================] - 0s 497us/step - loss: 0.3115 - acc: 0.8654\n",
      "Epoch 133/150\n",
      "156/156 [==============================] - 0s 511us/step - loss: 0.3099 - acc: 0.8782\n",
      "Epoch 134/150\n",
      "156/156 [==============================] - 0s 534us/step - loss: 0.3104 - acc: 0.8590\n",
      "Epoch 135/150\n",
      "156/156 [==============================] - 0s 503us/step - loss: 0.3112 - acc: 0.8718\n",
      "Epoch 136/150\n",
      "156/156 [==============================] - 0s 513us/step - loss: 0.3045 - acc: 0.8910\n",
      "Epoch 137/150\n",
      "156/156 [==============================] - 0s 820us/step - loss: 0.3066 - acc: 0.8718\n",
      "Epoch 138/150\n",
      "156/156 [==============================] - 0s 512us/step - loss: 0.3102 - acc: 0.8590\n",
      "Epoch 139/150\n",
      "156/156 [==============================] - 0s 472us/step - loss: 0.3041 - acc: 0.8654\n",
      "Epoch 140/150\n",
      "156/156 [==============================] - 0s 567us/step - loss: 0.3032 - acc: 0.8654\n",
      "Epoch 141/150\n",
      "156/156 [==============================] - 0s 500us/step - loss: 0.3028 - acc: 0.8782\n",
      "Epoch 142/150\n",
      "156/156 [==============================] - 0s 500us/step - loss: 0.3008 - acc: 0.8654\n",
      "Epoch 143/150\n",
      "156/156 [==============================] - 0s 492us/step - loss: 0.3004 - acc: 0.8718\n",
      "Epoch 144/150\n",
      "156/156 [==============================] - 0s 501us/step - loss: 0.3028 - acc: 0.8718\n",
      "Epoch 145/150\n",
      "156/156 [==============================] - 0s 517us/step - loss: 0.2960 - acc: 0.8654\n",
      "Epoch 146/150\n",
      "156/156 [==============================] - 0s 494us/step - loss: 0.2912 - acc: 0.8782\n",
      "Epoch 147/150\n",
      "156/156 [==============================] - 0s 531us/step - loss: 0.2917 - acc: 0.8846\n",
      "Epoch 148/150\n",
      "156/156 [==============================] - 0s 547us/step - loss: 0.3011 - acc: 0.8654\n",
      "Epoch 149/150\n",
      "156/156 [==============================] - 0s 504us/step - loss: 0.2984 - acc: 0.8718\n",
      "Epoch 150/150\n",
      "156/156 [==============================] - 0s 498us/step - loss: 0.2954 - acc: 0.8846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f48e6499048>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(X_train, y_train, epochs=best_epoch, batch_size=best_batch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_137 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 3,721\n",
      "Trainable params: 3,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the final model\n",
    "print(final_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 3s 59ms/step\n",
      "\n",
      "acc: 82.69%\n",
      "\n",
      "loss: 41.44%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Keras model on previously unseen data\n",
    "scores = final_model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (final_model.metrics_names[1], scores[1]*100))\n",
    "print(\"\\n%s: %.2f%%\" % (final_model.metrics_names[0], scores[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 4 Optimize Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5. Finalize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 5 Finalize Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0365, 0.1632, 0.1636, 0.1421, 0.113, 0.1306, 0.2112, 0.2268, 0.2992, 0.3735, 0.3042, 0.0387, 0.2679, 0.5397, 0.6204, 0.7257, 0.835, 0.6888, 0.445, 0.3921, 0.5605, 0.7545, 0.8311, 1.0, 0.8762, 0.7092, 0.7009, 0.5014, 0.3942, 0.4456, 0.4072, 0.0773, 0.1423, 0.0401, 0.3597, 0.6847, 0.7076, 0.3597, 0.0612, 0.3027, 0.3966, 0.3868, 0.238, 0.2059, 0.2288, 0.1704, 0.1587, 0.1792, 0.1022, 0.0151, 0.0223, 0.011, 0.0071, 0.0205, 0.0164, 0.0063, 0.0078, 0.0094, 0.011, 0.0068] => 0 (expected 1)\n",
      "[0.0099, 0.0484, 0.0299, 0.0297, 0.0652, 0.1077, 0.2363, 0.2385, 0.0075, 0.1882, 0.1456, 0.1892, 0.3176, 0.134, 0.2169, 0.2458, 0.2589, 0.2786, 0.2298, 0.0656, 0.1441, 0.1179, 0.1668, 0.1783, 0.2476, 0.257, 0.1036, 0.5356, 0.7124, 0.6291, 0.4756, 0.6015, 0.7208, 0.6234, 0.5725, 0.7523, 0.8712, 0.9252, 0.9709, 0.9297, 0.8995, 0.7911, 0.56, 0.2838, 0.4407, 0.5507, 0.4331, 0.2905, 0.1981, 0.0779, 0.0396, 0.0173, 0.0149, 0.0115, 0.0202, 0.0139, 0.0029, 0.016, 0.0106, 0.0134] => 1 (expected 1)\n",
      "[0.0308, 0.0339, 0.0202, 0.0889, 0.157, 0.175, 0.092, 0.1353, 0.1593, 0.2795, 0.3336, 0.294, 0.1608, 0.3335, 0.4985, 0.7295, 0.735, 0.8253, 0.8793, 0.9657, 1.0, 0.8707, 0.6471, 0.5973, 0.8218, 0.7755, 0.6111, 0.4195, 0.299, 0.1354, 0.2438, 0.5624, 0.5555, 0.6963, 0.7298, 0.7022, 0.5468, 0.1421, 0.4738, 0.641, 0.4375, 0.3178, 0.2377, 0.2808, 0.1374, 0.1136, 0.1034, 0.0688, 0.0422, 0.0117, 0.007, 0.0167, 0.0127, 0.0138, 0.009, 0.0051, 0.0029, 0.0122, 0.0056, 0.002] => 0 (expected 1)\n",
      "[0.013, 0.0006, 0.0088, 0.0456, 0.0525, 0.0778, 0.0931, 0.0941, 0.1711, 0.1483, 0.1532, 0.11, 0.089, 0.1236, 0.1197, 0.1145, 0.2137, 0.2838, 0.364, 0.543, 0.6673, 0.7979, 0.9273, 0.9027, 0.9192, 1.0, 0.9821, 0.9092, 0.8184, 0.6962, 0.59, 0.5447, 0.5142, 0.5389, 0.5531, 0.5318, 0.4826, 0.379, 0.1831, 0.175, 0.1679, 0.0674, 0.0609, 0.0375, 0.0533, 0.0278, 0.0179, 0.0114, 0.0073, 0.0116, 0.0092, 0.0078, 0.0041, 0.0013, 0.0011, 0.0045, 0.0039, 0.0022, 0.0023, 0.0016] => 1 (expected 1)\n",
      "[0.0664, 0.0575, 0.0842, 0.0372, 0.0458, 0.0771, 0.0771, 0.113, 0.2353, 0.1838, 0.2869, 0.4129, 0.3647, 0.1984, 0.284, 0.4039, 0.5837, 0.6792, 0.6086, 0.4858, 0.3246, 0.2013, 0.2082, 0.1686, 0.2484, 0.2736, 0.2984, 0.4655, 0.699, 0.7474, 0.7956, 0.7981, 0.6715, 0.6942, 0.744, 0.8169, 0.8912, 1.0, 0.8753, 0.7061, 0.6803, 0.5898, 0.4618, 0.3639, 0.1492, 0.1216, 0.1306, 0.1198, 0.0578, 0.0235, 0.0135, 0.0141, 0.019, 0.0043, 0.0036, 0.0026, 0.0024, 0.0162, 0.0109, 0.0079] => 1 (expected 1)\n",
      "[0.031, 0.0221, 0.0433, 0.0191, 0.0964, 0.1827, 0.1106, 0.1702, 0.2804, 0.4432, 0.5222, 0.5611, 0.5379, 0.4048, 0.2245, 0.1784, 0.2297, 0.272, 0.5209, 0.6898, 0.8202, 0.878, 0.76, 0.7616, 0.7152, 0.7288, 0.8686, 0.9509, 0.8348, 0.573, 0.4363, 0.4289, 0.424, 0.3156, 0.1287, 0.1477, 0.2062, 0.24, 0.5173, 0.5168, 0.1491, 0.2407, 0.3415, 0.4494, 0.4624, 0.2001, 0.0775, 0.1232, 0.0783, 0.0089, 0.0249, 0.0204, 0.0059, 0.0053, 0.0079, 0.0037, 0.0015, 0.0056, 0.0067, 0.0054] => 1 (expected 0)\n",
      "[0.0329, 0.0216, 0.0386, 0.0627, 0.1158, 0.1482, 0.2054, 0.1605, 0.2532, 0.2672, 0.3056, 0.3161, 0.2314, 0.2067, 0.1804, 0.2808, 0.4423, 0.5947, 0.6601, 0.5844, 0.4539, 0.4789, 0.5646, 0.5281, 0.7115, 1.0, 0.9564, 0.609, 0.5112, 0.4, 0.0482, 0.1852, 0.2186, 0.1436, 0.1757, 0.1428, 0.1644, 0.3089, 0.3648, 0.4441, 0.3859, 0.2813, 0.1238, 0.0953, 0.1201, 0.0825, 0.0618, 0.0141, 0.0108, 0.0124, 0.0104, 0.0095, 0.0151, 0.0059, 0.0015, 0.0053, 0.0016, 0.0042, 0.0053, 0.0074] => 1 (expected 0)\n",
      "[0.0211, 0.0319, 0.0415, 0.0286, 0.0121, 0.0438, 0.1299, 0.139, 0.0695, 0.0568, 0.0869, 0.1935, 0.1478, 0.1871, 0.1994, 0.3283, 0.6861, 0.5814, 0.25, 0.1734, 0.3363, 0.5588, 0.6592, 0.7012, 0.8099, 0.8901, 0.8745, 0.7887, 0.8725, 0.9376, 0.892, 0.7508, 0.6832, 0.761, 0.9017, 1.0, 0.9123, 0.7388, 0.5915, 0.4057, 0.3019, 0.2331, 0.2931, 0.2298, 0.2391, 0.191, 0.1096, 0.03, 0.0171, 0.0383, 0.0053, 0.009, 0.0042, 0.0153, 0.0106, 0.002, 0.0105, 0.0049, 0.007, 0.008] => 0 (expected 1)\n",
      "[0.026, 0.0192, 0.0254, 0.0061, 0.0352, 0.0701, 0.1263, 0.108, 0.1523, 0.163, 0.103, 0.2187, 0.1542, 0.263, 0.294, 0.2978, 0.0699, 0.1401, 0.299, 0.3915, 0.3598, 0.2403, 0.4208, 0.5675, 0.6094, 0.6323, 0.6549, 0.7673, 1.0, 0.8463, 0.5509, 0.4444, 0.5169, 0.4268, 0.1802, 0.0791, 0.0535, 0.1906, 0.2561, 0.2153, 0.2769, 0.2841, 0.1733, 0.0815, 0.0335, 0.0933, 0.1018, 0.0309, 0.0208, 0.0318, 0.0132, 0.0118, 0.012, 0.0051, 0.007, 0.0015, 0.0035, 0.0008, 0.0044, 0.0077] => 0 (expected 1)\n",
      "[0.1313, 0.2339, 0.3059, 0.4264, 0.401, 0.1791, 0.1853, 0.0055, 0.1929, 0.2231, 0.2907, 0.2259, 0.3136, 0.3302, 0.366, 0.3956, 0.4386, 0.467, 0.5255, 0.3735, 0.2243, 0.1973, 0.4337, 0.6532, 0.507, 0.2796, 0.4163, 0.595, 0.5242, 0.4178, 0.3714, 0.2375, 0.0863, 0.1437, 0.2896, 0.4577, 0.3725, 0.3372, 0.3803, 0.4181, 0.3603, 0.2711, 0.1653, 0.1951, 0.2811, 0.2246, 0.1921, 0.15, 0.0665, 0.0193, 0.0156, 0.0362, 0.021, 0.0154, 0.018, 0.0013, 0.0106, 0.0127, 0.0178, 0.0231] => 1 (expected 0)\n",
      "[0.0261, 0.0266, 0.0223, 0.0749, 0.1364, 0.1513, 0.1316, 0.1654, 0.1864, 0.2013, 0.289, 0.365, 0.351, 0.3495, 0.4325, 0.5398, 0.6237, 0.6876, 0.7329, 0.8107, 0.8396, 0.8632, 0.8747, 0.9607, 0.9716, 0.9121, 0.8576, 0.8798, 0.772, 0.5711, 0.4264, 0.286, 0.3114, 0.2066, 0.1165, 0.0185, 0.1302, 0.248, 0.1637, 0.1103, 0.2144, 0.2033, 0.1887, 0.137, 0.1376, 0.0307, 0.0373, 0.0606, 0.0399, 0.0169, 0.0135, 0.0222, 0.0175, 0.0127, 0.0022, 0.0124, 0.0054, 0.0021, 0.0028, 0.0023] => 1 (expected 0)\n",
      "[0.0262, 0.0582, 0.1099, 0.1083, 0.0974, 0.228, 0.2431, 0.3771, 0.5598, 0.6194, 0.6333, 0.706, 0.5544, 0.532, 0.6479, 0.6931, 0.6759, 0.7551, 0.8929, 0.8619, 0.7974, 0.6737, 0.4293, 0.3648, 0.5331, 0.2413, 0.507, 0.8533, 0.6036, 0.8514, 0.8512, 0.5045, 0.1862, 0.2709, 0.4232, 0.3043, 0.6116, 0.6756, 0.5375, 0.4719, 0.4647, 0.2587, 0.2129, 0.2222, 0.2111, 0.0176, 0.1348, 0.0744, 0.013, 0.0106, 0.0033, 0.0232, 0.0166, 0.0095, 0.018, 0.0244, 0.0316, 0.0164, 0.0095, 0.0078] => 1 (expected 1)\n",
      "[0.0197, 0.0394, 0.0384, 0.0076, 0.0251, 0.0629, 0.0747, 0.0578, 0.1357, 0.1695, 0.1734, 0.247, 0.3141, 0.3297, 0.2759, 0.2056, 0.1162, 0.1884, 0.339, 0.3926, 0.4282, 0.5418, 0.6448, 0.7223, 0.7853, 0.7984, 0.8847, 0.9582, 0.899, 0.6831, 0.6108, 0.548, 0.5058, 0.4476, 0.2401, 0.1405, 0.1772, 0.1742, 0.3326, 0.4021, 0.3009, 0.2075, 0.1206, 0.0255, 0.0298, 0.0691, 0.0781, 0.0777, 0.0369, 0.0057, 0.0091, 0.0134, 0.0097, 0.0042, 0.0058, 0.0072, 0.0041, 0.0045, 0.0047, 0.0054] => 1 (expected 0)\n",
      "[0.0368, 0.0279, 0.0103, 0.0566, 0.0759, 0.0679, 0.097, 0.1473, 0.2164, 0.2544, 0.2936, 0.2935, 0.2657, 0.3187, 0.2794, 0.2534, 0.198, 0.1929, 0.2826, 0.3245, 0.3504, 0.3324, 0.4217, 0.4774, 0.4808, 0.6325, 0.8334, 0.9458, 1.0, 0.8425, 0.5524, 0.4795, 0.52, 0.3968, 0.194, 0.1519, 0.201, 0.1736, 0.1029, 0.2244, 0.3717, 0.4449, 0.3939, 0.203, 0.201, 0.2187, 0.184, 0.1477, 0.0971, 0.0224, 0.0151, 0.0105, 0.0024, 0.0018, 0.0057, 0.0092, 0.0009, 0.0086, 0.011, 0.0052] => 1 (expected 0)\n",
      "[0.0231, 0.0315, 0.017, 0.0226, 0.041, 0.0116, 0.0223, 0.0805, 0.2365, 0.2461, 0.2245, 0.152, 0.1732, 0.3099, 0.438, 0.5595, 0.682, 0.6164, 0.6803, 0.8435, 0.9921, 1.0, 0.7983, 0.5426, 0.3952, 0.5179, 0.565, 0.3042, 0.1881, 0.396, 0.2286, 0.3544, 0.4187, 0.2398, 0.1847, 0.376, 0.4331, 0.3626, 0.2519, 0.187, 0.1046, 0.2339, 0.1991, 0.11, 0.0684, 0.0303, 0.0674, 0.0785, 0.0455, 0.0246, 0.0151, 0.0125, 0.0036, 0.0123, 0.0043, 0.0114, 0.0052, 0.0091, 0.0008, 0.0092] => 1 (expected 0)\n",
      "[0.0335, 0.0258, 0.0398, 0.057, 0.0529, 0.1091, 0.1709, 0.1684, 0.1865, 0.266, 0.3188, 0.3553, 0.3116, 0.1965, 0.178, 0.2794, 0.287, 0.3969, 0.5599, 0.6936, 0.7969, 0.7452, 0.8203, 0.9261, 0.881, 0.8814, 0.9301, 0.9955, 0.8576, 0.6069, 0.3934, 0.2464, 0.1645, 0.114, 0.0956, 0.008, 0.0702, 0.0936, 0.0894, 0.1127, 0.0873, 0.102, 0.1964, 0.2256, 0.1814, 0.2012, 0.1688, 0.1037, 0.0501, 0.0136, 0.013, 0.012, 0.0039, 0.0053, 0.0062, 0.0046, 0.0045, 0.0022, 0.0005, 0.0031] => 1 (expected 0)\n",
      "[0.0235, 0.022, 0.0167, 0.0516, 0.0746, 0.1121, 0.1258, 0.1717, 0.3074, 0.3199, 0.2946, 0.2484, 0.251, 0.1806, 0.1413, 0.3019, 0.3635, 0.3887, 0.298, 0.2219, 0.1624, 0.1343, 0.2046, 0.3791, 0.5771, 0.7545, 0.8406, 0.8547, 0.9036, 1.0, 0.9646, 0.7912, 0.6412, 0.5986, 0.6835, 0.7771, 0.8084, 0.7426, 0.6295, 0.5708, 0.4433, 0.3361, 0.3795, 0.495, 0.4373, 0.2404, 0.1128, 0.1654, 0.0933, 0.0225, 0.0214, 0.0221, 0.0152, 0.0083, 0.0058, 0.0023, 0.0057, 0.0052, 0.0027, 0.0021] => 1 (expected 0)\n",
      "[0.027, 0.0163, 0.0341, 0.0247, 0.0822, 0.1256, 0.1323, 0.1584, 0.2017, 0.2122, 0.221, 0.2399, 0.2964, 0.4061, 0.5095, 0.5512, 0.6613, 0.6804, 0.652, 0.6788, 0.7811, 0.8369, 0.8969, 0.9856, 1.0, 0.9395, 0.8917, 0.8105, 0.6828, 0.5572, 0.4301, 0.3339, 0.2035, 0.0798, 0.0809, 0.1525, 0.2626, 0.2456, 0.198, 0.2412, 0.2409, 0.1901, 0.2077, 0.1767, 0.1119, 0.0779, 0.1344, 0.096, 0.0598, 0.033, 0.0197, 0.0189, 0.0204, 0.0085, 0.0043, 0.0092, 0.0138, 0.0094, 0.0105, 0.0093] => 1 (expected 0)\n",
      "[0.0408, 0.0653, 0.0397, 0.0604, 0.0496, 0.1817, 0.1178, 0.1024, 0.0583, 0.2176, 0.2459, 0.3332, 0.3087, 0.2613, 0.3232, 0.3731, 0.4203, 0.5364, 0.7062, 0.8196, 0.8835, 0.8299, 0.7609, 0.7605, 0.8367, 0.8905, 0.7652, 0.5897, 0.3037, 0.0823, 0.2787, 0.7241, 0.8032, 0.805, 0.7676, 0.7468, 0.6253, 0.173, 0.2916, 0.5003, 0.522, 0.4824, 0.4004, 0.3877, 0.1651, 0.0442, 0.0663, 0.0418, 0.0475, 0.0235, 0.0066, 0.0062, 0.0129, 0.0184, 0.0069, 0.0198, 0.0199, 0.0102, 0.007, 0.0055] => 1 (expected 1)\n",
      "[0.0221, 0.0065, 0.0164, 0.0487, 0.0519, 0.0849, 0.0812, 0.1833, 0.2228, 0.181, 0.2549, 0.2984, 0.2624, 0.1893, 0.0668, 0.2666, 0.4274, 0.6291, 0.7782, 0.7686, 0.8099, 0.8493, 0.944, 0.945, 0.9655, 0.8045, 0.4969, 0.396, 0.3856, 0.5574, 0.7309, 0.8549, 0.9425, 0.8726, 0.6673, 0.4694, 0.1546, 0.1748, 0.3607, 0.5208, 0.5177, 0.3702, 0.224, 0.0816, 0.0395, 0.0785, 0.1052, 0.1034, 0.0764, 0.0216, 0.0167, 0.0089, 0.0051, 0.0015, 0.0075, 0.0058, 0.0016, 0.007, 0.0074, 0.0038] => 0 (expected 0)\n"
     ]
    }
   ],
   "source": [
    "# Make class predictions with the model\n",
    "predictions = final_model.predict_classes(X_original)\n",
    "\n",
    "# Summarize the first 20 cases\n",
    "for i in range(20):\n",
    "\tprint('%s => %d (expected %d)' % (X_test[i].tolist(), predictions[i], y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 5 Finalize Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Total time for the script:',(datetime.now() - startTimeScript))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
