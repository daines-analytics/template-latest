{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Deep Learning Model for [PROJECT NAME] Using Keras Version 3\n",
    "### David Lowe\n",
    "### November 12, 2019\n",
    "\n",
    "Template Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery. [https://machinelearningmastery.com/]\n",
    "\n",
    "SUMMARY: The purpose of this project is to construct a predictive model using various machine learning algorithms and to document the end-to-end steps using a template. The [PROJECT NAME] dataset is a binary classification situation where we are trying to predict one of the two possible outcomes.\n",
    "\n",
    "INTRODUCTION: [Sample Paragraph - The dataset contains various measurements of breast tissue samples for cancer diagnosis. It contains measurements such as the thickness of the clump, the uniformity of cell size and shape, the marginal adhesion, and so on. Dr. William H. Wolberg of the University of Wisconsin Hospitals in Madison is the original provider of this dataset.]\n",
    "\n",
    "ANALYSIS: [Sample Paragraph - The baseline performance of the model achieved an average accuracy score of 97.14%. After tuning the hyperparameters, the best model processed the training dataset with an accuracy of 97.32%. Furthermore, the final model processed the test dataset with an accuracy of 93.71%, which indicated a high-variance, over-fitting issue. We may need to acquire more data and/or apply regularization techniques during training before deploying the model for production use.]\n",
    "\n",
    "CONCLUSION: For this dataset, the model built using Keras and TensorFlow achieved a satisfactory result and should be considered for future modeling activities.\n",
    "\n",
    "Dataset Used: [PROJECT NAME] Dataset\n",
    "\n",
    "Dataset ML Model: Binary classification with numerical attributes\n",
    "\n",
    "Dataset Reference: [https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29]\n",
    "\n",
    "One potential source of performance benchmarks: [https://www.kaggle.com/uciml/breast-cancer-wisconsin-data]\n",
    "\n",
    "Any deep-learning modeling project genrally can be broken down into about six major tasks:\n",
    "0. Prepare Environment\n",
    "1. Load Data\n",
    "2. Define Model\n",
    "3. Fit and Evaluate Model\n",
    "4. Optimize Model\n",
    "5. Finalize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 0. Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the warning message filter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed number for reproducible results\n",
    "seedNum = 888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load libraries and packages\n",
    "import random\n",
    "random.seed(seedNum)\n",
    "import numpy as np\n",
    "np.random.seed(seedNum)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seedNum)\n",
    "import keras as K\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.utils import np_utils\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import smtplib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from email.message import EmailMessage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Begin the timer for the script processing\n",
    "startTimeScript = datetime.now()\n",
    "\n",
    "# Set up the verbose flag to print detailed messages for debugging (setting to True will activate)\n",
    "verbose = True\n",
    "tf.debugging.set_log_device_placement(verbose)\n",
    "\n",
    "# Set up the number of CPU cores available for multi-thread processing\n",
    "n_jobs = -1\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Set up the flag to stop sending progress emails (setting to True will send status emails!)\n",
    "notifyStatus = False\n",
    "\n",
    "# Set the number of folds for cross validation\n",
    "n_folds = 5\n",
    "\n",
    "# Set the flag for splitting the dataset\n",
    "splitDataset = True\n",
    "splitPercentage = 0.25\n",
    "\n",
    "# Set various default Keras modeling parameters\n",
    "default_kernel_init = K.initializers.RandomNormal(seed=seedNum)\n",
    "default_loss = 'binary_crossentropy'\n",
    "default_optimizer = 'adam'\n",
    "default_epochs = 250\n",
    "default_batches = 8\n",
    "default_metrics = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the email notification function\n",
    "def email_notify(msg_text):\n",
    "    sender = os.environ.get('MAIL_SENDER')\n",
    "    receiver = os.environ.get('MAIL_RECEIVER')\n",
    "    gateway = os.environ.get('SMTP_GATEWAY')\n",
    "    smtpuser = os.environ.get('SMTP_USERNAME')\n",
    "    password = os.environ.get('SMTP_PASSWORD')\n",
    "    if sender==None or receiver==None or gateway==None or smtpuser==None or password==None:\n",
    "        sys.exit(\"Incomplete email setup info. Script Processing Aborted!!!\")\n",
    "    msg = EmailMessage()\n",
    "    msg.set_content(msg_text)\n",
    "    msg['Subject'] = 'Notification from Keras Binary Classification Script'\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = receiver\n",
    "    server = smtplib.SMTP(gateway, 587)\n",
    "    server.starttls()\n",
    "    server.login(smtpuser, password)\n",
    "    server.send_message(msg)\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 0 Prepare Environment completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 1 Load Data has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a) Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attr01</th>\n",
       "      <th>attr02</th>\n",
       "      <th>attr03</th>\n",
       "      <th>attr04</th>\n",
       "      <th>attr05</th>\n",
       "      <th>attr06</th>\n",
       "      <th>attr07</th>\n",
       "      <th>attr08</th>\n",
       "      <th>attr09</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1017122</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1018099</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1018561</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1033078</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1033078</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  attr01  attr02  attr03  attr04  attr05  attr06  attr07  attr08  \\\n",
       "0  1000025       5       1       1       1       2     1.0       3       1   \n",
       "1  1002945       5       4       4       5       7    10.0       3       2   \n",
       "2  1015425       3       1       1       1       2     2.0       3       1   \n",
       "3  1016277       6       8       8       1       3     4.0       3       7   \n",
       "4  1017023       4       1       1       3       2     1.0       3       1   \n",
       "5  1017122       8      10      10       8       7    10.0       9       7   \n",
       "6  1018099       1       1       1       1       2    10.0       3       1   \n",
       "7  1018561       2       1       2       1       2     1.0       3       1   \n",
       "8  1033078       2       1       1       1       2     1.0       1       1   \n",
       "9  1033078       4       2       1       1       2     1.0       2       1   \n",
       "\n",
       "   attr09  target  \n",
       "0       1       2  \n",
       "1       1       2  \n",
       "2       1       2  \n",
       "3       1       2  \n",
       "4       1       2  \n",
       "5       1       4  \n",
       "6       1       2  \n",
       "7       1       2  \n",
       "8       5       2  \n",
       "9       1       2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "# dest_file = os.path.basename(dataset_path)\n",
    "# if (os.path.isfile(dest_file) == False) :\n",
    "#     print('Downloading ' + dataset_path + ' as ' + dest_file)\n",
    "#     with urllib.request.urlopen(dataset_path) as in_resp, open(dest_file, 'wb') as out_file:\n",
    "#         shutil.copyfileobj(in_resp, out_file)\n",
    "#     print(dest_file + 'downloaded!')\n",
    "#     print('Unpacking ' + dest_file)\n",
    "#     with zipfile.ZipFile(dest_file, 'r') as zip_ref:\n",
    "#         zip_ref.extractall('.')\n",
    "#     print(dest_file + 'unpacked!')\n",
    "\n",
    "# inputFile = dest_file\n",
    "attrNames = ['attr' + str(i).zfill(2) for i in range(1,10)]\n",
    "colNames = ['id'] + attrNames + ['target']\n",
    "Xy_original = pd.read_csv(dataset_path, names=colNames, sep=',', header=None, index_col=False, na_values=['?'])\n",
    "\n",
    "# Take a peek at the dataframe after the import\n",
    "Xy_original.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      "id        699 non-null int64\n",
      "attr01    699 non-null int64\n",
      "attr02    699 non-null int64\n",
      "attr03    699 non-null int64\n",
      "attr04    699 non-null int64\n",
      "attr05    699 non-null int64\n",
      "attr06    683 non-null float64\n",
      "attr07    699 non-null int64\n",
      "attr08    699 non-null int64\n",
      "attr09    699 non-null int64\n",
      "target    699 non-null int64\n",
      "dtypes: float64(1), int64(10)\n",
      "memory usage: 60.2 KB\n"
     ]
    }
   ],
   "source": [
    "Xy_original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attr01</th>\n",
       "      <th>attr02</th>\n",
       "      <th>attr03</th>\n",
       "      <th>attr04</th>\n",
       "      <th>attr05</th>\n",
       "      <th>attr06</th>\n",
       "      <th>attr07</th>\n",
       "      <th>attr08</th>\n",
       "      <th>attr09</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.990000e+02</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.071704e+06</td>\n",
       "      <td>4.417740</td>\n",
       "      <td>3.134478</td>\n",
       "      <td>3.207439</td>\n",
       "      <td>2.806867</td>\n",
       "      <td>3.216023</td>\n",
       "      <td>3.544656</td>\n",
       "      <td>3.437768</td>\n",
       "      <td>2.866953</td>\n",
       "      <td>1.589413</td>\n",
       "      <td>2.689557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.170957e+05</td>\n",
       "      <td>2.815741</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>3.643857</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>0.951273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.163400e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.706885e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.171710e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.238298e+06</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.345435e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id      attr01      attr02      attr03      attr04  \\\n",
       "count  6.990000e+02  699.000000  699.000000  699.000000  699.000000   \n",
       "mean   1.071704e+06    4.417740    3.134478    3.207439    2.806867   \n",
       "std    6.170957e+05    2.815741    3.051459    2.971913    2.855379   \n",
       "min    6.163400e+04    1.000000    1.000000    1.000000    1.000000   \n",
       "25%    8.706885e+05    2.000000    1.000000    1.000000    1.000000   \n",
       "50%    1.171710e+06    4.000000    1.000000    1.000000    1.000000   \n",
       "75%    1.238298e+06    6.000000    5.000000    5.000000    4.000000   \n",
       "max    1.345435e+07   10.000000   10.000000   10.000000   10.000000   \n",
       "\n",
       "           attr05      attr06      attr07      attr08      attr09      target  \n",
       "count  699.000000  683.000000  699.000000  699.000000  699.000000  699.000000  \n",
       "mean     3.216023    3.544656    3.437768    2.866953    1.589413    2.689557  \n",
       "std      2.214300    3.643857    2.438364    3.053634    1.715078    0.951273  \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    2.000000  \n",
       "25%      2.000000    1.000000    2.000000    1.000000    1.000000    2.000000  \n",
       "50%      2.000000    1.000000    3.000000    1.000000    1.000000    2.000000  \n",
       "75%      4.000000    6.000000    5.000000    4.000000    1.000000    4.000000  \n",
       "max     10.000000   10.000000   10.000000   10.000000   10.000000    4.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy_original.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id         0\n",
      "attr01     0\n",
      "attr02     0\n",
      "attr03     0\n",
      "attr04     0\n",
      "attr05     0\n",
      "attr06    16\n",
      "attr07     0\n",
      "attr08     0\n",
      "attr09     0\n",
      "target     0\n",
      "dtype: int64\n",
      "Total number of NaN in the dataframe:  16\n"
     ]
    }
   ],
   "source": [
    "print(Xy_original.isnull().sum())\n",
    "print('Total number of NaN in the dataframe: ', Xy_original.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b) Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr01</th>\n",
       "      <th>attr02</th>\n",
       "      <th>attr03</th>\n",
       "      <th>attr04</th>\n",
       "      <th>attr05</th>\n",
       "      <th>attr06</th>\n",
       "      <th>attr07</th>\n",
       "      <th>attr08</th>\n",
       "      <th>attr09</th>\n",
       "      <th>targetVar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attr01  attr02  attr03  attr04  attr05  attr06  attr07  attr08  attr09  \\\n",
       "0       5       1       1       1       2     1.0       3       1       1   \n",
       "1       5       4       4       5       7    10.0       3       2       1   \n",
       "2       3       1       1       1       2     2.0       3       1       1   \n",
       "3       6       8       8       1       3     4.0       3       7       1   \n",
       "4       4       1       1       3       2     1.0       3       1       1   \n",
       "5       8      10      10       8       7    10.0       9       7       1   \n",
       "6       1       1       1       1       2    10.0       3       1       1   \n",
       "7       2       1       2       1       2     1.0       3       1       1   \n",
       "8       2       1       1       1       2     1.0       1       1       5   \n",
       "9       4       2       1       1       2     1.0       2       1       1   \n",
       "\n",
       "   targetVar  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "5          1  \n",
       "6          0  \n",
       "7          0  \n",
       "8          0  \n",
       "9          0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the class column to the name of targetVar if required\n",
    "# Xy_original = Xy_original.rename(columns={'old_name': 'targetVar'})\n",
    "\n",
    "# Dropping features\n",
    "Xy_original.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Impute missing values\n",
    "# Xy_original['col_name'].fillna('someValue', inplace=True)\n",
    "Xy_original['attr06'].fillna(value=Xy_original['attr06'].median(), inplace=True)\n",
    "\n",
    "# Convert columns from one data type to another\n",
    "# Xy_original.column_name = Xy_original.column_name.astype('int')\n",
    "# Xy_original.column_name = Xy_original.column_name.astype('category')\n",
    "\n",
    "# Convert features with R/M levels into categorical feature of 0/1\n",
    "def reClassSomecol(target):\n",
    "    if (target == 4): return 1\n",
    "    else: return 0\n",
    "Xy_original['targetVar'] = Xy_original['target'].apply(reClassSomecol)\n",
    "Xy_original.drop(columns=['target'], inplace=True)\n",
    "\n",
    "# Take a peek at the dataframe after the cleaning\n",
    "Xy_original.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      "attr01       699 non-null int64\n",
      "attr02       699 non-null int64\n",
      "attr03       699 non-null int64\n",
      "attr04       699 non-null int64\n",
      "attr05       699 non-null int64\n",
      "attr06       699 non-null float64\n",
      "attr07       699 non-null int64\n",
      "attr08       699 non-null int64\n",
      "attr09       699 non-null int64\n",
      "targetVar    699 non-null int64\n",
      "dtypes: float64(1), int64(9)\n",
      "memory usage: 54.7 KB\n"
     ]
    }
   ],
   "source": [
    "Xy_original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr01</th>\n",
       "      <th>attr02</th>\n",
       "      <th>attr03</th>\n",
       "      <th>attr04</th>\n",
       "      <th>attr05</th>\n",
       "      <th>attr06</th>\n",
       "      <th>attr07</th>\n",
       "      <th>attr08</th>\n",
       "      <th>attr09</th>\n",
       "      <th>targetVar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.417740</td>\n",
       "      <td>3.134478</td>\n",
       "      <td>3.207439</td>\n",
       "      <td>2.806867</td>\n",
       "      <td>3.216023</td>\n",
       "      <td>3.486409</td>\n",
       "      <td>3.437768</td>\n",
       "      <td>2.866953</td>\n",
       "      <td>1.589413</td>\n",
       "      <td>0.344778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.815741</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>3.621929</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>0.475636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           attr01      attr02      attr03      attr04      attr05      attr06  \\\n",
       "count  699.000000  699.000000  699.000000  699.000000  699.000000  699.000000   \n",
       "mean     4.417740    3.134478    3.207439    2.806867    3.216023    3.486409   \n",
       "std      2.815741    3.051459    2.971913    2.855379    2.214300    3.621929   \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      2.000000    1.000000    1.000000    1.000000    2.000000    1.000000   \n",
       "50%      4.000000    1.000000    1.000000    1.000000    2.000000    1.000000   \n",
       "75%      6.000000    5.000000    5.000000    4.000000    4.000000    5.000000   \n",
       "max     10.000000   10.000000   10.000000   10.000000   10.000000   10.000000   \n",
       "\n",
       "           attr07      attr08      attr09   targetVar  \n",
       "count  699.000000  699.000000  699.000000  699.000000  \n",
       "mean     3.437768    2.866953    1.589413    0.344778  \n",
       "std      2.438364    3.053634    1.715078    0.475636  \n",
       "min      1.000000    1.000000    1.000000    0.000000  \n",
       "25%      2.000000    1.000000    1.000000    0.000000  \n",
       "50%      3.000000    1.000000    1.000000    0.000000  \n",
       "75%      5.000000    4.000000    1.000000    1.000000  \n",
       "max     10.000000   10.000000   10.000000    1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy_original.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr01       0\n",
      "attr02       0\n",
      "attr03       0\n",
      "attr04       0\n",
      "attr05       0\n",
      "attr06       0\n",
      "attr07       0\n",
      "attr08       0\n",
      "attr09       0\n",
      "targetVar    0\n",
      "dtype: int64\n",
      "Total number of NaN in the dataframe:  0\n"
     ]
    }
   ],
   "source": [
    "print(Xy_original.isnull().sum())\n",
    "print('Total number of NaN in the dataframe: ', Xy_original.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.c) Feature Scaling and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use variable totCol to hold the number of columns in the dataframe\n",
    "totCol = len(Xy_original.columns)\n",
    "\n",
    "# Set up variable totAttr for the total number of attribute columns\n",
    "totAttr = totCol-1\n",
    "\n",
    "# targetCol variable indicates the column location of the target/class variable\n",
    "# If the first column, set targetCol to 1. If the last column, set targetCol to totCol\n",
    "# If (targetCol <> 1) and (targetCol <> totCol), be aware when slicing up the dataframes for visualization\n",
    "targetCol = totCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xy_original.shape: (699, 10) X_original.shape: (699, 9) y_original.shape: (699,)\n"
     ]
    }
   ],
   "source": [
    "# We create attribute-only and target-only datasets (X_original and y_original)\n",
    "# for various visualization and cleaning/transformation operations\n",
    "\n",
    "if targetCol == totCol:\n",
    "    X_original = Xy_original.iloc[:,0:totAttr]\n",
    "    y_original = Xy_original.iloc[:,totAttr]\n",
    "else:\n",
    "    X_original = Xy_original.iloc[:,1:totCol]\n",
    "    y_original = Xy_original.iloc[:,0]\n",
    "\n",
    "print(\"Xy_original.shape: {} X_original.shape: {} y_original.shape: {}\".format(Xy_original.shape, X_original.shape, y_original.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the number of row and columns for visualization display. dispRow * dispCol should be >= totAttr\n",
    "dispCol = 4\n",
    "if totAttr % dispCol == 0 :\n",
    "    dispRow = totAttr // dispCol\n",
    "else :\n",
    "    dispRow = (totAttr // dispCol) + 1\n",
    "    \n",
    "# Set figure width to display the data visualization plots\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = dispCol*4\n",
    "fig_size[1] = dispRow*4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histograms for each attribute before pre-processing\n",
    "X_original.hist(layout=(dispRow,dispCol))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20693572, -0.69999505, -0.74329904, ..., -0.17966213,\n",
       "        -0.61182504, -0.34391178],\n",
       "       [ 0.20693572,  0.28384518,  0.2668747 , ..., -0.17966213,\n",
       "        -0.28411186, -0.34391178],\n",
       "       [-0.50386559, -0.69999505, -0.74329904, ..., -0.17966213,\n",
       "        -0.61182504, -0.34391178],\n",
       "       ...,\n",
       "       [ 0.20693572,  2.25152563,  2.28722218, ...,  1.87236122,\n",
       "         2.33759359,  0.23956962],\n",
       "       [-0.14846494,  1.59563215,  0.94032386, ...,  2.69317056,\n",
       "         1.02674087, -0.34391178],\n",
       "       [-0.14846494,  1.59563215,  1.61377302, ...,  2.69317056,\n",
       "         0.37131451, -0.34391178]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply feature scaling and transformation\n",
    "\n",
    "# X_original['some_feature'] = preprocessing.scale(X_original['some_feature'])\n",
    "preprocessing.scale(X_original, copy=False)\n",
    "# X_original['some_feature'] = preprocessing.normalize(X_original['some_feature'])\n",
    "# preprocessing.normalize(X_original, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histograms for each attribute after pre-processing\n",
    "X_original.hist(layout=(dispRow,dispCol))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot-encoding before splitting into trainig and test\n",
    "# X_original = pd.get_dummies(X_original)\n",
    "# print(X_original.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.d) Splitting Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0\n",
      " 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 1 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1\n",
      " 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 1\n",
      " 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0\n",
      " 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1\n",
      " 0 0 0 1 1 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 0\n",
      " 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1\n",
      " 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Encode class values as integers and perform one-hot-encoding\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(y_original)\n",
    "y_encoded = encoder.transform(y_original)\n",
    "print(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (524, 9) X_train.type: <class 'numpy.ndarray'>\n",
      "y_train.shape: (524,) y_train.type: <class 'numpy.ndarray'>\n",
      "X_test.shape: (175, 9) X_test.type: <class 'numpy.ndarray'>\n",
      "y_test.shape: (175,) y_test.type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Split the data further into training and test datasets\n",
    "X_encoded = X_original.values\n",
    "if (splitDataset):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=splitPercentage, random_state=seedNum)\n",
    "else:\n",
    "    X_train, y_train = X_encoded, y_encoded\n",
    "    X_test, y_test = X_encoded, y_encoded\n",
    "print(\"X_train.shape: {} X_train.type: {}\".format(X_train.shape, type(X_train)))\n",
    "print(\"y_train.shape: {} y_train.type: {}\".format(y_train.shape, type(y_train)))\n",
    "print(\"X_test.shape: {} X_test.type: {}\".format(X_test.shape, type(X_test)))\n",
    "print(\"y_test.shape: {} y_test.type: {}\".format(y_test.shape, type(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 1 Load Data completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 2 Define Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras model required for KerasClassifier\n",
    "def create_default_model():\n",
    "    default_model = K.models.Sequential()\n",
    "    default_model.add(Dense(9, input_dim=9, kernel_initializer=default_kernel_init, activation='relu'))\n",
    "    default_model.add(Dense(1, kernel_initializer=default_kernel_init, activation='sigmoid'))\n",
    "    default_model.compile(loss=default_loss, optimizer=default_optimizer, metrics=default_metrics)\n",
    "    return default_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Keras model\n",
    "cv_model = KerasClassifier(build_fn=create_default_model, epochs=default_epochs, batch_size=default_batches, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 2 Define Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3. Fit and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 3 Fit and Evaluate Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Reshape in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_keras_scratch_graph_810 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_keras_scratch_graph_27567 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_keras_scratch_graph_28448 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_keras_scratch_graph_55205 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_keras_scratch_graph_56086 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_keras_scratch_graph_82843 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_keras_scratch_graph_83724 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_keras_scratch_graph_110481 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_keras_scratch_graph_111362 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_keras_scratch_graph_138119 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Generating results using the metrics of ['accuracy']\n",
      "All cross-Validate results: [0.97142857 0.96190476 0.96190476 0.98095238 0.98076922]\n",
      "Baseline results [mean (std)]: 97.14% (0.85%)\n",
      "Total time for performing cross-validation of the default model: 0:01:06.716166\n"
     ]
    }
   ],
   "source": [
    "startTimeModule = datetime.now()\n",
    "\n",
    "# Fit and evaluate the Keras model using 10-fold cross validation\n",
    "kfold = KFold(n_splits=n_folds, shuffle=True, random_state=seedNum)\n",
    "results = cross_val_score(cv_model, X_train, y_train, cv=kfold)\n",
    "print('Generating results using the metrics of', default_metrics)\n",
    "print('All cross-Validate results:', results)\n",
    "print('Baseline results [mean (std)]: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
    "\n",
    "print('Total time for performing cross-validation of the default model:', (datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Pb01NDTS44-"
   },
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 3 Fit and Evaluate Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4. Optimize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 4 Optimize Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras model required for KerasClassifier\n",
    "def create_customized_model(optimizer, kernel_init):\n",
    "    customized_model = K.models.Sequential()\n",
    "    customized_model.add(Dense(9, input_dim=9, kernel_initializer=kernel_init, activation='relu'))\n",
    "    customized_model.add(Dense(1, kernel_initializer=kernel_init, activation='sigmoid'))\n",
    "    customized_model.compile(loss=default_loss, optimizer=optimizer, metrics=default_metrics)\n",
    "    return customized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed: 22.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 40.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op __inference_keras_scratch_graph_140066 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Best: 0.973282 using {'optimizer': <keras.optimizers.Adam object at 0x7f3f386229d0>, 'kernel_init': <keras.initializers.RandomNormal object at 0x7f3f386226d0>, 'epochs': 1000, 'batch_size': 8}\n",
      "0.963740 (0.011036) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f386229d0>, 'kernel_init': <keras.initializers.VarianceScaling object at 0x7f3f386221d0>, 'epochs': 1000, 'batch_size': 16}\n",
      "0.948473 (0.011592) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f386229d0>, 'kernel_init': <keras.initializers.Orthogonal object at 0x7f3f38622150>, 'epochs': 750, 'batch_size': 8}\n",
      "0.973282 (0.007087) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f386229d0>, 'kernel_init': <keras.initializers.RandomNormal object at 0x7f3f386226d0>, 'epochs': 1000, 'batch_size': 8}\n",
      "0.961832 (0.010610) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f7d41f110>, 'kernel_init': <keras.initializers.VarianceScaling object at 0x7f3f386221d0>, 'epochs': 750, 'batch_size': 8}\n",
      "0.967557 (0.015475) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f7d41f110>, 'kernel_init': <keras.initializers.RandomNormal object at 0x7f3f386226d0>, 'epochs': 1000, 'batch_size': 16}\n",
      "0.961832 (0.015952) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f7d41f110>, 'kernel_init': <keras.initializers.Orthogonal object at 0x7f3f38622150>, 'epochs': 1000, 'batch_size': 8}\n",
      "0.959924 (0.018421) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f7d41f110>, 'kernel_init': <keras.initializers.RandomNormal object at 0x7f3f386226d0>, 'epochs': 750, 'batch_size': 8}\n",
      "0.969466 (0.012687) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f38622210>, 'kernel_init': <keras.initializers.VarianceScaling object at 0x7f3f386221d0>, 'epochs': 500, 'batch_size': 16}\n",
      "0.969466 (0.014003) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f7d41f110>, 'kernel_init': <keras.initializers.VarianceScaling object at 0x7f3f386221d0>, 'epochs': 1000, 'batch_size': 32}\n",
      "0.971374 (0.014739) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f386229d0>, 'kernel_init': <keras.initializers.VarianceScaling object at 0x7f3f386221d0>, 'epochs': 500, 'batch_size': 32}\n",
      "0.973282 (0.009305) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f38622210>, 'kernel_init': <keras.initializers.RandomNormal object at 0x7f3f386226d0>, 'epochs': 750, 'batch_size': 16}\n",
      "0.965649 (0.012871) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f38622210>, 'kernel_init': <keras.initializers.Orthogonal object at 0x7f3f38622150>, 'epochs': 750, 'batch_size': 16}\n",
      "0.963740 (0.016458) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f7d41f110>, 'kernel_init': <keras.initializers.Orthogonal object at 0x7f3f38622150>, 'epochs': 500, 'batch_size': 16}\n",
      "0.963740 (0.003851) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f7d41f110>, 'kernel_init': <keras.initializers.RandomNormal object at 0x7f3f386226d0>, 'epochs': 750, 'batch_size': 16}\n",
      "0.965649 (0.012905) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f7d41f110>, 'kernel_init': <keras.initializers.VarianceScaling object at 0x7f3f386221d0>, 'epochs': 750, 'batch_size': 16}\n",
      "0.956107 (0.015512) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f38622210>, 'kernel_init': <keras.initializers.VarianceScaling object at 0x7f3f386221d0>, 'epochs': 750, 'batch_size': 8}\n",
      "0.967557 (0.019618) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f7d41f110>, 'kernel_init': <keras.initializers.RandomNormal object at 0x7f3f386226d0>, 'epochs': 1000, 'batch_size': 32}\n",
      "0.963740 (0.007154) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f7d41f110>, 'kernel_init': <keras.initializers.VarianceScaling object at 0x7f3f386221d0>, 'epochs': 750, 'batch_size': 32}\n",
      "0.956107 (0.015574) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f386229d0>, 'kernel_init': <keras.initializers.Orthogonal object at 0x7f3f38622150>, 'epochs': 750, 'batch_size': 16}\n",
      "0.954198 (0.015173) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f38622210>, 'kernel_init': <keras.initializers.VarianceScaling object at 0x7f3f386221d0>, 'epochs': 1000, 'batch_size': 16}\n",
      "0.952290 (0.019067) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f38622210>, 'kernel_init': <keras.initializers.Orthogonal object at 0x7f3f38622150>, 'epochs': 500, 'batch_size': 8}\n",
      "0.944656 (0.028164) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f386229d0>, 'kernel_init': <keras.initializers.Orthogonal object at 0x7f3f38622150>, 'epochs': 1000, 'batch_size': 8}\n",
      "0.971374 (0.012022) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f386229d0>, 'kernel_init': <keras.initializers.RandomNormal object at 0x7f3f386226d0>, 'epochs': 750, 'batch_size': 32}\n",
      "0.956107 (0.018699) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f7d41f110>, 'kernel_init': <keras.initializers.Orthogonal object at 0x7f3f38622150>, 'epochs': 750, 'batch_size': 32}\n",
      "0.961832 (0.016001) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f7d41f110>, 'kernel_init': <keras.initializers.Orthogonal object at 0x7f3f38622150>, 'epochs': 500, 'batch_size': 32}\n",
      "0.963740 (0.022885) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f7d41f110>, 'kernel_init': <keras.initializers.Orthogonal object at 0x7f3f38622150>, 'epochs': 500, 'batch_size': 8}\n",
      "0.967557 (0.015447) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f38622210>, 'kernel_init': <keras.initializers.RandomNormal object at 0x7f3f386226d0>, 'epochs': 750, 'batch_size': 32}\n",
      "0.969466 (0.016368) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f386229d0>, 'kernel_init': <keras.initializers.VarianceScaling object at 0x7f3f386221d0>, 'epochs': 500, 'batch_size': 8}\n",
      "0.963740 (0.031545) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f7d41f110>, 'kernel_init': <keras.initializers.VarianceScaling object at 0x7f3f386221d0>, 'epochs': 1000, 'batch_size': 8}\n",
      "0.969466 (0.013972) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f386229d0>, 'kernel_init': <keras.initializers.RandomNormal object at 0x7f3f386226d0>, 'epochs': 500, 'batch_size': 16}\n",
      "0.967557 (0.012914) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f386229d0>, 'kernel_init': <keras.initializers.Orthogonal object at 0x7f3f38622150>, 'epochs': 500, 'batch_size': 16}\n",
      "0.965649 (0.021386) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f7d41f110>, 'kernel_init': <keras.initializers.VarianceScaling object at 0x7f3f386221d0>, 'epochs': 1000, 'batch_size': 16}\n",
      "0.967557 (0.015475) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f38622210>, 'kernel_init': <keras.initializers.VarianceScaling object at 0x7f3f386221d0>, 'epochs': 750, 'batch_size': 16}\n",
      "0.963740 (0.013977) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f7d41f110>, 'kernel_init': <keras.initializers.Orthogonal object at 0x7f3f38622150>, 'epochs': 1000, 'batch_size': 32}\n",
      "0.961832 (0.013437) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f386229d0>, 'kernel_init': <keras.initializers.VarianceScaling object at 0x7f3f386221d0>, 'epochs': 1000, 'batch_size': 32}\n",
      "0.967557 (0.011474) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f38622210>, 'kernel_init': <keras.initializers.Orthogonal object at 0x7f3f38622150>, 'epochs': 1000, 'batch_size': 8}\n",
      "0.965649 (0.015439) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f386229d0>, 'kernel_init': <keras.initializers.RandomNormal object at 0x7f3f386226d0>, 'epochs': 750, 'batch_size': 8}\n",
      "0.956107 (0.016595) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f38622210>, 'kernel_init': <keras.initializers.RandomNormal object at 0x7f3f386226d0>, 'epochs': 750, 'batch_size': 8}\n",
      "0.959924 (0.007115) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f386229d0>, 'kernel_init': <keras.initializers.Orthogonal object at 0x7f3f38622150>, 'epochs': 500, 'batch_size': 8}\n",
      "0.958015 (0.025951) with: {'optimizer': <keras.optimizers.Adam object at 0x7f3f7d41f110>, 'kernel_init': <keras.initializers.VarianceScaling object at 0x7f3f386221d0>, 'epochs': 500, 'batch_size': 16}\n",
      "Total time for performing grid-search of the best parameters: 0:42:27.262915\n"
     ]
    }
   ],
   "source": [
    "startTimeModule = datetime.now()\n",
    "\n",
    "# Create model\n",
    "grid_model = KerasClassifier(build_fn=create_customized_model, verbose=0)\n",
    "\n",
    "# Perform grid search using different epochs, batch sizes, and optimizers\n",
    "optz_1 = K.optimizers.Adam(learning_rate=0.001)\n",
    "optz_2 = K.optimizers.Adam(learning_rate=0.005)\n",
    "optz_3 = K.optimizers.Adam(learning_rate=0.009)\n",
    "optimizer_grid = [optz_1, optz_2, optz_3]\n",
    "init_1 = K.initializers.RandomNormal(seed=seedNum)\n",
    "init_2 = K.initializers.glorot_normal(seed=seedNum)\n",
    "init_3 = K.initializers.Orthogonal(seed=seedNum)\n",
    "init_grid = [init_1, init_2, init_3]\n",
    "epoch_grid = [500, 750, 1000]\n",
    "batch_grid = [8, 16, 32]\n",
    "param_grid = dict(optimizer=optimizer_grid, kernel_init=init_grid, epochs=epoch_grid, batch_size=batch_grid)\n",
    "# grid = GridSearchCV(estimator=grid_model, param_grid=param_grid, cv=n_folds, n_jobs=n_jobs, verbose=3)\n",
    "n_iter = int(len(optimizer_grid) * len(init_grid) * len(epoch_grid) * len(batch_grid) * 0.5)\n",
    "grid = RandomizedSearchCV(estimator=grid_model, param_distributions=param_grid, n_iter=n_iter, cv=n_folds, n_jobs=n_jobs, verbose=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "print('Total time for performing grid-search of the best parameters:', (datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimizer = grid_result.best_params_[\"optimizer\"]\n",
    "best_kernel_init = grid_result.best_params_[\"kernel_init\"]\n",
    "best_epoch = grid_result.best_params_[\"epochs\"]\n",
    "best_batch = grid_result.best_params_[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 4 Optimize Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5. Finalize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 5 Finalize Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forming the final model using: optimizer=<keras.optimizers.Adam object at 0x7f3f386229d0>, kernel=<keras.initializers.RandomNormal object at 0x7f3f386226d0>, epochs=1000, batch_size=8\n",
      "Epoch 1/1000\n",
      "Executing op __inference_keras_scratch_graph_472836 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "524/524 [==============================] - 1s 954us/step - loss: 0.5765 - accuracy: 0.6508\n",
      "Epoch 2/1000\n",
      "524/524 [==============================] - 0s 354us/step - loss: 0.3818 - accuracy: 0.9332\n",
      "Epoch 3/1000\n",
      "524/524 [==============================] - 0s 346us/step - loss: 0.2934 - accuracy: 0.9408\n",
      "Epoch 4/1000\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.2538 - accuracy: 0.9408\n",
      "Epoch 5/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.2292 - accuracy: 0.9427\n",
      "Epoch 6/1000\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.2106 - accuracy: 0.9485\n",
      "Epoch 7/1000\n",
      "524/524 [==============================] - 0s 408us/step - loss: 0.1987 - accuracy: 0.9447\n",
      "Epoch 8/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.1840 - accuracy: 0.9542\n",
      "Epoch 9/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.1773 - accuracy: 0.9504\n",
      "Epoch 10/1000\n",
      "524/524 [==============================] - 0s 309us/step - loss: 0.1706 - accuracy: 0.9580\n",
      "Epoch 11/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.1617 - accuracy: 0.9561\n",
      "Epoch 12/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.1559 - accuracy: 0.9561\n",
      "Epoch 13/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.1514 - accuracy: 0.9542\n",
      "Epoch 14/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.1471 - accuracy: 0.9599\n",
      "Epoch 15/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.1428 - accuracy: 0.9561\n",
      "Epoch 16/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.1382 - accuracy: 0.9561\n",
      "Epoch 17/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.1344 - accuracy: 0.9580\n",
      "Epoch 18/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.1335 - accuracy: 0.9580\n",
      "Epoch 19/1000\n",
      "524/524 [==============================] - 0s 356us/step - loss: 0.1277 - accuracy: 0.9676\n",
      "Epoch 20/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.1252 - accuracy: 0.9637\n",
      "Epoch 21/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.1222 - accuracy: 0.9656\n",
      "Epoch 22/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.1197 - accuracy: 0.9637\n",
      "Epoch 23/1000\n",
      "524/524 [==============================] - 0s 315us/step - loss: 0.1169 - accuracy: 0.9676\n",
      "Epoch 24/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.1151 - accuracy: 0.9695\n",
      "Epoch 25/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.1126 - accuracy: 0.9714\n",
      "Epoch 26/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.1110 - accuracy: 0.9733\n",
      "Epoch 27/1000\n",
      "524/524 [==============================] - 0s 309us/step - loss: 0.1092 - accuracy: 0.9714\n",
      "Epoch 28/1000\n",
      "524/524 [==============================] - 0s 300us/step - loss: 0.1075 - accuracy: 0.9695\n",
      "Epoch 29/1000\n",
      "524/524 [==============================] - 0s 316us/step - loss: 0.1048 - accuracy: 0.9714\n",
      "Epoch 30/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.1037 - accuracy: 0.9714\n",
      "Epoch 31/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.1033 - accuracy: 0.9733\n",
      "Epoch 32/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.1003 - accuracy: 0.9714\n",
      "Epoch 33/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0998 - accuracy: 0.9714\n",
      "Epoch 34/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0972 - accuracy: 0.9714\n",
      "Epoch 35/1000\n",
      "524/524 [==============================] - 0s 339us/step - loss: 0.0982 - accuracy: 0.9733\n",
      "Epoch 36/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0963 - accuracy: 0.9733\n",
      "Epoch 37/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0941 - accuracy: 0.9714\n",
      "Epoch 38/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0936 - accuracy: 0.9733\n",
      "Epoch 39/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0920 - accuracy: 0.9714\n",
      "Epoch 40/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0909 - accuracy: 0.9733\n",
      "Epoch 41/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0899 - accuracy: 0.9733\n",
      "Epoch 42/1000\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.0887 - accuracy: 0.9714\n",
      "Epoch 43/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0878 - accuracy: 0.9752\n",
      "Epoch 44/1000\n",
      "524/524 [==============================] - 0s 346us/step - loss: 0.0875 - accuracy: 0.9733\n",
      "Epoch 45/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0864 - accuracy: 0.9733\n",
      "Epoch 46/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0860 - accuracy: 0.9733\n",
      "Epoch 47/1000\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.0847 - accuracy: 0.9714\n",
      "Epoch 48/1000\n",
      "524/524 [==============================] - 0s 344us/step - loss: 0.0846 - accuracy: 0.9771\n",
      "Epoch 49/1000\n",
      "524/524 [==============================] - 0s 361us/step - loss: 0.0848 - accuracy: 0.9752\n",
      "Epoch 50/1000\n",
      "524/524 [==============================] - 0s 318us/step - loss: 0.0816 - accuracy: 0.9771\n",
      "Epoch 51/1000\n",
      "524/524 [==============================] - 0s 342us/step - loss: 0.0815 - accuracy: 0.9752\n",
      "Epoch 52/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0808 - accuracy: 0.9771\n",
      "Epoch 53/1000\n",
      "524/524 [==============================] - 0s 362us/step - loss: 0.0799 - accuracy: 0.9771\n",
      "Epoch 54/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0789 - accuracy: 0.9752\n",
      "Epoch 55/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0812 - accuracy: 0.9714\n",
      "Epoch 56/1000\n",
      "524/524 [==============================] - 0s 316us/step - loss: 0.0780 - accuracy: 0.9752\n",
      "Epoch 57/1000\n",
      "524/524 [==============================] - 0s 318us/step - loss: 0.0766 - accuracy: 0.9752\n",
      "Epoch 58/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0790 - accuracy: 0.9790\n",
      "Epoch 59/1000\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.0769 - accuracy: 0.9752\n",
      "Epoch 60/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0750 - accuracy: 0.9752\n",
      "Epoch 61/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0749 - accuracy: 0.9771\n",
      "Epoch 62/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0742 - accuracy: 0.9752\n",
      "Epoch 63/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0741 - accuracy: 0.9752\n",
      "Epoch 64/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0733 - accuracy: 0.9790\n",
      "Epoch 65/1000\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.0735 - accuracy: 0.9752\n",
      "Epoch 66/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0735 - accuracy: 0.9752\n",
      "Epoch 67/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0725 - accuracy: 0.9771\n",
      "Epoch 68/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0709 - accuracy: 0.9752\n",
      "Epoch 69/1000\n",
      "524/524 [==============================] - 0s 352us/step - loss: 0.0714 - accuracy: 0.9771\n",
      "Epoch 70/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0713 - accuracy: 0.9771\n",
      "Epoch 71/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0700 - accuracy: 0.9771\n",
      "Epoch 72/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0704 - accuracy: 0.9752\n",
      "Epoch 73/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0694 - accuracy: 0.9809\n",
      "Epoch 74/1000\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.0690 - accuracy: 0.9771\n",
      "Epoch 75/1000\n",
      "524/524 [==============================] - 0s 318us/step - loss: 0.0689 - accuracy: 0.9771\n",
      "Epoch 76/1000\n",
      "524/524 [==============================] - 0s 354us/step - loss: 0.0691 - accuracy: 0.9790\n",
      "Epoch 77/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0675 - accuracy: 0.9771\n",
      "Epoch 78/1000\n",
      "524/524 [==============================] - 0s 354us/step - loss: 0.0677 - accuracy: 0.9771\n",
      "Epoch 79/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0678 - accuracy: 0.9771\n",
      "Epoch 80/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0668 - accuracy: 0.9752\n",
      "Epoch 81/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0671 - accuracy: 0.9771\n",
      "Epoch 82/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0665 - accuracy: 0.9771\n",
      "Epoch 83/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0660 - accuracy: 0.9771\n",
      "Epoch 84/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0662 - accuracy: 0.9771\n",
      "Epoch 85/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0659 - accuracy: 0.9771\n",
      "Epoch 86/1000\n",
      "524/524 [==============================] - 0s 302us/step - loss: 0.0656 - accuracy: 0.9790\n",
      "Epoch 87/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0657 - accuracy: 0.9752\n",
      "Epoch 88/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0647 - accuracy: 0.9771\n",
      "Epoch 89/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0646 - accuracy: 0.9771\n",
      "Epoch 90/1000\n",
      "524/524 [==============================] - 0s 345us/step - loss: 0.0641 - accuracy: 0.9771\n",
      "Epoch 91/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0645 - accuracy: 0.9790\n",
      "Epoch 92/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0643 - accuracy: 0.9752\n",
      "Epoch 93/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0648 - accuracy: 0.9771\n",
      "Epoch 94/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0629 - accuracy: 0.9752\n",
      "Epoch 95/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0637 - accuracy: 0.9809\n",
      "Epoch 96/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0639 - accuracy: 0.9771\n",
      "Epoch 97/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0626 - accuracy: 0.9809\n",
      "Epoch 98/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0620 - accuracy: 0.9771\n",
      "Epoch 99/1000\n",
      "524/524 [==============================] - 0s 352us/step - loss: 0.0620 - accuracy: 0.9809\n",
      "Epoch 100/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0624 - accuracy: 0.9752\n",
      "Epoch 101/1000\n",
      "524/524 [==============================] - 0s 340us/step - loss: 0.0616 - accuracy: 0.9752\n",
      "Epoch 102/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0621 - accuracy: 0.9790\n",
      "Epoch 103/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0622 - accuracy: 0.9752\n",
      "Epoch 104/1000\n",
      "524/524 [==============================] - 0s 314us/step - loss: 0.0616 - accuracy: 0.9752\n",
      "Epoch 105/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0610 - accuracy: 0.9809\n",
      "Epoch 106/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0623 - accuracy: 0.9771\n",
      "Epoch 107/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0615 - accuracy: 0.9752\n",
      "Epoch 108/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0615 - accuracy: 0.9771\n",
      "Epoch 109/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0617 - accuracy: 0.9790\n",
      "Epoch 110/1000\n",
      "524/524 [==============================] - 0s 344us/step - loss: 0.0611 - accuracy: 0.9771\n",
      "Epoch 111/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0601 - accuracy: 0.9771\n",
      "Epoch 112/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0607 - accuracy: 0.9790\n",
      "Epoch 113/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0611 - accuracy: 0.9790\n",
      "Epoch 114/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0632 - accuracy: 0.9809\n",
      "Epoch 115/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0600 - accuracy: 0.9790\n",
      "Epoch 116/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0610 - accuracy: 0.9790\n",
      "Epoch 117/1000\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.0599 - accuracy: 0.9790\n",
      "Epoch 118/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0615 - accuracy: 0.9790\n",
      "Epoch 119/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0607 - accuracy: 0.9771\n",
      "Epoch 120/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0618 - accuracy: 0.9790\n",
      "Epoch 121/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0604 - accuracy: 0.9809\n",
      "Epoch 122/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0582 - accuracy: 0.9790\n",
      "Epoch 123/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0599 - accuracy: 0.9809\n",
      "Epoch 124/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0585 - accuracy: 0.9771\n",
      "Epoch 125/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0589 - accuracy: 0.9809\n",
      "Epoch 126/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0590 - accuracy: 0.9790\n",
      "Epoch 127/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0582 - accuracy: 0.9771\n",
      "Epoch 128/1000\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.0582 - accuracy: 0.9809\n",
      "Epoch 129/1000\n",
      "524/524 [==============================] - 0s 342us/step - loss: 0.0576 - accuracy: 0.9771\n",
      "Epoch 130/1000\n",
      "524/524 [==============================] - 0s 349us/step - loss: 0.0578 - accuracy: 0.9790\n",
      "Epoch 131/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0583 - accuracy: 0.9771\n",
      "Epoch 132/1000\n",
      "524/524 [==============================] - 0s 348us/step - loss: 0.0581 - accuracy: 0.9771\n",
      "Epoch 133/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0586 - accuracy: 0.9790\n",
      "Epoch 134/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0576 - accuracy: 0.9790\n",
      "Epoch 135/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0597 - accuracy: 0.9771\n",
      "Epoch 136/1000\n",
      "524/524 [==============================] - 0s 311us/step - loss: 0.0579 - accuracy: 0.9771\n",
      "Epoch 137/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0574 - accuracy: 0.9790\n",
      "Epoch 138/1000\n",
      "524/524 [==============================] - 0s 351us/step - loss: 0.0589 - accuracy: 0.9790\n",
      "Epoch 139/1000\n",
      "524/524 [==============================] - 0s 345us/step - loss: 0.0586 - accuracy: 0.9809\n",
      "Epoch 140/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0579 - accuracy: 0.9790\n",
      "Epoch 141/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0574 - accuracy: 0.9771\n",
      "Epoch 142/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0574 - accuracy: 0.9790\n",
      "Epoch 143/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0565 - accuracy: 0.9809\n",
      "Epoch 144/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0568 - accuracy: 0.9771\n",
      "Epoch 145/1000\n",
      "524/524 [==============================] - 0s 342us/step - loss: 0.0562 - accuracy: 0.9771\n",
      "Epoch 146/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0587 - accuracy: 0.9828\n",
      "Epoch 147/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0582 - accuracy: 0.9809\n",
      "Epoch 148/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0585 - accuracy: 0.9771\n",
      "Epoch 149/1000\n",
      "524/524 [==============================] - 0s 311us/step - loss: 0.0598 - accuracy: 0.9752\n",
      "Epoch 150/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0570 - accuracy: 0.9771\n",
      "Epoch 151/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0570 - accuracy: 0.9790\n",
      "Epoch 152/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0563 - accuracy: 0.9790\n",
      "Epoch 153/1000\n",
      "524/524 [==============================] - 0s 372us/step - loss: 0.0570 - accuracy: 0.9809\n",
      "Epoch 154/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0576 - accuracy: 0.9771\n",
      "Epoch 155/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0563 - accuracy: 0.9809\n",
      "Epoch 156/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0563 - accuracy: 0.9790\n",
      "Epoch 157/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0564 - accuracy: 0.9771\n",
      "Epoch 158/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0559 - accuracy: 0.9771\n",
      "Epoch 159/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0562 - accuracy: 0.9771\n",
      "Epoch 160/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0592 - accuracy: 0.9771\n",
      "Epoch 161/1000\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.0574 - accuracy: 0.9790\n",
      "Epoch 162/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0572 - accuracy: 0.9790\n",
      "Epoch 163/1000\n",
      "524/524 [==============================] - 0s 340us/step - loss: 0.0556 - accuracy: 0.9752\n",
      "Epoch 164/1000\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.0558 - accuracy: 0.9790\n",
      "Epoch 165/1000\n",
      "524/524 [==============================] - 0s 316us/step - loss: 0.0558 - accuracy: 0.9771\n",
      "Epoch 166/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0566 - accuracy: 0.9790\n",
      "Epoch 167/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0554 - accuracy: 0.9752\n",
      "Epoch 168/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0562 - accuracy: 0.9809\n",
      "Epoch 169/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0555 - accuracy: 0.9771\n",
      "Epoch 170/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0579 - accuracy: 0.9790\n",
      "Epoch 171/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0549 - accuracy: 0.9771\n",
      "Epoch 172/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0563 - accuracy: 0.9790\n",
      "Epoch 173/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0560 - accuracy: 0.9771\n",
      "Epoch 174/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0559 - accuracy: 0.9790\n",
      "Epoch 175/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0559 - accuracy: 0.9790\n",
      "Epoch 176/1000\n",
      "524/524 [==============================] - 0s 339us/step - loss: 0.0560 - accuracy: 0.9790\n",
      "Epoch 177/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0550 - accuracy: 0.9809\n",
      "Epoch 178/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0553 - accuracy: 0.9790\n",
      "Epoch 179/1000\n",
      "524/524 [==============================] - 0s 348us/step - loss: 0.0586 - accuracy: 0.9809\n",
      "Epoch 180/1000\n",
      "524/524 [==============================] - 0s 300us/step - loss: 0.0553 - accuracy: 0.9809\n",
      "Epoch 181/1000\n",
      "524/524 [==============================] - 0s 318us/step - loss: 0.0554 - accuracy: 0.9790\n",
      "Epoch 182/1000\n",
      "524/524 [==============================] - 0s 298us/step - loss: 0.0553 - accuracy: 0.9771\n",
      "Epoch 183/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0550 - accuracy: 0.9752\n",
      "Epoch 184/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0552 - accuracy: 0.9771\n",
      "Epoch 185/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0552 - accuracy: 0.9752\n",
      "Epoch 186/1000\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.0551 - accuracy: 0.9771\n",
      "Epoch 187/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0556 - accuracy: 0.9790\n",
      "Epoch 188/1000\n",
      "524/524 [==============================] - 0s 342us/step - loss: 0.0548 - accuracy: 0.9790\n",
      "Epoch 189/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0550 - accuracy: 0.9809\n",
      "Epoch 190/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0547 - accuracy: 0.9790\n",
      "Epoch 191/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0540 - accuracy: 0.9771\n",
      "Epoch 192/1000\n",
      "524/524 [==============================] - 0s 340us/step - loss: 0.0552 - accuracy: 0.9809\n",
      "Epoch 193/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0554 - accuracy: 0.9752\n",
      "Epoch 194/1000\n",
      "524/524 [==============================] - 0s 344us/step - loss: 0.0558 - accuracy: 0.9809\n",
      "Epoch 195/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0546 - accuracy: 0.9809\n",
      "Epoch 196/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0542 - accuracy: 0.9771\n",
      "Epoch 197/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0544 - accuracy: 0.9790\n",
      "Epoch 198/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0557 - accuracy: 0.9790\n",
      "Epoch 199/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0544 - accuracy: 0.9790\n",
      "Epoch 200/1000\n",
      "524/524 [==============================] - 0s 343us/step - loss: 0.0545 - accuracy: 0.9790\n",
      "Epoch 201/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0573 - accuracy: 0.9790\n",
      "Epoch 202/1000\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.0546 - accuracy: 0.9771\n",
      "Epoch 203/1000\n",
      "524/524 [==============================] - 0s 318us/step - loss: 0.0546 - accuracy: 0.9809\n",
      "Epoch 204/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0541 - accuracy: 0.9790\n",
      "Epoch 205/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0554 - accuracy: 0.9809\n",
      "Epoch 206/1000\n",
      "524/524 [==============================] - 0s 339us/step - loss: 0.0556 - accuracy: 0.9790\n",
      "Epoch 207/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0541 - accuracy: 0.9790\n",
      "Epoch 208/1000\n",
      "524/524 [==============================] - 0s 345us/step - loss: 0.0566 - accuracy: 0.9752\n",
      "Epoch 209/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0542 - accuracy: 0.9809\n",
      "Epoch 210/1000\n",
      "524/524 [==============================] - 0s 339us/step - loss: 0.0547 - accuracy: 0.9790\n",
      "Epoch 211/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0544 - accuracy: 0.9771\n",
      "Epoch 212/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0549 - accuracy: 0.9809\n",
      "Epoch 213/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0556 - accuracy: 0.9771\n",
      "Epoch 214/1000\n",
      "524/524 [==============================] - 0s 354us/step - loss: 0.0551 - accuracy: 0.9790\n",
      "Epoch 215/1000\n",
      "524/524 [==============================] - 0s 314us/step - loss: 0.0539 - accuracy: 0.9771\n",
      "Epoch 216/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0540 - accuracy: 0.9771\n",
      "Epoch 217/1000\n",
      "524/524 [==============================] - 0s 343us/step - loss: 0.0548 - accuracy: 0.9733\n",
      "Epoch 218/1000\n",
      "524/524 [==============================] - 0s 355us/step - loss: 0.0572 - accuracy: 0.9790\n",
      "Epoch 219/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0570 - accuracy: 0.9809\n",
      "Epoch 220/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0542 - accuracy: 0.9771\n",
      "Epoch 221/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0545 - accuracy: 0.9790\n",
      "Epoch 222/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0548 - accuracy: 0.9771\n",
      "Epoch 223/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0555 - accuracy: 0.9771\n",
      "Epoch 224/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0557 - accuracy: 0.9752\n",
      "Epoch 225/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0539 - accuracy: 0.9771\n",
      "Epoch 226/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0538 - accuracy: 0.9790\n",
      "Epoch 227/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0551 - accuracy: 0.9752\n",
      "Epoch 228/1000\n",
      "524/524 [==============================] - 0s 340us/step - loss: 0.0551 - accuracy: 0.9809\n",
      "Epoch 229/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0542 - accuracy: 0.9790\n",
      "Epoch 230/1000\n",
      "524/524 [==============================] - 0s 342us/step - loss: 0.0543 - accuracy: 0.9809\n",
      "Epoch 231/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0549 - accuracy: 0.9790\n",
      "Epoch 232/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0561 - accuracy: 0.9752\n",
      "Epoch 233/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0541 - accuracy: 0.9828\n",
      "Epoch 234/1000\n",
      "524/524 [==============================] - 0s 339us/step - loss: 0.0560 - accuracy: 0.9790\n",
      "Epoch 235/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0545 - accuracy: 0.9790\n",
      "Epoch 236/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0554 - accuracy: 0.9771\n",
      "Epoch 237/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0550 - accuracy: 0.9790\n",
      "Epoch 238/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0548 - accuracy: 0.9828\n",
      "Epoch 239/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0544 - accuracy: 0.9771\n",
      "Epoch 240/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0569 - accuracy: 0.9752\n",
      "Epoch 241/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0536 - accuracy: 0.9752\n",
      "Epoch 242/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0535 - accuracy: 0.9771\n",
      "Epoch 243/1000\n",
      "524/524 [==============================] - 0s 345us/step - loss: 0.0568 - accuracy: 0.9790\n",
      "Epoch 244/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0537 - accuracy: 0.9790\n",
      "Epoch 245/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0539 - accuracy: 0.9790\n",
      "Epoch 246/1000\n",
      "524/524 [==============================] - 0s 363us/step - loss: 0.0541 - accuracy: 0.9790\n",
      "Epoch 247/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0550 - accuracy: 0.9828\n",
      "Epoch 248/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0539 - accuracy: 0.9809\n",
      "Epoch 249/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0546 - accuracy: 0.9790\n",
      "Epoch 250/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0557 - accuracy: 0.9771\n",
      "Epoch 251/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0556 - accuracy: 0.9771\n",
      "Epoch 252/1000\n",
      "524/524 [==============================] - 0s 318us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 253/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0540 - accuracy: 0.9809\n",
      "Epoch 254/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0538 - accuracy: 0.9790\n",
      "Epoch 255/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0567 - accuracy: 0.9771\n",
      "Epoch 256/1000\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.0551 - accuracy: 0.9790\n",
      "Epoch 257/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0548 - accuracy: 0.9771\n",
      "Epoch 258/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0585 - accuracy: 0.9752\n",
      "Epoch 259/1000\n",
      "524/524 [==============================] - 0s 316us/step - loss: 0.0543 - accuracy: 0.9790\n",
      "Epoch 260/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0540 - accuracy: 0.9771\n",
      "Epoch 261/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0541 - accuracy: 0.9771\n",
      "Epoch 262/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0539 - accuracy: 0.9790\n",
      "Epoch 263/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0553 - accuracy: 0.9771\n",
      "Epoch 264/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0543 - accuracy: 0.9771\n",
      "Epoch 265/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0537 - accuracy: 0.9790\n",
      "Epoch 266/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0555 - accuracy: 0.9809\n",
      "Epoch 267/1000\n",
      "524/524 [==============================] - 0s 308us/step - loss: 0.0530 - accuracy: 0.9771\n",
      "Epoch 268/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0531 - accuracy: 0.9790\n",
      "Epoch 269/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0542 - accuracy: 0.9790\n",
      "Epoch 270/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0553 - accuracy: 0.9790\n",
      "Epoch 271/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0534 - accuracy: 0.9790\n",
      "Epoch 272/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0541 - accuracy: 0.9771\n",
      "Epoch 273/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0531 - accuracy: 0.9790\n",
      "Epoch 274/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0562 - accuracy: 0.9771\n",
      "Epoch 275/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0533 - accuracy: 0.9771\n",
      "Epoch 276/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0566 - accuracy: 0.9752\n",
      "Epoch 277/1000\n",
      "524/524 [==============================] - 0s 368us/step - loss: 0.0537 - accuracy: 0.9752\n",
      "Epoch 278/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0535 - accuracy: 0.9752\n",
      "Epoch 279/1000\n",
      "524/524 [==============================] - 0s 312us/step - loss: 0.0528 - accuracy: 0.9790\n",
      "Epoch 280/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0548 - accuracy: 0.9771\n",
      "Epoch 281/1000\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.0540 - accuracy: 0.9790\n",
      "Epoch 282/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0545 - accuracy: 0.9790\n",
      "Epoch 283/1000\n",
      "524/524 [==============================] - 0s 340us/step - loss: 0.0569 - accuracy: 0.9771\n",
      "Epoch 284/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0549 - accuracy: 0.9771\n",
      "Epoch 285/1000\n",
      "524/524 [==============================] - 0s 297us/step - loss: 0.0538 - accuracy: 0.9809\n",
      "Epoch 286/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0537 - accuracy: 0.9752\n",
      "Epoch 287/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0533 - accuracy: 0.9790\n",
      "Epoch 288/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0555 - accuracy: 0.9790\n",
      "Epoch 289/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0531 - accuracy: 0.9790\n",
      "Epoch 290/1000\n",
      "524/524 [==============================] - 0s 343us/step - loss: 0.0538 - accuracy: 0.9752\n",
      "Epoch 291/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0548 - accuracy: 0.9771\n",
      "Epoch 292/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0543 - accuracy: 0.9771\n",
      "Epoch 293/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0543 - accuracy: 0.9771\n",
      "Epoch 294/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0541 - accuracy: 0.9771\n",
      "Epoch 295/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0551 - accuracy: 0.9809\n",
      "Epoch 296/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0535 - accuracy: 0.9752\n",
      "Epoch 297/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0560 - accuracy: 0.9790\n",
      "Epoch 298/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0546 - accuracy: 0.9752\n",
      "Epoch 299/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0535 - accuracy: 0.9790\n",
      "Epoch 300/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0552 - accuracy: 0.9752\n",
      "Epoch 301/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0533 - accuracy: 0.9790\n",
      "Epoch 302/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0530 - accuracy: 0.9790\n",
      "Epoch 303/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0547 - accuracy: 0.9790\n",
      "Epoch 304/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0534 - accuracy: 0.9752\n",
      "Epoch 305/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0536 - accuracy: 0.9790\n",
      "Epoch 306/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 307/1000\n",
      "524/524 [==============================] - 0s 310us/step - loss: 0.0528 - accuracy: 0.9790\n",
      "Epoch 308/1000\n",
      "524/524 [==============================] - 0s 318us/step - loss: 0.0537 - accuracy: 0.9771\n",
      "Epoch 309/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0540 - accuracy: 0.9771\n",
      "Epoch 310/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0535 - accuracy: 0.9752\n",
      "Epoch 311/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0545 - accuracy: 0.9809\n",
      "Epoch 312/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0536 - accuracy: 0.9752\n",
      "Epoch 313/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0538 - accuracy: 0.9752\n",
      "Epoch 314/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0527 - accuracy: 0.9771\n",
      "Epoch 315/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0540 - accuracy: 0.9771\n",
      "Epoch 316/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0538 - accuracy: 0.9771\n",
      "Epoch 317/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0531 - accuracy: 0.9771\n",
      "Epoch 318/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0559 - accuracy: 0.9790\n",
      "Epoch 319/1000\n",
      "524/524 [==============================] - 0s 295us/step - loss: 0.0532 - accuracy: 0.9809\n",
      "Epoch 320/1000\n",
      "524/524 [==============================] - 0s 344us/step - loss: 0.0546 - accuracy: 0.9790\n",
      "Epoch 321/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0568 - accuracy: 0.9733\n",
      "Epoch 322/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0553 - accuracy: 0.9790\n",
      "Epoch 323/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0532 - accuracy: 0.9790\n",
      "Epoch 324/1000\n",
      "524/524 [==============================] - 0s 339us/step - loss: 0.0535 - accuracy: 0.9790\n",
      "Epoch 325/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 326/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0536 - accuracy: 0.9771\n",
      "Epoch 327/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0557 - accuracy: 0.9752\n",
      "Epoch 328/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0557 - accuracy: 0.9771\n",
      "Epoch 329/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0533 - accuracy: 0.9771\n",
      "Epoch 330/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0545 - accuracy: 0.9790\n",
      "Epoch 331/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0536 - accuracy: 0.9771\n",
      "Epoch 332/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0534 - accuracy: 0.9790\n",
      "Epoch 333/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0526 - accuracy: 0.9771\n",
      "Epoch 334/1000\n",
      "524/524 [==============================] - 0s 349us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 335/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0539 - accuracy: 0.9790\n",
      "Epoch 336/1000\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.0535 - accuracy: 0.9809\n",
      "Epoch 337/1000\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.0539 - accuracy: 0.9790\n",
      "Epoch 338/1000\n",
      "524/524 [==============================] - 0s 350us/step - loss: 0.0527 - accuracy: 0.9790\n",
      "Epoch 339/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0542 - accuracy: 0.9790\n",
      "Epoch 340/1000\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 341/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0529 - accuracy: 0.9809\n",
      "Epoch 342/1000\n",
      "524/524 [==============================] - 0s 349us/step - loss: 0.0540 - accuracy: 0.9771\n",
      "Epoch 343/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0535 - accuracy: 0.9809\n",
      "Epoch 344/1000\n",
      "524/524 [==============================] - 0s 346us/step - loss: 0.0535 - accuracy: 0.9752\n",
      "Epoch 345/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0541 - accuracy: 0.9790\n",
      "Epoch 346/1000\n",
      "524/524 [==============================] - 0s 348us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 347/1000\n",
      "524/524 [==============================] - 0s 339us/step - loss: 0.0545 - accuracy: 0.9752\n",
      "Epoch 348/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0535 - accuracy: 0.9790\n",
      "Epoch 349/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0547 - accuracy: 0.9771\n",
      "Epoch 350/1000\n",
      "524/524 [==============================] - 0s 313us/step - loss: 0.0530 - accuracy: 0.9771\n",
      "Epoch 351/1000\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 352/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0530 - accuracy: 0.9790\n",
      "Epoch 353/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0537 - accuracy: 0.9790\n",
      "Epoch 354/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0543 - accuracy: 0.9752\n",
      "Epoch 355/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0538 - accuracy: 0.9771\n",
      "Epoch 356/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 357/1000\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.0537 - accuracy: 0.9790\n",
      "Epoch 358/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0525 - accuracy: 0.9752\n",
      "Epoch 359/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0529 - accuracy: 0.9771\n",
      "Epoch 360/1000\n",
      "524/524 [==============================] - 0s 342us/step - loss: 0.0534 - accuracy: 0.9790\n",
      "Epoch 361/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0547 - accuracy: 0.9752\n",
      "Epoch 362/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0541 - accuracy: 0.9790\n",
      "Epoch 363/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0532 - accuracy: 0.9771\n",
      "Epoch 364/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0529 - accuracy: 0.9752\n",
      "Epoch 365/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0532 - accuracy: 0.9771\n",
      "Epoch 366/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0526 - accuracy: 0.9771\n",
      "Epoch 367/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0540 - accuracy: 0.9809\n",
      "Epoch 368/1000\n",
      "524/524 [==============================] - 0s 311us/step - loss: 0.0529 - accuracy: 0.9790\n",
      "Epoch 369/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0545 - accuracy: 0.9752\n",
      "Epoch 370/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0538 - accuracy: 0.9752\n",
      "Epoch 371/1000\n",
      "524/524 [==============================] - 0s 340us/step - loss: 0.0536 - accuracy: 0.9790\n",
      "Epoch 372/1000\n",
      "524/524 [==============================] - 0s 342us/step - loss: 0.0530 - accuracy: 0.9790\n",
      "Epoch 373/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0536 - accuracy: 0.9790\n",
      "Epoch 374/1000\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.0535 - accuracy: 0.9790\n",
      "Epoch 375/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0537 - accuracy: 0.9809\n",
      "Epoch 376/1000\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.0535 - accuracy: 0.9790\n",
      "Epoch 377/1000\n",
      "524/524 [==============================] - 0s 344us/step - loss: 0.0538 - accuracy: 0.9790\n",
      "Epoch 378/1000\n",
      "524/524 [==============================] - 0s 344us/step - loss: 0.0533 - accuracy: 0.9790\n",
      "Epoch 379/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 380/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0534 - accuracy: 0.9809\n",
      "Epoch 381/1000\n",
      "524/524 [==============================] - 0s 308us/step - loss: 0.0543 - accuracy: 0.9790\n",
      "Epoch 382/1000\n",
      "524/524 [==============================] - 0s 296us/step - loss: 0.0523 - accuracy: 0.9771\n",
      "Epoch 383/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0557 - accuracy: 0.9771\n",
      "Epoch 384/1000\n",
      "524/524 [==============================] - 0s 387us/step - loss: 0.0552 - accuracy: 0.9771\n",
      "Epoch 385/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0535 - accuracy: 0.9809\n",
      "Epoch 386/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0543 - accuracy: 0.9790\n",
      "Epoch 387/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0537 - accuracy: 0.9790\n",
      "Epoch 388/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0530 - accuracy: 0.9771\n",
      "Epoch 389/1000\n",
      "524/524 [==============================] - 0s 355us/step - loss: 0.0540 - accuracy: 0.9771\n",
      "Epoch 390/1000\n",
      "524/524 [==============================] - 0s 372us/step - loss: 0.0531 - accuracy: 0.9771\n",
      "Epoch 391/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 392/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0550 - accuracy: 0.9771\n",
      "Epoch 393/1000\n",
      "524/524 [==============================] - 0s 342us/step - loss: 0.0536 - accuracy: 0.9790\n",
      "Epoch 394/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0539 - accuracy: 0.9790\n",
      "Epoch 395/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0531 - accuracy: 0.9790\n",
      "Epoch 396/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0541 - accuracy: 0.9771\n",
      "Epoch 397/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0549 - accuracy: 0.9809\n",
      "Epoch 398/1000\n",
      "524/524 [==============================] - 0s 348us/step - loss: 0.0556 - accuracy: 0.9809\n",
      "Epoch 399/1000\n",
      "524/524 [==============================] - 0s 347us/step - loss: 0.0530 - accuracy: 0.9752\n",
      "Epoch 400/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0532 - accuracy: 0.9752\n",
      "Epoch 401/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0537 - accuracy: 0.9790\n",
      "Epoch 402/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0546 - accuracy: 0.9790\n",
      "Epoch 403/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0538 - accuracy: 0.9790\n",
      "Epoch 404/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0531 - accuracy: 0.9771\n",
      "Epoch 405/1000\n",
      "524/524 [==============================] - 0s 350us/step - loss: 0.0540 - accuracy: 0.9771\n",
      "Epoch 406/1000\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.0530 - accuracy: 0.9790\n",
      "Epoch 407/1000\n",
      "524/524 [==============================] - 0s 347us/step - loss: 0.0540 - accuracy: 0.9790\n",
      "Epoch 408/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0549 - accuracy: 0.9752\n",
      "Epoch 409/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0541 - accuracy: 0.9771\n",
      "Epoch 410/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0536 - accuracy: 0.9771\n",
      "Epoch 411/1000\n",
      "524/524 [==============================] - 0s 343us/step - loss: 0.0530 - accuracy: 0.9809\n",
      "Epoch 412/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0532 - accuracy: 0.9790\n",
      "Epoch 413/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0543 - accuracy: 0.9809\n",
      "Epoch 414/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0533 - accuracy: 0.9809\n",
      "Epoch 415/1000\n",
      "524/524 [==============================] - 0s 357us/step - loss: 0.0563 - accuracy: 0.9771\n",
      "Epoch 416/1000\n",
      "524/524 [==============================] - 0s 308us/step - loss: 0.0535 - accuracy: 0.9809\n",
      "Epoch 417/1000\n",
      "524/524 [==============================] - 0s 308us/step - loss: 0.0521 - accuracy: 0.9771\n",
      "Epoch 418/1000\n",
      "524/524 [==============================] - 0s 355us/step - loss: 0.0526 - accuracy: 0.9790\n",
      "Epoch 419/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0540 - accuracy: 0.9752\n",
      "Epoch 420/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0528 - accuracy: 0.9790\n",
      "Epoch 421/1000\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 422/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0523 - accuracy: 0.9771\n",
      "Epoch 423/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0529 - accuracy: 0.9752\n",
      "Epoch 424/1000\n",
      "524/524 [==============================] - 0s 314us/step - loss: 0.0526 - accuracy: 0.9771\n",
      "Epoch 425/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0533 - accuracy: 0.9771\n",
      "Epoch 426/1000\n",
      "524/524 [==============================] - 0s 318us/step - loss: 0.0532 - accuracy: 0.9752\n",
      "Epoch 427/1000\n",
      "524/524 [==============================] - 0s 353us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 428/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0530 - accuracy: 0.9790\n",
      "Epoch 429/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0535 - accuracy: 0.9771\n",
      "Epoch 430/1000\n",
      "524/524 [==============================] - 0s 358us/step - loss: 0.0531 - accuracy: 0.9790\n",
      "Epoch 431/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0518 - accuracy: 0.9771\n",
      "Epoch 432/1000\n",
      "524/524 [==============================] - 0s 354us/step - loss: 0.0544 - accuracy: 0.9790\n",
      "Epoch 433/1000\n",
      "524/524 [==============================] - 0s 316us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 434/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0536 - accuracy: 0.9790\n",
      "Epoch 435/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0557 - accuracy: 0.9790\n",
      "Epoch 436/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0527 - accuracy: 0.9790\n",
      "Epoch 437/1000\n",
      "524/524 [==============================] - 0s 342us/step - loss: 0.0527 - accuracy: 0.9752\n",
      "Epoch 438/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0531 - accuracy: 0.9790\n",
      "Epoch 439/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0542 - accuracy: 0.9752\n",
      "Epoch 440/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0530 - accuracy: 0.9752\n",
      "Epoch 441/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0537 - accuracy: 0.9771\n",
      "Epoch 442/1000\n",
      "524/524 [==============================] - 0s 343us/step - loss: 0.0535 - accuracy: 0.9771\n",
      "Epoch 443/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0539 - accuracy: 0.9790\n",
      "Epoch 444/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0526 - accuracy: 0.9771\n",
      "Epoch 445/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0524 - accuracy: 0.9790\n",
      "Epoch 446/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0537 - accuracy: 0.9771\n",
      "Epoch 447/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 448/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0534 - accuracy: 0.9790\n",
      "Epoch 449/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 450/1000\n",
      "524/524 [==============================] - 0s 350us/step - loss: 0.0544 - accuracy: 0.9733\n",
      "Epoch 451/1000\n",
      "524/524 [==============================] - 0s 353us/step - loss: 0.0529 - accuracy: 0.9771\n",
      "Epoch 452/1000\n",
      "524/524 [==============================] - 0s 356us/step - loss: 0.0539 - accuracy: 0.9809\n",
      "Epoch 453/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 454/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0539 - accuracy: 0.9771\n",
      "Epoch 455/1000\n",
      "524/524 [==============================] - 0s 372us/step - loss: 0.0530 - accuracy: 0.9771\n",
      "Epoch 456/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0530 - accuracy: 0.9752\n",
      "Epoch 457/1000\n",
      "524/524 [==============================] - 0s 350us/step - loss: 0.0545 - accuracy: 0.9771\n",
      "Epoch 458/1000\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.0552 - accuracy: 0.9771\n",
      "Epoch 459/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0524 - accuracy: 0.9790\n",
      "Epoch 460/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0516 - accuracy: 0.9809\n",
      "Epoch 461/1000\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.0548 - accuracy: 0.9790\n",
      "Epoch 462/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0529 - accuracy: 0.9790\n",
      "Epoch 463/1000\n",
      "524/524 [==============================] - 0s 346us/step - loss: 0.0543 - accuracy: 0.9790\n",
      "Epoch 464/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0533 - accuracy: 0.9771\n",
      "Epoch 465/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0551 - accuracy: 0.9771\n",
      "Epoch 466/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0525 - accuracy: 0.9771\n",
      "Epoch 467/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0559 - accuracy: 0.9790\n",
      "Epoch 468/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0536 - accuracy: 0.9828\n",
      "Epoch 469/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0547 - accuracy: 0.9771\n",
      "Epoch 470/1000\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.0536 - accuracy: 0.9752\n",
      "Epoch 471/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0520 - accuracy: 0.9809\n",
      "Epoch 472/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0536 - accuracy: 0.9752\n",
      "Epoch 473/1000\n",
      "524/524 [==============================] - 0s 339us/step - loss: 0.0550 - accuracy: 0.9752\n",
      "Epoch 474/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0542 - accuracy: 0.9790\n",
      "Epoch 475/1000\n",
      "524/524 [==============================] - 0s 313us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 476/1000\n",
      "524/524 [==============================] - 0s 365us/step - loss: 0.0552 - accuracy: 0.9790\n",
      "Epoch 477/1000\n",
      "524/524 [==============================] - 0s 309us/step - loss: 0.0542 - accuracy: 0.9809\n",
      "Epoch 478/1000\n",
      "524/524 [==============================] - 0s 350us/step - loss: 0.0531 - accuracy: 0.9790\n",
      "Epoch 479/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0532 - accuracy: 0.9752\n",
      "Epoch 480/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0534 - accuracy: 0.9790\n",
      "Epoch 481/1000\n",
      "524/524 [==============================] - 0s 367us/step - loss: 0.0542 - accuracy: 0.9771\n",
      "Epoch 482/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0527 - accuracy: 0.9790\n",
      "Epoch 483/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0563 - accuracy: 0.9790\n",
      "Epoch 484/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0546 - accuracy: 0.9771\n",
      "Epoch 485/1000\n",
      "524/524 [==============================] - 0s 339us/step - loss: 0.0532 - accuracy: 0.9771\n",
      "Epoch 486/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0533 - accuracy: 0.9809\n",
      "Epoch 487/1000\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.0546 - accuracy: 0.9771\n",
      "Epoch 488/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0526 - accuracy: 0.9790\n",
      "Epoch 489/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0527 - accuracy: 0.9809\n",
      "Epoch 490/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0546 - accuracy: 0.9790\n",
      "Epoch 491/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0550 - accuracy: 0.9771\n",
      "Epoch 492/1000\n",
      "524/524 [==============================] - 0s 342us/step - loss: 0.0531 - accuracy: 0.9771\n",
      "Epoch 493/1000\n",
      "524/524 [==============================] - 0s 362us/step - loss: 0.0526 - accuracy: 0.9771\n",
      "Epoch 494/1000\n",
      "524/524 [==============================] - 0s 358us/step - loss: 0.0530 - accuracy: 0.9790\n",
      "Epoch 495/1000\n",
      "524/524 [==============================] - 0s 349us/step - loss: 0.0527 - accuracy: 0.9790\n",
      "Epoch 496/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0533 - accuracy: 0.9771\n",
      "Epoch 497/1000\n",
      "524/524 [==============================] - 0s 355us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 498/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0527 - accuracy: 0.9752\n",
      "Epoch 499/1000\n",
      "524/524 [==============================] - 0s 343us/step - loss: 0.0533 - accuracy: 0.9790\n",
      "Epoch 500/1000\n",
      "524/524 [==============================] - 0s 350us/step - loss: 0.0545 - accuracy: 0.9771\n",
      "Epoch 501/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0536 - accuracy: 0.9771\n",
      "Epoch 502/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0535 - accuracy: 0.9790\n",
      "Epoch 503/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0524 - accuracy: 0.9752\n",
      "Epoch 504/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0531 - accuracy: 0.9809\n",
      "Epoch 505/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0538 - accuracy: 0.9771\n",
      "Epoch 506/1000\n",
      "524/524 [==============================] - 0s 360us/step - loss: 0.0543 - accuracy: 0.9752\n",
      "Epoch 507/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0536 - accuracy: 0.9790\n",
      "Epoch 508/1000\n",
      "524/524 [==============================] - 0s 351us/step - loss: 0.0529 - accuracy: 0.9771\n",
      "Epoch 509/1000\n",
      "524/524 [==============================] - 0s 345us/step - loss: 0.0527 - accuracy: 0.9771\n",
      "Epoch 510/1000\n",
      "524/524 [==============================] - 0s 340us/step - loss: 0.0542 - accuracy: 0.9828\n",
      "Epoch 511/1000\n",
      "524/524 [==============================] - 0s 356us/step - loss: 0.0542 - accuracy: 0.9809\n",
      "Epoch 512/1000\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.0533 - accuracy: 0.9790\n",
      "Epoch 513/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0578 - accuracy: 0.9790\n",
      "Epoch 514/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0525 - accuracy: 0.9771\n",
      "Epoch 515/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0532 - accuracy: 0.9790\n",
      "Epoch 516/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0530 - accuracy: 0.9790\n",
      "Epoch 517/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0541 - accuracy: 0.9790\n",
      "Epoch 518/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0524 - accuracy: 0.9790\n",
      "Epoch 519/1000\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.97 - 0s 331us/step - loss: 0.0552 - accuracy: 0.9771\n",
      "Epoch 520/1000\n",
      "524/524 [==============================] - 0s 311us/step - loss: 0.0535 - accuracy: 0.9771\n",
      "Epoch 521/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0532 - accuracy: 0.9790\n",
      "Epoch 522/1000\n",
      "524/524 [==============================] - 0s 316us/step - loss: 0.0526 - accuracy: 0.9790\n",
      "Epoch 523/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0536 - accuracy: 0.9771\n",
      "Epoch 524/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0529 - accuracy: 0.9790\n",
      "Epoch 525/1000\n",
      "524/524 [==============================] - 0s 315us/step - loss: 0.0540 - accuracy: 0.9752\n",
      "Epoch 526/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0526 - accuracy: 0.9790\n",
      "Epoch 527/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0525 - accuracy: 0.9790\n",
      "Epoch 528/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0537 - accuracy: 0.9809\n",
      "Epoch 529/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0530 - accuracy: 0.9790\n",
      "Epoch 530/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0528 - accuracy: 0.9790\n",
      "Epoch 531/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0529 - accuracy: 0.9771\n",
      "Epoch 532/1000\n",
      "524/524 [==============================] - 0s 353us/step - loss: 0.0531 - accuracy: 0.9790\n",
      "Epoch 533/1000\n",
      "524/524 [==============================] - 0s 382us/step - loss: 0.0544 - accuracy: 0.9771\n",
      "Epoch 534/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0542 - accuracy: 0.9790\n",
      "Epoch 535/1000\n",
      "524/524 [==============================] - 0s 366us/step - loss: 0.0520 - accuracy: 0.9790\n",
      "Epoch 536/1000\n",
      "524/524 [==============================] - 0s 352us/step - loss: 0.0550 - accuracy: 0.9771\n",
      "Epoch 537/1000\n",
      "524/524 [==============================] - 0s 360us/step - loss: 0.0530 - accuracy: 0.9809\n",
      "Epoch 538/1000\n",
      "524/524 [==============================] - 0s 353us/step - loss: 0.0526 - accuracy: 0.9790\n",
      "Epoch 539/1000\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.0545 - accuracy: 0.9771\n",
      "Epoch 540/1000\n",
      "524/524 [==============================] - 0s 362us/step - loss: 0.0540 - accuracy: 0.9809\n",
      "Epoch 541/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0535 - accuracy: 0.9790\n",
      "Epoch 542/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0532 - accuracy: 0.9790\n",
      "Epoch 543/1000\n",
      "524/524 [==============================] - 0s 348us/step - loss: 0.0523 - accuracy: 0.9790\n",
      "Epoch 544/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0533 - accuracy: 0.9790\n",
      "Epoch 545/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0549 - accuracy: 0.9771\n",
      "Epoch 546/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0530 - accuracy: 0.9771\n",
      "Epoch 547/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0527 - accuracy: 0.9771\n",
      "Epoch 548/1000\n",
      "524/524 [==============================] - 0s 339us/step - loss: 0.0527 - accuracy: 0.9771\n",
      "Epoch 549/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 550/1000\n",
      "524/524 [==============================] - 0s 354us/step - loss: 0.0523 - accuracy: 0.9790\n",
      "Epoch 551/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0535 - accuracy: 0.9752\n",
      "Epoch 552/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0525 - accuracy: 0.9809\n",
      "Epoch 553/1000\n",
      "524/524 [==============================] - 0s 340us/step - loss: 0.0536 - accuracy: 0.9771\n",
      "Epoch 554/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0535 - accuracy: 0.9752\n",
      "Epoch 555/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0525 - accuracy: 0.9771\n",
      "Epoch 556/1000\n",
      "524/524 [==============================] - 0s 309us/step - loss: 0.0523 - accuracy: 0.9790\n",
      "Epoch 557/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0527 - accuracy: 0.9771\n",
      "Epoch 558/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0526 - accuracy: 0.9809\n",
      "Epoch 559/1000\n",
      "524/524 [==============================] - 0s 356us/step - loss: 0.0537 - accuracy: 0.9752\n",
      "Epoch 560/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0532 - accuracy: 0.9752\n",
      "Epoch 561/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 562/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0530 - accuracy: 0.9752\n",
      "Epoch 563/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0530 - accuracy: 0.9752\n",
      "Epoch 564/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0529 - accuracy: 0.9790\n",
      "Epoch 565/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0536 - accuracy: 0.9790\n",
      "Epoch 566/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0536 - accuracy: 0.9771\n",
      "Epoch 567/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0524 - accuracy: 0.9771\n",
      "Epoch 568/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0536 - accuracy: 0.9752\n",
      "Epoch 569/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 570/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0542 - accuracy: 0.9790\n",
      "Epoch 571/1000\n",
      "524/524 [==============================] - 0s 345us/step - loss: 0.0548 - accuracy: 0.9771\n",
      "Epoch 572/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0535 - accuracy: 0.9771\n",
      "Epoch 573/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0535 - accuracy: 0.9790\n",
      "Epoch 574/1000\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.0543 - accuracy: 0.9771\n",
      "Epoch 575/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0519 - accuracy: 0.9771\n",
      "Epoch 576/1000\n",
      "524/524 [==============================] - 0s 369us/step - loss: 0.0552 - accuracy: 0.9809\n",
      "Epoch 577/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0565 - accuracy: 0.9790\n",
      "Epoch 578/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0535 - accuracy: 0.9790\n",
      "Epoch 579/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0534 - accuracy: 0.9790\n",
      "Epoch 580/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0536 - accuracy: 0.9771\n",
      "Epoch 581/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0550 - accuracy: 0.9752\n",
      "Epoch 582/1000\n",
      "524/524 [==============================] - 0s 340us/step - loss: 0.0538 - accuracy: 0.9790\n",
      "Epoch 583/1000\n",
      "524/524 [==============================] - 0s 347us/step - loss: 0.0546 - accuracy: 0.9752\n",
      "Epoch 584/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0528 - accuracy: 0.9790\n",
      "Epoch 585/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0552 - accuracy: 0.9752\n",
      "Epoch 586/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0526 - accuracy: 0.9771\n",
      "Epoch 587/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0541 - accuracy: 0.9771\n",
      "Epoch 588/1000\n",
      "524/524 [==============================] - 0s 340us/step - loss: 0.0542 - accuracy: 0.9771\n",
      "Epoch 589/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0525 - accuracy: 0.9752\n",
      "Epoch 590/1000\n",
      "524/524 [==============================] - 0s 364us/step - loss: 0.0534 - accuracy: 0.9790\n",
      "Epoch 591/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0528 - accuracy: 0.9790\n",
      "Epoch 592/1000\n",
      "524/524 [==============================] - 0s 342us/step - loss: 0.0532 - accuracy: 0.9790\n",
      "Epoch 593/1000\n",
      "524/524 [==============================] - 0s 340us/step - loss: 0.0532 - accuracy: 0.9809\n",
      "Epoch 594/1000\n",
      "524/524 [==============================] - 0s 340us/step - loss: 0.0532 - accuracy: 0.9771\n",
      "Epoch 595/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 596/1000\n",
      "524/524 [==============================] - 0s 343us/step - loss: 0.0534 - accuracy: 0.9790\n",
      "Epoch 597/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 598/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0543 - accuracy: 0.9771\n",
      "Epoch 599/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0537 - accuracy: 0.9771\n",
      "Epoch 600/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0532 - accuracy: 0.9752\n",
      "Epoch 601/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0541 - accuracy: 0.9771\n",
      "Epoch 602/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0538 - accuracy: 0.9771\n",
      "Epoch 603/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0537 - accuracy: 0.9790\n",
      "Epoch 604/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0551 - accuracy: 0.9771\n",
      "Epoch 605/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0529 - accuracy: 0.9790\n",
      "Epoch 606/1000\n",
      "524/524 [==============================] - 0s 354us/step - loss: 0.0526 - accuracy: 0.9790\n",
      "Epoch 607/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0534 - accuracy: 0.9790\n",
      "Epoch 608/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0541 - accuracy: 0.9828\n",
      "Epoch 609/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0551 - accuracy: 0.9790\n",
      "Epoch 610/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0539 - accuracy: 0.9771\n",
      "Epoch 611/1000\n",
      "524/524 [==============================] - 0s 308us/step - loss: 0.0536 - accuracy: 0.9790\n",
      "Epoch 612/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0528 - accuracy: 0.9752\n",
      "Epoch 613/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0524 - accuracy: 0.9771\n",
      "Epoch 614/1000\n",
      "524/524 [==============================] - 0s 343us/step - loss: 0.0532 - accuracy: 0.9771\n",
      "Epoch 615/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0517 - accuracy: 0.9771\n",
      "Epoch 616/1000\n",
      "524/524 [==============================] - 0s 355us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 617/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0526 - accuracy: 0.9752\n",
      "Epoch 618/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0544 - accuracy: 0.9752\n",
      "Epoch 619/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0528 - accuracy: 0.9752\n",
      "Epoch 620/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0543 - accuracy: 0.9771\n",
      "Epoch 621/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0562 - accuracy: 0.9771\n",
      "Epoch 622/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0529 - accuracy: 0.9752\n",
      "Epoch 623/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0540 - accuracy: 0.9771\n",
      "Epoch 624/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0558 - accuracy: 0.9771\n",
      "Epoch 625/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0532 - accuracy: 0.9771\n",
      "Epoch 626/1000\n",
      "524/524 [==============================] - 0s 316us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 627/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0549 - accuracy: 0.9771\n",
      "Epoch 628/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0529 - accuracy: 0.9771\n",
      "Epoch 629/1000\n",
      "524/524 [==============================] - 0s 307us/step - loss: 0.0526 - accuracy: 0.9790\n",
      "Epoch 630/1000\n",
      "524/524 [==============================] - 0s 316us/step - loss: 0.0535 - accuracy: 0.9771\n",
      "Epoch 631/1000\n",
      "524/524 [==============================] - 0s 345us/step - loss: 0.0523 - accuracy: 0.9809\n",
      "Epoch 632/1000\n",
      "524/524 [==============================] - 0s 339us/step - loss: 0.0542 - accuracy: 0.9771\n",
      "Epoch 633/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0548 - accuracy: 0.9733\n",
      "Epoch 634/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0530 - accuracy: 0.9771\n",
      "Epoch 635/1000\n",
      "524/524 [==============================] - 0s 347us/step - loss: 0.0536 - accuracy: 0.9790\n",
      "Epoch 636/1000\n",
      "524/524 [==============================] - 0s 351us/step - loss: 0.0537 - accuracy: 0.9771\n",
      "Epoch 637/1000\n",
      "524/524 [==============================] - 0s 371us/step - loss: 0.0525 - accuracy: 0.9771\n",
      "Epoch 638/1000\n",
      "524/524 [==============================] - 0s 311us/step - loss: 0.0527 - accuracy: 0.9771\n",
      "Epoch 639/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0544 - accuracy: 0.9771\n",
      "Epoch 640/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0536 - accuracy: 0.9790\n",
      "Epoch 641/1000\n",
      "524/524 [==============================] - 0s 349us/step - loss: 0.0534 - accuracy: 0.9752\n",
      "Epoch 642/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 643/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0537 - accuracy: 0.9771\n",
      "Epoch 644/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0535 - accuracy: 0.9752\n",
      "Epoch 645/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0535 - accuracy: 0.9752\n",
      "Epoch 646/1000\n",
      "524/524 [==============================] - 0s 349us/step - loss: 0.0538 - accuracy: 0.9790\n",
      "Epoch 647/1000\n",
      "524/524 [==============================] - 0s 350us/step - loss: 0.0523 - accuracy: 0.9771\n",
      "Epoch 648/1000\n",
      "524/524 [==============================] - 0s 350us/step - loss: 0.0535 - accuracy: 0.9790\n",
      "Epoch 649/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0532 - accuracy: 0.9771\n",
      "Epoch 650/1000\n",
      "524/524 [==============================] - 0s 351us/step - loss: 0.0549 - accuracy: 0.9790\n",
      "Epoch 651/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0548 - accuracy: 0.9771\n",
      "Epoch 652/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0525 - accuracy: 0.9771\n",
      "Epoch 653/1000\n",
      "524/524 [==============================] - 0s 318us/step - loss: 0.0548 - accuracy: 0.9771\n",
      "Epoch 654/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0556 - accuracy: 0.9752\n",
      "Epoch 655/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0523 - accuracy: 0.9790\n",
      "Epoch 656/1000\n",
      "524/524 [==============================] - 0s 339us/step - loss: 0.0570 - accuracy: 0.9771\n",
      "Epoch 657/1000\n",
      "524/524 [==============================] - 0s 357us/step - loss: 0.0523 - accuracy: 0.9771\n",
      "Epoch 658/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0533 - accuracy: 0.9752\n",
      "Epoch 659/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0530 - accuracy: 0.9790\n",
      "Epoch 660/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0543 - accuracy: 0.9790\n",
      "Epoch 661/1000\n",
      "524/524 [==============================] - 0s 349us/step - loss: 0.0540 - accuracy: 0.9771\n",
      "Epoch 662/1000\n",
      "524/524 [==============================] - 0s 349us/step - loss: 0.0536 - accuracy: 0.9752\n",
      "Epoch 663/1000\n",
      "524/524 [==============================] - 0s 347us/step - loss: 0.0540 - accuracy: 0.9771\n",
      "Epoch 664/1000\n",
      "524/524 [==============================] - 0s 356us/step - loss: 0.0526 - accuracy: 0.9752\n",
      "Epoch 665/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0522 - accuracy: 0.9790\n",
      "Epoch 666/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0558 - accuracy: 0.9752\n",
      "Epoch 667/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0520 - accuracy: 0.9771\n",
      "Epoch 668/1000\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.0529 - accuracy: 0.9828\n",
      "Epoch 669/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 670/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0536 - accuracy: 0.9790\n",
      "Epoch 671/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0532 - accuracy: 0.9809\n",
      "Epoch 672/1000\n",
      "524/524 [==============================] - 0s 340us/step - loss: 0.0535 - accuracy: 0.9733\n",
      "Epoch 673/1000\n",
      "524/524 [==============================] - 0s 355us/step - loss: 0.0529 - accuracy: 0.9790\n",
      "Epoch 674/1000\n",
      "524/524 [==============================] - 0s 366us/step - loss: 0.0530 - accuracy: 0.9790\n",
      "Epoch 675/1000\n",
      "524/524 [==============================] - 0s 355us/step - loss: 0.0533 - accuracy: 0.9809\n",
      "Epoch 676/1000\n",
      "524/524 [==============================] - 0s 356us/step - loss: 0.0536 - accuracy: 0.9790\n",
      "Epoch 677/1000\n",
      "524/524 [==============================] - 0s 348us/step - loss: 0.0530 - accuracy: 0.9771\n",
      "Epoch 678/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0546 - accuracy: 0.9790\n",
      "Epoch 679/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0531 - accuracy: 0.9752\n",
      "Epoch 680/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0550 - accuracy: 0.9790\n",
      "Epoch 681/1000\n",
      "524/524 [==============================] - 0s 298us/step - loss: 0.0525 - accuracy: 0.9790\n",
      "Epoch 682/1000\n",
      "524/524 [==============================] - 0s 350us/step - loss: 0.0545 - accuracy: 0.9771\n",
      "Epoch 683/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0532 - accuracy: 0.9809\n",
      "Epoch 684/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0524 - accuracy: 0.9809\n",
      "Epoch 685/1000\n",
      "524/524 [==============================] - 0s 316us/step - loss: 0.0531 - accuracy: 0.9771\n",
      "Epoch 686/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0531 - accuracy: 0.9771\n",
      "Epoch 687/1000\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.0524 - accuracy: 0.9790\n",
      "Epoch 688/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0536 - accuracy: 0.9771\n",
      "Epoch 689/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0553 - accuracy: 0.9752\n",
      "Epoch 690/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0545 - accuracy: 0.9771\n",
      "Epoch 691/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0534 - accuracy: 0.9790\n",
      "Epoch 692/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0537 - accuracy: 0.9752\n",
      "Epoch 693/1000\n",
      "524/524 [==============================] - 0s 306us/step - loss: 0.0550 - accuracy: 0.9790\n",
      "Epoch 694/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0523 - accuracy: 0.9790\n",
      "Epoch 695/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0526 - accuracy: 0.9771\n",
      "Epoch 696/1000\n",
      "524/524 [==============================] - 0s 318us/step - loss: 0.0540 - accuracy: 0.9790\n",
      "Epoch 697/1000\n",
      "524/524 [==============================] - 0s 311us/step - loss: 0.0527 - accuracy: 0.9771\n",
      "Epoch 698/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0531 - accuracy: 0.9771\n",
      "Epoch 699/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0527 - accuracy: 0.9771\n",
      "Epoch 700/1000\n",
      "524/524 [==============================] - 0s 314us/step - loss: 0.0536 - accuracy: 0.9790\n",
      "Epoch 701/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0559 - accuracy: 0.9790\n",
      "Epoch 702/1000\n",
      "524/524 [==============================] - 0s 307us/step - loss: 0.0523 - accuracy: 0.9790\n",
      "Epoch 703/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0549 - accuracy: 0.9790\n",
      "Epoch 704/1000\n",
      "524/524 [==============================] - 0s 296us/step - loss: 0.0534 - accuracy: 0.9790\n",
      "Epoch 705/1000\n",
      "524/524 [==============================] - 0s 351us/step - loss: 0.0525 - accuracy: 0.9809\n",
      "Epoch 706/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0529 - accuracy: 0.9809\n",
      "Epoch 707/1000\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.0533 - accuracy: 0.9771\n",
      "Epoch 708/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0529 - accuracy: 0.9790\n",
      "Epoch 709/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0552 - accuracy: 0.9771\n",
      "Epoch 710/1000\n",
      "524/524 [==============================] - 0s 356us/step - loss: 0.0537 - accuracy: 0.9752\n",
      "Epoch 711/1000\n",
      "524/524 [==============================] - 0s 315us/step - loss: 0.0522 - accuracy: 0.9771\n",
      "Epoch 712/1000\n",
      "524/524 [==============================] - 0s 387us/step - loss: 0.0532 - accuracy: 0.9790\n",
      "Epoch 713/1000\n",
      "524/524 [==============================] - 0s 344us/step - loss: 0.0544 - accuracy: 0.9733\n",
      "Epoch 714/1000\n",
      "524/524 [==============================] - 0s 347us/step - loss: 0.0540 - accuracy: 0.9790\n",
      "Epoch 715/1000\n",
      "524/524 [==============================] - 0s 355us/step - loss: 0.0524 - accuracy: 0.9771\n",
      "Epoch 716/1000\n",
      "524/524 [==============================] - 0s 353us/step - loss: 0.0539 - accuracy: 0.9752\n",
      "Epoch 717/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0542 - accuracy: 0.9752\n",
      "Epoch 718/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0527 - accuracy: 0.9771\n",
      "Epoch 719/1000\n",
      "524/524 [==============================] - 0s 342us/step - loss: 0.0523 - accuracy: 0.9790\n",
      "Epoch 720/1000\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.0525 - accuracy: 0.9771\n",
      "Epoch 721/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0531 - accuracy: 0.9752\n",
      "Epoch 722/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0527 - accuracy: 0.9790\n",
      "Epoch 723/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0528 - accuracy: 0.9790\n",
      "Epoch 724/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0542 - accuracy: 0.9790\n",
      "Epoch 725/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0524 - accuracy: 0.9752\n",
      "Epoch 726/1000\n",
      "524/524 [==============================] - 0s 354us/step - loss: 0.0555 - accuracy: 0.9771\n",
      "Epoch 727/1000\n",
      "524/524 [==============================] - 0s 318us/step - loss: 0.0530 - accuracy: 0.9790\n",
      "Epoch 728/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0527 - accuracy: 0.9771\n",
      "Epoch 729/1000\n",
      "524/524 [==============================] - 0s 340us/step - loss: 0.0527 - accuracy: 0.9790\n",
      "Epoch 730/1000\n",
      "524/524 [==============================] - 0s 347us/step - loss: 0.0525 - accuracy: 0.9809\n",
      "Epoch 731/1000\n",
      "524/524 [==============================] - 0s 349us/step - loss: 0.0536 - accuracy: 0.9752\n",
      "Epoch 732/1000\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 733/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0544 - accuracy: 0.9809\n",
      "Epoch 734/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0539 - accuracy: 0.9771\n",
      "Epoch 735/1000\n",
      "524/524 [==============================] - 0s 344us/step - loss: 0.0533 - accuracy: 0.9790\n",
      "Epoch 736/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0528 - accuracy: 0.9790\n",
      "Epoch 737/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 738/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0519 - accuracy: 0.9828\n",
      "Epoch 739/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0546 - accuracy: 0.9809\n",
      "Epoch 740/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0540 - accuracy: 0.9771\n",
      "Epoch 741/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0532 - accuracy: 0.9771\n",
      "Epoch 742/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0526 - accuracy: 0.9790\n",
      "Epoch 743/1000\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.0531 - accuracy: 0.9790\n",
      "Epoch 744/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0552 - accuracy: 0.9790\n",
      "Epoch 745/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0539 - accuracy: 0.9771\n",
      "Epoch 746/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0544 - accuracy: 0.9752\n",
      "Epoch 747/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0535 - accuracy: 0.9771\n",
      "Epoch 748/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0536 - accuracy: 0.9809\n",
      "Epoch 749/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0538 - accuracy: 0.9752\n",
      "Epoch 750/1000\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.0528 - accuracy: 0.9752\n",
      "Epoch 751/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0535 - accuracy: 0.9752\n",
      "Epoch 752/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0535 - accuracy: 0.9771\n",
      "Epoch 753/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0530 - accuracy: 0.9790\n",
      "Epoch 754/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0533 - accuracy: 0.9790\n",
      "Epoch 755/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0551 - accuracy: 0.9771\n",
      "Epoch 756/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0527 - accuracy: 0.9790\n",
      "Epoch 757/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0528 - accuracy: 0.9790\n",
      "Epoch 758/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0540 - accuracy: 0.9771\n",
      "Epoch 759/1000\n",
      "524/524 [==============================] - 0s 345us/step - loss: 0.0523 - accuracy: 0.9771\n",
      "Epoch 760/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0534 - accuracy: 0.9752\n",
      "Epoch 761/1000\n",
      "524/524 [==============================] - 0s 349us/step - loss: 0.0537 - accuracy: 0.9790\n",
      "Epoch 762/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0524 - accuracy: 0.9771\n",
      "Epoch 763/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0526 - accuracy: 0.9790\n",
      "Epoch 764/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0532 - accuracy: 0.9752\n",
      "Epoch 765/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0539 - accuracy: 0.9771\n",
      "Epoch 766/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0535 - accuracy: 0.9771\n",
      "Epoch 767/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0531 - accuracy: 0.9790\n",
      "Epoch 768/1000\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.0532 - accuracy: 0.9771\n",
      "Epoch 769/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0536 - accuracy: 0.9752\n",
      "Epoch 770/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0528 - accuracy: 0.9790\n",
      "Epoch 771/1000\n",
      "524/524 [==============================] - 0s 354us/step - loss: 0.0531 - accuracy: 0.9733\n",
      "Epoch 772/1000\n",
      "524/524 [==============================] - 0s 300us/step - loss: 0.0524 - accuracy: 0.9790\n",
      "Epoch 773/1000\n",
      "524/524 [==============================] - 0s 298us/step - loss: 0.0533 - accuracy: 0.9771\n",
      "Epoch 774/1000\n",
      "524/524 [==============================] - 0s 299us/step - loss: 0.0531 - accuracy: 0.9790\n",
      "Epoch 775/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0540 - accuracy: 0.9771\n",
      "Epoch 776/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0530 - accuracy: 0.9771\n",
      "Epoch 777/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0537 - accuracy: 0.9790\n",
      "Epoch 778/1000\n",
      "524/524 [==============================] - 0s 305us/step - loss: 0.0522 - accuracy: 0.9771\n",
      "Epoch 779/1000\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.0528 - accuracy: 0.9752\n",
      "Epoch 780/1000\n",
      "524/524 [==============================] - 0s 316us/step - loss: 0.0530 - accuracy: 0.9771\n",
      "Epoch 781/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0526 - accuracy: 0.9771\n",
      "Epoch 782/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0545 - accuracy: 0.9752\n",
      "Epoch 783/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0526 - accuracy: 0.9771\n",
      "Epoch 784/1000\n",
      "524/524 [==============================] - 0s 316us/step - loss: 0.0539 - accuracy: 0.9733\n",
      "Epoch 785/1000\n",
      "524/524 [==============================] - 0s 339us/step - loss: 0.0527 - accuracy: 0.9790\n",
      "Epoch 786/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0538 - accuracy: 0.9771\n",
      "Epoch 787/1000\n",
      "524/524 [==============================] - 0s 352us/step - loss: 0.0535 - accuracy: 0.9752\n",
      "Epoch 788/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0541 - accuracy: 0.9733\n",
      "Epoch 789/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0531 - accuracy: 0.9790\n",
      "Epoch 790/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0531 - accuracy: 0.9790\n",
      "Epoch 791/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0535 - accuracy: 0.9752\n",
      "Epoch 792/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0540 - accuracy: 0.9771\n",
      "Epoch 793/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0549 - accuracy: 0.9752\n",
      "Epoch 794/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0526 - accuracy: 0.9790\n",
      "Epoch 795/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0545 - accuracy: 0.9752\n",
      "Epoch 796/1000\n",
      "524/524 [==============================] - 0s 340us/step - loss: 0.0550 - accuracy: 0.9752\n",
      "Epoch 797/1000\n",
      "524/524 [==============================] - 0s 348us/step - loss: 0.0535 - accuracy: 0.9790\n",
      "Epoch 798/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 799/1000\n",
      "524/524 [==============================] - 0s 349us/step - loss: 0.0555 - accuracy: 0.9771\n",
      "Epoch 800/1000\n",
      "524/524 [==============================] - 0s 344us/step - loss: 0.0534 - accuracy: 0.9752\n",
      "Epoch 801/1000\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.0531 - accuracy: 0.9790\n",
      "Epoch 802/1000\n",
      "524/524 [==============================] - 0s 361us/step - loss: 0.0526 - accuracy: 0.9790\n",
      "Epoch 803/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0523 - accuracy: 0.9809\n",
      "Epoch 804/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 805/1000\n",
      "524/524 [==============================] - 0s 346us/step - loss: 0.0539 - accuracy: 0.9752\n",
      "Epoch 806/1000\n",
      "524/524 [==============================] - 0s 343us/step - loss: 0.0533 - accuracy: 0.9771\n",
      "Epoch 807/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0530 - accuracy: 0.9790\n",
      "Epoch 808/1000\n",
      "524/524 [==============================] - 0s 347us/step - loss: 0.0554 - accuracy: 0.9752\n",
      "Epoch 809/1000\n",
      "524/524 [==============================] - 0s 358us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 810/1000\n",
      "524/524 [==============================] - 0s 349us/step - loss: 0.0532 - accuracy: 0.9771\n",
      "Epoch 811/1000\n",
      "524/524 [==============================] - 0s 348us/step - loss: 0.0547 - accuracy: 0.9771\n",
      "Epoch 812/1000\n",
      "524/524 [==============================] - 0s 354us/step - loss: 0.0530 - accuracy: 0.9771\n",
      "Epoch 813/1000\n",
      "524/524 [==============================] - 0s 377us/step - loss: 0.0535 - accuracy: 0.9771\n",
      "Epoch 814/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0545 - accuracy: 0.9752\n",
      "Epoch 815/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0528 - accuracy: 0.9790\n",
      "Epoch 816/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0535 - accuracy: 0.9771\n",
      "Epoch 817/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0523 - accuracy: 0.9752\n",
      "Epoch 818/1000\n",
      "524/524 [==============================] - 0s 380us/step - loss: 0.0527 - accuracy: 0.9771\n",
      "Epoch 819/1000\n",
      "524/524 [==============================] - 0s 312us/step - loss: 0.0534 - accuracy: 0.9790\n",
      "Epoch 820/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0532 - accuracy: 0.9771\n",
      "Epoch 821/1000\n",
      "524/524 [==============================] - 0s 304us/step - loss: 0.0533 - accuracy: 0.9771\n",
      "Epoch 822/1000\n",
      "524/524 [==============================] - 0s 340us/step - loss: 0.0541 - accuracy: 0.9771\n",
      "Epoch 823/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0530 - accuracy: 0.9771\n",
      "Epoch 824/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0536 - accuracy: 0.9733\n",
      "Epoch 825/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0533 - accuracy: 0.9790\n",
      "Epoch 826/1000\n",
      "524/524 [==============================] - 0s 309us/step - loss: 0.0526 - accuracy: 0.9752\n",
      "Epoch 827/1000\n",
      "524/524 [==============================] - 0s 313us/step - loss: 0.0521 - accuracy: 0.9771\n",
      "Epoch 828/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0527 - accuracy: 0.9771\n",
      "Epoch 829/1000\n",
      "524/524 [==============================] - 0s 315us/step - loss: 0.0538 - accuracy: 0.9790\n",
      "Epoch 830/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0531 - accuracy: 0.9771\n",
      "Epoch 831/1000\n",
      "524/524 [==============================] - 0s 318us/step - loss: 0.0532 - accuracy: 0.9771\n",
      "Epoch 832/1000\n",
      "524/524 [==============================] - 0s 305us/step - loss: 0.0529 - accuracy: 0.9790\n",
      "Epoch 833/1000\n",
      "524/524 [==============================] - 0s 318us/step - loss: 0.0544 - accuracy: 0.9752\n",
      "Epoch 834/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0533 - accuracy: 0.9771\n",
      "Epoch 835/1000\n",
      "524/524 [==============================] - 0s 313us/step - loss: 0.0521 - accuracy: 0.9771\n",
      "Epoch 836/1000\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.0532 - accuracy: 0.9771\n",
      "Epoch 837/1000\n",
      "524/524 [==============================] - 0s 348us/step - loss: 0.0532 - accuracy: 0.9790\n",
      "Epoch 838/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0534 - accuracy: 0.9790\n",
      "Epoch 839/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0533 - accuracy: 0.9790\n",
      "Epoch 840/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0532 - accuracy: 0.9752\n",
      "Epoch 841/1000\n",
      "524/524 [==============================] - 0s 387us/step - loss: 0.0522 - accuracy: 0.9790\n",
      "Epoch 842/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0550 - accuracy: 0.9771\n",
      "Epoch 843/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0553 - accuracy: 0.9771\n",
      "Epoch 844/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0536 - accuracy: 0.9752\n",
      "Epoch 845/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0526 - accuracy: 0.9790\n",
      "Epoch 846/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0521 - accuracy: 0.9771\n",
      "Epoch 847/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0532 - accuracy: 0.9771\n",
      "Epoch 848/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0543 - accuracy: 0.9733\n",
      "Epoch 849/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0538 - accuracy: 0.9752\n",
      "Epoch 850/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0527 - accuracy: 0.9771\n",
      "Epoch 851/1000\n",
      "524/524 [==============================] - 0s 344us/step - loss: 0.0532 - accuracy: 0.9771\n",
      "Epoch 852/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0536 - accuracy: 0.9771\n",
      "Epoch 853/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0537 - accuracy: 0.9809\n",
      "Epoch 854/1000\n",
      "524/524 [==============================] - 0s 318us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 855/1000\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.0535 - accuracy: 0.9790\n",
      "Epoch 856/1000\n",
      "524/524 [==============================] - 0s 318us/step - loss: 0.0533 - accuracy: 0.9771\n",
      "Epoch 857/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0542 - accuracy: 0.9771\n",
      "Epoch 858/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0533 - accuracy: 0.9790\n",
      "Epoch 859/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0524 - accuracy: 0.9790\n",
      "Epoch 860/1000\n",
      "524/524 [==============================] - 0s 361us/step - loss: 0.0525 - accuracy: 0.9790\n",
      "Epoch 861/1000\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0533 - accuracy: 0.9790\n",
      "Epoch 862/1000\n",
      "524/524 [==============================] - 0s 343us/step - loss: 0.0530 - accuracy: 0.9771\n",
      "Epoch 863/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0532 - accuracy: 0.9752\n",
      "Epoch 864/1000\n",
      "524/524 [==============================] - 0s 300us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 865/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0546 - accuracy: 0.9752\n",
      "Epoch 866/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 867/1000\n",
      "524/524 [==============================] - 0s 349us/step - loss: 0.0541 - accuracy: 0.9771\n",
      "Epoch 868/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0533 - accuracy: 0.9752\n",
      "Epoch 869/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0525 - accuracy: 0.9790\n",
      "Epoch 870/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0545 - accuracy: 0.9771\n",
      "Epoch 871/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0524 - accuracy: 0.9771\n",
      "Epoch 872/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0535 - accuracy: 0.9809\n",
      "Epoch 873/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0539 - accuracy: 0.9790\n",
      "Epoch 874/1000\n",
      "524/524 [==============================] - 0s 315us/step - loss: 0.0535 - accuracy: 0.9790\n",
      "Epoch 875/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0553 - accuracy: 0.9771\n",
      "Epoch 876/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0540 - accuracy: 0.9752\n",
      "Epoch 877/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 878/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0547 - accuracy: 0.9790\n",
      "Epoch 879/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0536 - accuracy: 0.9771\n",
      "Epoch 880/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0529 - accuracy: 0.9790\n",
      "Epoch 881/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0529 - accuracy: 0.9771\n",
      "Epoch 882/1000\n",
      "524/524 [==============================] - 0s 315us/step - loss: 0.0531 - accuracy: 0.9752\n",
      "Epoch 883/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0523 - accuracy: 0.9771\n",
      "Epoch 884/1000\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.0534 - accuracy: 0.9790\n",
      "Epoch 885/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0520 - accuracy: 0.9771\n",
      "Epoch 886/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0526 - accuracy: 0.9790\n",
      "Epoch 887/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0534 - accuracy: 0.9752\n",
      "Epoch 888/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0555 - accuracy: 0.9771\n",
      "Epoch 889/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0568 - accuracy: 0.9771\n",
      "Epoch 890/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 891/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0529 - accuracy: 0.9790\n",
      "Epoch 892/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0536 - accuracy: 0.9790\n",
      "Epoch 893/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0544 - accuracy: 0.9790\n",
      "Epoch 894/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0527 - accuracy: 0.9771\n",
      "Epoch 895/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0538 - accuracy: 0.9790\n",
      "Epoch 896/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0529 - accuracy: 0.9809\n",
      "Epoch 897/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0551 - accuracy: 0.9771\n",
      "Epoch 898/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0533 - accuracy: 0.9771\n",
      "Epoch 899/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0530 - accuracy: 0.9771\n",
      "Epoch 900/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0540 - accuracy: 0.9809\n",
      "Epoch 901/1000\n",
      "524/524 [==============================] - 0s 308us/step - loss: 0.0533 - accuracy: 0.9771\n",
      "Epoch 902/1000\n",
      "524/524 [==============================] - 0s 283us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 903/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0529 - accuracy: 0.9752\n",
      "Epoch 904/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0533 - accuracy: 0.9771\n",
      "Epoch 905/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0545 - accuracy: 0.9752\n",
      "Epoch 906/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0529 - accuracy: 0.9790\n",
      "Epoch 907/1000\n",
      "524/524 [==============================] - 0s 316us/step - loss: 0.0533 - accuracy: 0.9771\n",
      "Epoch 908/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0529 - accuracy: 0.9790\n",
      "Epoch 909/1000\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.0552 - accuracy: 0.9771\n",
      "Epoch 910/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0524 - accuracy: 0.9771\n",
      "Epoch 911/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0521 - accuracy: 0.9790\n",
      "Epoch 912/1000\n",
      "524/524 [==============================] - 0s 296us/step - loss: 0.0536 - accuracy: 0.9790\n",
      "Epoch 913/1000\n",
      "524/524 [==============================] - 0s 295us/step - loss: 0.0559 - accuracy: 0.9790\n",
      "Epoch 914/1000\n",
      "524/524 [==============================] - 0s 298us/step - loss: 0.0533 - accuracy: 0.9790\n",
      "Epoch 915/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0532 - accuracy: 0.9809\n",
      "Epoch 916/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0541 - accuracy: 0.9771\n",
      "Epoch 917/1000\n",
      "524/524 [==============================] - 0s 342us/step - loss: 0.0537 - accuracy: 0.9771\n",
      "Epoch 918/1000\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.0545 - accuracy: 0.9771\n",
      "Epoch 919/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0536 - accuracy: 0.9790\n",
      "Epoch 920/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0529 - accuracy: 0.9752\n",
      "Epoch 921/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0524 - accuracy: 0.9790\n",
      "Epoch 922/1000\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.0532 - accuracy: 0.9752\n",
      "Epoch 923/1000\n",
      "524/524 [==============================] - 0s 304us/step - loss: 0.0527 - accuracy: 0.9771\n",
      "Epoch 924/1000\n",
      "524/524 [==============================] - 0s 296us/step - loss: 0.0527 - accuracy: 0.9771\n",
      "Epoch 925/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0527 - accuracy: 0.9771\n",
      "Epoch 926/1000\n",
      "524/524 [==============================] - 0s 297us/step - loss: 0.0541 - accuracy: 0.9771\n",
      "Epoch 927/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0562 - accuracy: 0.9752\n",
      "Epoch 928/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0545 - accuracy: 0.9790\n",
      "Epoch 929/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0527 - accuracy: 0.9771\n",
      "Epoch 930/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0525 - accuracy: 0.9790\n",
      "Epoch 931/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0529 - accuracy: 0.9790\n",
      "Epoch 932/1000\n",
      "524/524 [==============================] - 0s 313us/step - loss: 0.0534 - accuracy: 0.9752\n",
      "Epoch 933/1000\n",
      "524/524 [==============================] - 0s 296us/step - loss: 0.0527 - accuracy: 0.9790\n",
      "Epoch 934/1000\n",
      "524/524 [==============================] - 0s 315us/step - loss: 0.0531 - accuracy: 0.9771\n",
      "Epoch 935/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0528 - accuracy: 0.9828\n",
      "Epoch 936/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0530 - accuracy: 0.9752\n",
      "Epoch 937/1000\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0533 - accuracy: 0.9752\n",
      "Epoch 938/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0533 - accuracy: 0.9771\n",
      "Epoch 939/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0533 - accuracy: 0.9771\n",
      "Epoch 940/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0521 - accuracy: 0.9790\n",
      "Epoch 941/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0539 - accuracy: 0.9790\n",
      "Epoch 942/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 943/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0520 - accuracy: 0.9809\n",
      "Epoch 944/1000\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.0543 - accuracy: 0.9733\n",
      "Epoch 945/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0536 - accuracy: 0.9828\n",
      "Epoch 946/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0529 - accuracy: 0.9771\n",
      "Epoch 947/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0535 - accuracy: 0.9752\n",
      "Epoch 948/1000\n",
      "524/524 [==============================] - 0s 330us/step - loss: 0.0518 - accuracy: 0.9809\n",
      "Epoch 949/1000\n",
      "524/524 [==============================] - 0s 310us/step - loss: 0.0571 - accuracy: 0.9771\n",
      "Epoch 950/1000\n",
      "524/524 [==============================] - 0s 293us/step - loss: 0.0531 - accuracy: 0.9790\n",
      "Epoch 951/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0540 - accuracy: 0.9790\n",
      "Epoch 952/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0529 - accuracy: 0.9771\n",
      "Epoch 953/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0529 - accuracy: 0.9771\n",
      "Epoch 954/1000\n",
      "524/524 [==============================] - 0s 313us/step - loss: 0.0526 - accuracy: 0.9771\n",
      "Epoch 955/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0525 - accuracy: 0.9790\n",
      "Epoch 956/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0541 - accuracy: 0.9771\n",
      "Epoch 957/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0544 - accuracy: 0.9771\n",
      "Epoch 958/1000\n",
      "524/524 [==============================] - 0s 344us/step - loss: 0.0556 - accuracy: 0.9790\n",
      "Epoch 959/1000\n",
      "524/524 [==============================] - 0s 308us/step - loss: 0.0530 - accuracy: 0.9752\n",
      "Epoch 960/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0541 - accuracy: 0.9771\n",
      "Epoch 961/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0523 - accuracy: 0.9771\n",
      "Epoch 962/1000\n",
      "524/524 [==============================] - 0s 303us/step - loss: 0.0534 - accuracy: 0.9771\n",
      "Epoch 963/1000\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0524 - accuracy: 0.9771\n",
      "Epoch 964/1000\n",
      "524/524 [==============================] - 0s 316us/step - loss: 0.0533 - accuracy: 0.9752\n",
      "Epoch 965/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0537 - accuracy: 0.9771\n",
      "Epoch 966/1000\n",
      "524/524 [==============================] - 0s 292us/step - loss: 0.0543 - accuracy: 0.9771\n",
      "Epoch 967/1000\n",
      "524/524 [==============================] - 0s 313us/step - loss: 0.0555 - accuracy: 0.9771\n",
      "Epoch 968/1000\n",
      "524/524 [==============================] - 0s 286us/step - loss: 0.0559 - accuracy: 0.9752\n",
      "Epoch 969/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0518 - accuracy: 0.9771\n",
      "Epoch 970/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0528 - accuracy: 0.9790\n",
      "Epoch 971/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0524 - accuracy: 0.9752\n",
      "Epoch 972/1000\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.0545 - accuracy: 0.9771\n",
      "Epoch 973/1000\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0544 - accuracy: 0.9809\n",
      "Epoch 974/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0526 - accuracy: 0.9809\n",
      "Epoch 975/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0540 - accuracy: 0.9771\n",
      "Epoch 976/1000\n",
      "524/524 [==============================] - 0s 318us/step - loss: 0.0534 - accuracy: 0.9752\n",
      "Epoch 977/1000\n",
      "524/524 [==============================] - 0s 309us/step - loss: 0.0529 - accuracy: 0.9790\n",
      "Epoch 978/1000\n",
      "524/524 [==============================] - 0s 335us/step - loss: 0.0531 - accuracy: 0.9771\n",
      "Epoch 979/1000\n",
      "524/524 [==============================] - 0s 346us/step - loss: 0.0525 - accuracy: 0.9771\n",
      "Epoch 980/1000\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.0533 - accuracy: 0.9790\n",
      "Epoch 981/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0537 - accuracy: 0.9771\n",
      "Epoch 982/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0529 - accuracy: 0.9790\n",
      "Epoch 983/1000\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0534 - accuracy: 0.9809\n",
      "Epoch 984/1000\n",
      "524/524 [==============================] - 0s 316us/step - loss: 0.0538 - accuracy: 0.9752\n",
      "Epoch 985/1000\n",
      "524/524 [==============================] - 0s 305us/step - loss: 0.0544 - accuracy: 0.9771\n",
      "Epoch 986/1000\n",
      "524/524 [==============================] - 0s 340us/step - loss: 0.0528 - accuracy: 0.9752\n",
      "Epoch 987/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0547 - accuracy: 0.9771\n",
      "Epoch 988/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0540 - accuracy: 0.9809\n",
      "Epoch 989/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0551 - accuracy: 0.9771\n",
      "Epoch 990/1000\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0536 - accuracy: 0.9771\n",
      "Epoch 991/1000\n",
      "524/524 [==============================] - 0s 337us/step - loss: 0.0538 - accuracy: 0.9771\n",
      "Epoch 992/1000\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0529 - accuracy: 0.9809\n",
      "Epoch 993/1000\n",
      "524/524 [==============================] - 0s 358us/step - loss: 0.0528 - accuracy: 0.9771\n",
      "Epoch 994/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0537 - accuracy: 0.9752\n",
      "Epoch 995/1000\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0528 - accuracy: 0.9790\n",
      "Epoch 996/1000\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0533 - accuracy: 0.9771\n",
      "Epoch 997/1000\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.0546 - accuracy: 0.9771\n",
      "Epoch 998/1000\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0527 - accuracy: 0.9790\n",
      "Epoch 999/1000\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.0537 - accuracy: 0.9771\n",
      "Epoch 1000/1000\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0529 - accuracy: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f401938ef10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the final model for evaluating the test dataset\n",
    "print('Forming the final model using: optimizer=%s, kernel=%s, epochs=%d, batch_size=%d'\n",
    "      % (best_optimizer, best_kernel_init, best_epoch, best_batch))\n",
    "final_model = create_customized_model(best_optimizer, best_kernel_init)\n",
    "final_model.fit(X_train, y_train, epochs=best_epoch, batch_size=best_batch, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the final model\n",
    "print(final_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'sequential_7', 'layers': [{'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'batch_input_shape': (None, 9), 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'RandomNormal', 'config': {'mean': 0.0, 'stddev': 0.05, 'seed': 892}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 1, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'RandomNormal', 'config': {'mean': 0.0, 'stddev': 0.05, 'seed': 892}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]}\n"
     ]
    }
   ],
   "source": [
    "# Display the configuration of the final model\n",
    "print(final_model.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op __inference_keras_scratch_graph_804893 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "175/175 [==============================] - 0s 361us/step\n",
      "\n",
      "accuracy: 93.71%\n",
      "\n",
      "loss: 0.20\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Keras model on previously unseen data\n",
    "scores = final_model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (final_model.metrics_names[1], scores[1]*100))\n",
    "print(\"\\n%s: %.2f\" % (final_model.metrics_names[0], scores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op __inference_keras_scratch_graph_804943 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Data item #0 predicted to be 0 (expected 0)\n",
      "Data item #1 predicted to be 0 (expected 0)\n",
      "Data item #2 predicted to be 0 (expected 0)\n",
      "Data item #3 predicted to be 0 (expected 0)\n",
      "Data item #4 predicted to be 0 (expected 1)\n",
      "Data item #5 predicted to be 1 (expected 1)\n",
      "Data item #6 predicted to be 0 (expected 0)\n",
      "Data item #7 predicted to be 0 (expected 0)\n",
      "Data item #8 predicted to be 1 (expected 1)\n",
      "Data item #9 predicted to be 1 (expected 1)\n",
      "Data item #10 predicted to be 0 (expected 0)\n",
      "Data item #11 predicted to be 0 (expected 0)\n",
      "Data item #12 predicted to be 1 (expected 1)\n",
      "Data item #13 predicted to be 0 (expected 0)\n",
      "Data item #14 predicted to be 0 (expected 1)\n",
      "Data item #15 predicted to be 0 (expected 0)\n",
      "Data item #16 predicted to be 1 (expected 1)\n",
      "Data item #17 predicted to be 0 (expected 0)\n",
      "Data item #18 predicted to be 0 (expected 0)\n",
      "Data item #19 predicted to be 1 (expected 1)\n"
     ]
    }
   ],
   "source": [
    "# Make class predictions with the model\n",
    "predictions = final_model.predict_classes(X_test)\n",
    "\n",
    "# Summarize the first 20 cases\n",
    "for i in range(20):\n",
    "\tprint('Data item #%d predicted to be %d (expected %d)' % (i, predictions[i], y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 5 Finalize Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for the script: 0:46:45.030493\n"
     ]
    }
   ],
   "source": [
    "print ('Total time for the script:',(datetime.now() - startTimeScript))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
