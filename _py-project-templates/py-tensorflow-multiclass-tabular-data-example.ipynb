{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Classification Deep Learning Model for [PROJECT NAME] Using Keras Version 6\n",
    "### David Lowe\n",
    "### April 9, 2020\n",
    "\n",
    "Template Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery. [https://machinelearningmastery.com/]\n",
    "\n",
    "SUMMARY: The purpose of this project is to construct a predictive model using various machine learning algorithms and to document the end-to-end steps using a template. The [PROJECT NAME] dataset is a multi-class classification situation where we are trying to predict one of several (more than two) possible outcomes.\n",
    "\n",
    "INTRODUCTION: [Sample Paragraph - This is perhaps the best known database to be found in the pattern recognition literature. Fisher's paper is a classic in the field and is referenced frequently to this day. (See Duda & Hart, for example.) The data set contains three classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other two; the latter are NOT linearly separable from each other.]\n",
    "\n",
    "ANALYSIS: [Sample Paragraph - The baseline performance of the model achieved an average accuracy score of 81.58%. After tuning the hyperparameters, the best model processed the training dataset with an accuracy score of 83.04%. Furthermore, the final model processed the test dataset with an accuracy measurement of 92.11%, which was even better than the accuracy rate from model training.]\n",
    "\n",
    "CONCLUSION: For this dataset, the model built using TensorFlow achieved a satisfactory result and should be considered for future modeling activities.\n",
    "\n",
    "Dataset Used: [PROJECT NAME] Dataset\n",
    "\n",
    "Dataset ML Model: Multi-class classification with numerical attributes\n",
    "\n",
    "Dataset Reference: [https://archive.ics.uci.edu/ml/machine-learning-databases/iris/]\n",
    "\n",
    "One potential source of performance benchmarks: [https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/]\n",
    "\n",
    "Any deep-learning modeling project genrally can be broken down into about five major tasks:\n",
    "\n",
    "1. Prepare Environment\n",
    "2. Load Data\n",
    "3. Define and Fit Model\n",
    "4. Optimize Model\n",
    "5. Finalize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1. Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve GPU configuration information from Colab\n",
    "# gpu_info = !nvidia-smi\n",
    "# gpu_info = '\\n'.join(gpu_info)\n",
    "# if gpu_info.find('failed') >= 0:\n",
    "#     print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "#     print('and then re-execute this cell.')\n",
    "# else:\n",
    "#     print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve memory configuration information from Colab\n",
    "# from psutil import virtual_memory\n",
    "# ram_gb = virtual_memory().total / 1e9\n",
    "# print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "# if ram_gb < 20:\n",
    "#     print('To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"')\n",
    "#     print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
    "#     print('re-execute this cell.')\n",
    "# else:\n",
    "#     print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct Colab to use TensorFlow v2\n",
    "# %tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed number for reproducible results\n",
    "seedNum = 888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and packages\n",
    "import random\n",
    "random.seed(seedNum)\n",
    "import numpy as np\n",
    "np.random.seed(seedNum)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seedNum)\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import smtplib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from email.message import EmailMessage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Begin the timer for the script processing\n",
    "startTimeScript = datetime.now()\n",
    "\n",
    "# Set up the verbose flag to print detailed messages for debugging (setting to True will activate)\n",
    "# verbose = True\n",
    "# tf.debugging.set_log_device_placement(verbose)\n",
    "\n",
    "# Set up the number of CPU cores available for multi-thread processing\n",
    "n_jobs = -1\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Set up the flag to stop sending progress emails (setting to True will send status emails!)\n",
    "notifyStatus = False\n",
    "\n",
    "# Set the number of folds for cross validation\n",
    "n_folds = 5\n",
    "\n",
    "# Set the flag for splitting the dataset\n",
    "splitDataset = True\n",
    "splitPercentage = 0.25\n",
    "\n",
    "# Set various default Keras modeling parameters\n",
    "default_loss = 'categorical_crossentropy'\n",
    "default_metrics = ['accuracy']\n",
    "default_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "default_kernel_init = tf.keras.initializers.he_uniform(seed=seedNum)\n",
    "default_epoch = 50\n",
    "default_batch = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the email notification function\n",
    "def email_notify(msg_text):\n",
    "    sender = os.environ.get('MAIL_SENDER')\n",
    "    receiver = os.environ.get('MAIL_RECEIVER')\n",
    "    gateway = os.environ.get('SMTP_GATEWAY')\n",
    "    smtpuser = os.environ.get('SMTP_USERNAME')\n",
    "    password = os.environ.get('SMTP_PASSWORD')\n",
    "    if sender==None or receiver==None or gateway==None or smtpuser==None or password==None:\n",
    "        sys.exit(\"Incomplete email setup info. Script Processing Aborted!!!\")\n",
    "    msg = EmailMessage()\n",
    "    msg.set_content(msg_text)\n",
    "    msg['Subject'] = 'Notification from Keras Multi-Class Classification Script'\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = receiver\n",
    "    server = smtplib.SMTP(gateway, 587)\n",
    "    server.starttls()\n",
    "    server.login(smtpuser, password)\n",
    "    server.send_message(msg)\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the random number generators\n",
    "def reset_random(x):\n",
    "    random.seed(x)\n",
    "    np.random.seed(x)\n",
    "    tf.random.set_seed(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 1. Prepare Environment completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 2. Load Data has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a) Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>targetVar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width    targetVar\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
       "5           5.4          3.9           1.7          0.4  Iris-setosa\n",
       "6           4.6          3.4           1.4          0.3  Iris-setosa\n",
       "7           5.0          3.4           1.5          0.2  Iris-setosa\n",
       "8           4.4          2.9           1.4          0.2  Iris-setosa\n",
       "9           4.9          3.1           1.5          0.1  Iris-setosa"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "colNames = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'targetVar']\n",
    "Xy_original = pd.read_csv(dataset_path, names=colNames, sep=',', header=None, index_col=False, na_values=['?'])\n",
    "\n",
    "# Take a peek at the dataframe after the import\n",
    "Xy_original.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   targetVar     150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "Xy_original.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_counts = Xy_original.isnull().sum()\n",
    "null_counts[null_counts > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of NaN in the dataframe:  0\n"
     ]
    }
   ],
   "source": [
    "print('Total number of NaN in the dataframe: ', Xy_original.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b) Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>targetVar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width    targetVar\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
       "5           5.4          3.9           1.7          0.4  Iris-setosa\n",
       "6           4.6          3.4           1.4          0.3  Iris-setosa\n",
       "7           5.0          3.4           1.5          0.2  Iris-setosa\n",
       "8           4.4          2.9           1.4          0.2  Iris-setosa\n",
       "9           4.9          3.1           1.5          0.1  Iris-setosa"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the class column to the name of targetVar if required\n",
    "# Xy_original = Xy_original.rename(columns={'old_name': 'targetVar'})\n",
    "\n",
    "# Dropping features\n",
    "# Xy_original.drop(columns=['attribute_name'], inplace=True)\n",
    "\n",
    "# Impute missing values\n",
    "# Xy_original['col_name'].fillna('someValue', inplace=True)\n",
    "# Xy_original['attribute_name'].fillna(value=Xy_original['attribute_name'].median(), inplace=True)\n",
    "\n",
    "# Convert columns from one data type to another\n",
    "# Xy_original.column_name = Xy_original.column_name.astype('int')\n",
    "# Xy_original.column_name = Xy_original.column_name.astype('category')\n",
    "\n",
    "# Convert features with Y/N levels into categorical feature of 1/0\n",
    "# def reClassSomecol(target):\n",
    "#     if (target == 'Y'): return 1\n",
    "#     else: return 0\n",
    "# Xy_original['targetVar'] = Xy_original['target'].apply(reClassSomecol)\n",
    "# Xy_original.drop(columns=['target'], inplace=True)\n",
    "\n",
    "# Take a peek at the dataframe after the cleaning\n",
    "Xy_original.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   targetVar     150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "Xy_original.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_counts = Xy_original.isnull().sum()\n",
    "null_counts[null_counts > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of NaN in the dataframe:  0\n"
     ]
    }
   ],
   "source": [
    "print('Total number of NaN in the dataframe: ', Xy_original.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.c) Feature Scaling and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use variable totCol to hold the number of columns in the dataframe\n",
    "totCol = len(Xy_original.columns)\n",
    "\n",
    "# Set up variable totAttr for the total number of attribute columns\n",
    "totAttr = totCol-1\n",
    "\n",
    "# targetCol variable indicates the column location of the target/class variable\n",
    "# If the first column, set targetCol to 1. If the last column, set targetCol to totCol\n",
    "# If (targetCol <> 1) and (targetCol <> totCol), be aware when slicing up the dataframes for visualization\n",
    "targetCol = totCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xy_original.shape: (150, 5) X_original.shape: (150, 4) y_original.shape: (150,)\n"
     ]
    }
   ],
   "source": [
    "# We create attribute-only and target-only datasets (X_original and y_original)\n",
    "# for various visualization and cleaning/transformation operations\n",
    "\n",
    "if targetCol == totCol:\n",
    "    X_original = Xy_original.iloc[:,0:totAttr]\n",
    "    y_original = Xy_original.iloc[:,totAttr]\n",
    "else:\n",
    "    X_original = Xy_original.iloc[:,1:totCol]\n",
    "    y_original = Xy_original.iloc[:,0]\n",
    "\n",
    "print(\"Xy_original.shape: {} X_original.shape: {} y_original.shape: {}\".format(Xy_original.shape, X_original.shape, y_original.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the number of row and columns for visualization display. dispRow * dispCol should be >= totAttr\n",
    "dispCol = 4\n",
    "if totAttr % dispCol == 0 :\n",
    "    dispRow = totAttr // dispCol\n",
    "else :\n",
    "    dispRow = (totAttr // dispCol) + 1\n",
    "    \n",
    "# Set figure width to display the data visualization plots\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = dispCol*4\n",
    "fig_size[1] = dispRow*4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6UAAAEICAYAAACnPFJfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3df7itdV3n/+cLAUGOhQbtEKjDjGZjncQ8kX7pWzvMBsURnRwujTFOaceamLR2k2gzhb8m7BLN0ss6BnJsUCGUEUFLh9gwfMdwBFFA7CviMcEDqElwbL7Ypvf3j3WfXGz2j7XXXmvd9177+biufe217p+vda/1Wev+3Pfn/typKiRJkiRJasMBbQeQJEmSJG1eVkolSZIkSa2xUipJkiRJao2VUkmSJElSa6yUSpIkSZJaY6VUkiRJktQaK6UbTJILkrx+lWlmk9wxqUyL1n12kv/WxrqlLhuk7K5hWacn+egK4+eTvHQSWaRplKSSPH6VaVorR0n2JPnpNtYtdd0g5XcNy/pIkjOWGbe1WdeBk8gy7ayUtmwj/7C0WfmV2tZm2a2qC6vqZwaZNsmOJNeOO5Ok8fAgktSeqnpWVe0eZNrVDghrZVZKJUmSJEmtsVI6Is1Zk1cl+WySbyR5V5JDmnHPSXJjknuT/K8kP9wM/zPge4EPJdmX5Lea4X+e5K4kf5/kmiQ/uM5sj0vy/iRfTfLFJL/WN+7sJBcneXeS+5PckmR73/gfSfKpZtyfJ7koyeuTHAZ8BHhck31fksc1sx283PKkrulS2U1ydZKfbR6f2DT7OaV5/owkNzaPH3L2M8kzk3yuWe/bgDTD/xXwx8DTm5z39q3uMUmuaMrpdUn+5XBbUBq/JK9Mcmfzef2bpjwckOSsJF9I8vXmt+yxzfT7m9XtTPKVJHuT/Gbf8k5I8vGmbO9N8rYkB68z45LfF824PUl+M8lnmnJ60f7vmWb8bzU5vpLkpU32xyfZCZwO/FZThj/Ut8rjl1ue1CVdK79JjmvmPaB5/s4k9/SN/7Mkr2ge//PZzySPSPKmJF9LcjtwSt88bwD+b+BtTVl9W98qfzrJ55t1vj1JhtuS081K6WidDvxr4F8C3w/85yRPAc4HXgZ8F/AnwGVJHllVLwb+Fvg3VbWlqn6/Wc5HgCcA3w3cAFw4bKCmwH0I+DRwNPAM4BVJ/nXfZM8F3gccDlwGvK2Z92DgUuAC4LHAe4HnA1TVN4FnAV9psm+pqq+stDypw7pSdq8GZpvHPwncDvxE3/OrF8+Q5AjgA8B/Bo4AvgCcCFBVtwK/DHy8yXl436wvBF4DPAa4DXjDGrNKE5HkicCZwI9W1aPpldU9wH8EnkevbDwO+Abw9kWz/xS9MvkzwCvz7Sb3DwK/Tq/MPJ3eb+N/WEfGZb8v+iY7DTgZOA74YWBHM+/JwG8APw08nm9/B1BVu+h9j/x+U4b/zWrLk7qki+W3qr4I3Ac8pRn0E8C+5kAuLPN7C/wS8Jxmvu3AC/qW+dvA/wTObMrqmX3zPQf4UXrl9LRmG2gRK6Wj9baq+nJV/R29HbwXATuBP6mq66rqwaZd+gPA05ZbSFWdX1X3V9UDwNnAk5N855CZfhQ4sqpeW1XfqqrbgXfS2yHd79qq+nBVPQj8GfDkZvjTgAOBP6yqf6yqDwCfGGCdyy1P6qqulN2r6f0YQu9H8vf6ni/3I/ls4JaquqSq/hH4A+CuAdZ1aVV9oqoW6O30Hr+GnNIkPQg8EnhSkoOqak9VfYHeAZffrqo7+srcC/LQTkdeU1XfrKqbgHfRK9tU1fVV9ddVtVBVe+hVIn+S4Q3yffGHVfWV5nvmQ3y7zJ0GvKuqbqmqf2hexyCWW57UJV0tv1cDP5nke5rnlzTPjwO+g97JnMVOA/6gb3/h9wZc1zlVdW9V/S1wFZbVJVkpHa0v9z3+Er0jP98HzDWn7O9tms8d24x7mKZpwDlNc4b76B1Ngt7RoGF8H70mtv3rfzUw0zdN/w7sPwCHNF8KjwPurKpa5jUuZ7nlSV3VlbL7ceD7k8zQ+9F6N3Bsczb0BOCaJeZ5XH/+prwOU063rCGnNDFVdRvwCno7rfckeV96l4t8H3BpX/m8ld4OcP/v21JlmyTfn+Ty9Jrb3wf8V4b/nYXBvi+WK3MPKcMMVn5XWp7UGR0uv/tbJv0Evd/WeXoV258E/mdV/dMS8ywuq18acF2W1QFYKR2tY/sefy/wFXof3jdU1eF9f4+qqvc209WiZfwccCq9ZjzfCWxthg/b/vzLwBcXrf/RVfXsAebdCxy9qO17/2tcnF3aqDpRdpuzJNcDLwdurqpvAf+LXtO+L1TV15aYbW9//qa8Wk41VarqPVX14/R2ZAt4I70y+qxFZfSQqrqzb9alyjbAO4DPAU+oqu+gd7B2Pdd5rfZ9sZK9wDHLZAbLsDa4jpbfq+ldAzrbPL6W3qUvy7VKgkW/t02mfpbVdbBSOlq/muSY5kLt3wYuotdU9peT/Fh6DktySpJHN/PcDfyLvmU8ml6Tn68Dj6J39Gc9PgHc31xkfmhzNueHkvzoAPN+nN5RqzOTHJjkVHpna/a7G/iudTQtlrqiS2X3anrX3+z/UZxf9HyxK4AfTPJvmxYJvwZ8T9/4u4Fj1tIJhNQlSZ6Y5KTm+sz/D/g/wD/R68TrDUm+r5nuyOZ3qt9/SfKo9Dod+wV6ZRt65fU+eteR/QDwK+uMudr3xUouBn4hyb9K8ijgvywav/i7Rtowulp+q+rzTZZ/D1xdVffRK2s/y/K/txcDv9bsLzwGOGvReMvqOlgpHa33AB+l1znJF4DXV9Un6V0Y/TZ6F3HfxkM7I/g9ep2q3Jtez2Lvptcc4E7gs8BfrydQc13nc+g1Bfwi8DXgT+mdyVlt3m8B/xZ4CXAvvYJ7Ob0db6rqc/Q6P7q9yb9ks0ZpA+hS2b2a3g/uNcs8f4jm7Om/A86hVyF+AvD/9E3yV8AtwF1JljrTKnXdI+l9vr9GrxncdwOvAt5KrzO9jya5n16Z+7FF815Nr+xeCbypqj7aDP9Neq0b7qdXobyIdRjg+2KleT8C/CG9a81u49vfHQ80/8+jdz3evUn++3pySi3ocvm9Gvh6VX2573nodVS4lHcCf0nvetMb6HUy2O+t9K6L/UaSPxwy06aVh14uqGEl2QO8tKr+R9tZxinJdcAfV9W72s4ijcJmKbvSZpJkK70DsQc1nXltGOn1AHoz8MiNll0ahY1cfjU8z5RqRUl+Msn3NM13z6DXnfVftJ1LkqRpkeT5SR7ZNAl8I/Ahd8YlbSZWSjeoJK9O7+a8i/8+MuJVPZFeM4V7gTngBVW1d8TrkDaNCZZdSeuU5JZlyuvpI17Vy4B76F0+8CDrv8ZV2vQmWH41AjbflSRJkiS1xjOlkiRJkqTWHDjJlR1xxBG1devWSa5yRd/85jc57LDD2o4xNtP++qAbr/H666//WlUd2WqIMTniiCPqyCOPbH0b79eF97tLOaA7WbqSA1bPMu1ltku/s4t16XOyFuaerMW5N3OZ7cp72JUc0J0sXckB3cmyP8dQZbaqJvb31Kc+tbrkqquuajvCWE3766vqxmsEPlkTLEeT/HvqU5/aiW28X1eydCVHVXeydCVH1epZpr3MdlmXPidrYe7JWpx7M5fZrryHXclR1Z0sXclR1Z0s+3MMU2ZtvitJkiRJao2VUkmSJElSa6yUSpIkSZJaY6VUkiRJktQaK6WSJEmSpNZYKZUkSZIktcZKqSRJkiSpNVZKJUmSJEmtsVIqSZIkSWrNgW0H6Lf1rCvWvYw955wygiSSBmGZldSG9X73+L0jbSz9ZX5u2wI7hvgOsNx3m2dKJUmSJEmtsVIqTakkj0jyqSSXN8+PS3JdktuSXJTk4LYzSpIkSVZKpen1cuDWvudvBN5SVY8HvgG8pJVUkiRJUh8rpdIUSnIMcArwp83zACcBlzST7Aae1046SZIk6ds61dGRpJH5A+C3gEc3z78LuLeqFprndwBHLzVjkp3AToCZmRn27dvH/Pz8kiuZ27aw5PC1WG7ZS1kpyyR1JQd0J0tXckC3skiSpNVZKZWmTJLnAPdU1fVJZtc6f1XtAnYBbN++vbZs2cLs7NKLGab3u8X2nL70spcyPz+/bJZJ6koO6E6WruSAbmWRJEmrs1IqTZ8TgecmeTZwCPAdwFuBw5Mc2JwtPQa4s8WMkrSheVsaSRqdVa8pTXJIkk8k+XSSW5K8phl+QZIvJrmx+Tt+/HElraaqXlVVx1TVVuCFwF9V1enAVcALmsnOAD7YUkRJkiTpnw1ypvQB4KSq2pfkIODaJB9pxv2nqrpkhXkldccrgfcleT3wKeC8lvNIkiRJq1dKq6qAfc3Tg5q/GmcoSaNRVfPAfPP4duCENvNIkiRJiw10TWmSRwDXA48H3l5V1yX5FeANSX4HuBI4q6oeWGLeh/TkuVKPiJu1J89xmfbXB5vjNUqSJEnTbKBKaVU9CByf5HDg0iQ/BLwKuAs4mF5Pna8EXrvEvA/pyXOlHhE3a0+e4zLtrw82x2uUNN2SHAu8G5ih1xJpV1W9NcnZwC8BX20mfXVVfbidlJIkjc+qHR31q6p76XWWcnJV7a2eB4B3YbNASZKGsQDMVdWTgKcBv5rkSc24t1TV8c2fFVKpA+wEVBq9Vc+UJjkS+MequjfJocAzgTcmOaqq9iYJ8Dzg5jFnlSRp6lTVXmBv8/j+JLcCR7ebStIK7ARUGrFBmu8eBexuris9ALi4qi5P8ldNhTXAjcAvjzGnJElTL8lW4CnAdfTuOXxmkp8HPknvbOo3lphn4L4b2jaqfgDW2wfFWjMslXvSGYaxUftd6HpuOwGVRm+Q3nc/Q+8HcvHwk8aSSJKkTSjJFuD9wCuq6r4k7wBeR29n93XAucAvLp5vLX03tG1U/QCstw+KtfQ/AUvnnnSGYWzUfhc2Qu5JdQLalQp62zn6DwLNHDrcQaFR5297m/TrSpb15BiooyNJkjQ+TRPA9wMXVtUHAKrq7r7x7wQubymepEUm1QloVyrobefoPwg0t22Bc29aexVm1AeC2t4m/bqSZT051tTRkSRJGq2mb4bzgFur6s19w4/qm+z52HeD1Dl2AiqNhmdKJUlq14nAi4GbktzYDHs18KKm984C9gAvayeepH52AiqNnpVSSZJaVFXX0us0cDFvASN1k52ASiNmpVSSJEkakJ2ASqPnNaWSJEmSpNZYKZUkSZIktcZKqSRJkiSpNVZKJUmSJEmtsVIqSZIkSWqNlVJpyiQ5JMknknw6yS1JXtMMvyDJF5Pc2Pwd33ZWSZIkyVvCSNPnAeCkqtqX5CDg2iQfacb9p6q6pMVskiRJ0kNYKZWmTFUVsK95elDzV+0lkiRJkpZnpVSaQkkeAVwPPB54e1Vdl+RXgDck+R3gSuCsqnpgiXl3AjsBZmZm2LdvH/Pz80uuZ27bwrqzLrfspayUZZK6kgO6k6UrOaBbWabR1rOuGHreuW0LzI4uiiRpSlgplaZQVT0IHJ/kcODSJD8EvAq4CzgY2AW8EnjtEvPuasazffv22rJlC7Ozs0uuZ8c6dk7323P60steyvz8/LJZJqkrOaA7WbqSA7qVRZIkrc6OjqQpVlX3AlcBJ1fV3up5AHgXcEK76SRJkiQrpdLUSXJkc4aUJIcCzwQ+l+SoZliA5wE3t5dSkiRJ6rH5rjR9jgJ2N9eVHgBcXFWXJ/mrJEcCAW4EfrnNkJIkSRJYKZWmTlV9BnjKEsNPaiGOJEmStKJVm+8mOSTJJ5J8OsktSV7TDD8uyXVJbktyUZKDxx9XkiRJkjRNBrmm9AHgpKp6MnA8cHKSpwFvBN5SVY8HvgG8ZHwxJUmSJEnTaNXmu1VVwL7m6UHNXwEnAT/XDN8NnA28Y/QRJUmSJGl467nHMsCec04ZURItZaBrSpsOU64HHg+8HfgCcG9VLTST3AEcvcy8O4GdADMzMyve0Hxu28Ky4wa1lhumT/sN1qf99cHmeI2SJEnSNBuoUlpVDwLHN7eZuBT4gUFXUFW7gF0A27dvr5VuaL5jnUcwAPacvvzyF5v2G6xP++uDzfEatTkMewR3btsCO866wiO4kjQhSQ4BrgEeSW9f+pKq+t0kxwHvA76L3smcF1fVt9pLKm0ca7pPaVXdC1wFPB04PMn+Su0xwJ0jziZJkiR1jf2tSCM2SO+7RzZnSElyKPBM4FZ6ldMXNJOdAXxwXCElSZKkLqie5fpbuaQZvht4XgvxpA1pkOa7RwG7m+tKDwAurqrLk3wWeF+S1wOfAs4bY05JkiSpEybV30pX+s5oO0d/vzMzh46mH5q1Wvz6294m/bqSZT05Bul99zPAU5YYfjtwwlBr1YZgL2WSJEkPN6n+VrrSd0bbOfr7nZnbtsC5Nw3ULc5ILe63pu1t0q8rWdaTY03XlEqSJEnqsb8VaTSslEqSJEkDsr8VafQmf+5bkiRJ2rjsb0UaMSulkiRJ0oDsb0UaPZvvSpIkSZJaY6VUkqQWJTk2yVVJPpvkliQvb4Y/NsnHkny++f+YtrNKkjQOVkolSWrXAjBXVU8Cngb8apInAWcBV1bVE4Arm+eSJE0dK6XSlElySJJPJPl0c9blNc3w45Jcl+S2JBclObjtrJKgqvZW1Q3N4/vp9eJ5NHAqsLuZbDfwvHYSSpI0XnZ0JE2fB4CTqmpfkoOAa5N8BPgN4C1V9b4kfwy8BHhHm0ElPVSSrfQ6ULkOmKmqvc2ou4CZZebZCewEmJmZYX5+fqwZ57YtDD3vzKGMJN96MsDaM+zbt+9h80w6wzCWyr0RbNTckoZnpVSaMlVVwL7m6UHNXwEnAT/XDN8NnI2VUqkzkmwB3g+8oqruS/LP46qqktRS81XVLmAXwPbt22t2dnasOXecdcXQ885tW+C0EeRbTwaAPaevLcP8/DyLt+ukMwxjqdwbwUbNLWl4VkqlKdTcO+164PHA24EvAPdW1f5D+3fQax641LwPOeuy0hHr9Z4pgLWdLejK0fNx5Bh2W84c2pu37e3SlfcGupVlUE2rhvcDF1bVB5rBdyc5qqr2JjkKuKe9hJIkjY+VUmkKVdWDwPFJDgcuBX5gDfM+5KzLli1blj1ivd4zBbC2swVdOXo+jhzDbsu5bQuce9OBEznrspKuvDfQrSyDSO+U6HnArVX15r5RlwFnAOc0/z/YQjxJksbOSqk0xarq3iRXAU8HDk9yYHO29BjgznbTSWqcCLwYuCnJjc2wV9OrjF6c5CXAl4DTWsonSdJYWSmVpkySI4F/bCqkhwLPBN4IXAW8AHgfnnWROqOqrgWyzOhnTDKLJEltsFIqTZ+jgN3NdaUHABdX1eVJPgu8L8nrgU/Ray4oSZIktcpKqTRlquoz9G4psXj47cAJk08kSZIkLc9K6ZTaetYVzG1bGElHNJIkSZI0Lge0HUCSJEmStHlZKZUkSZIktWbVSmmSY5NcleSzSW5J8vJm+NlJ7kxyY/P37PHHlSRJkiRNk0GuKV0A5qrqhiSPBq5P8rFm3Fuq6k3jiydJkiRJmmarVkqrai+wt3l8f5JbgaPHHUySJEmSNP3W1Ptukq30bjVxHXAicGaSnwc+Se9s6jeWmGcnsBNgZmaG+fn5ZZc/t21hLXGWtNLyF9u3b9+apt9I5rYtMHPoaLbpsCaxbaf5PZQkSd2T5Fjg3cAMUMCuqnprkrOBXwK+2kz66qr6cDsppY1l4Eppki3A+4FXVNV9Sd4BvI5eYXwdcC7wi4vnq6pdwC6A7du31+zs7LLrGMXtS/acvvzyF5ufn2elPBvZjuaWMOfe1N5df9byXgxrmt9DSZLUSV7aJo3YQDWWJAfRq5BeWFUfAKiqu/vGvxO4fCwJJUmSpszWURyIP+eUESTRWnlpmzR6g/S+G+A84NaqenPf8KP6Jns+cPPo40mSJEndtOjSNuhd2vaZJOcneUxrwaQNZpAzpScCLwZuSnJjM+zVwIuSHE+v+e4e4GVjSShJkiR1zLCXtq2lv5Wu9J3Rdo7+PlLa6jNl8etve5v060qW9eQYpPfda4EsMcoLtyVJkrTprOfStrX0t9KVvjPaztHf70xbfaYs7iul7W3SrytZ1pNj1ea7kiRJknq8tE0avfa6ZpUkSZI2Hi9tk0bMSqkkSZI0IC9tk0bPSqkkSZKksRnFLZA03bymVJoySY5NclWSzya5JcnLm+FnJ7kzyY3N37PbzipJkiR5plSaPgvAXFXdkOTRwPVJPtaMe0tVvanFbJIkSdJDWCmVpkxV7QX2No/vT3IrcHS7qSRJkqSl2XxXmmJJtgJPAa5rBp2Z5DNJzk/ymNaCSZIkSQ3PlEpTKskWejf2fkVV3ZfkHcDr6HVV/zrgXOAXl5hvJ7ATYGZmhn379jE/P7/kOua2Law753LLXspKWSZpHDmG3ZYzh/bmbXu7dOW9gW5lkSRJq7NSKk2hJAfRq5BeWFUfAKiqu/vGvxO4fKl5q2oXsAtg+/bttWXLFmZnZ5dcz44R9Ka35/Sll72U+fn5ZbNM0jhyDLst57YtcO5NB65pO45DV94b6FYWSZK0OpvvSlMmSYDzgFur6s19w4/qm+z5wM2TziZJkiQt5plSafqcCLwYuCnJjc2wVwMvSnI8vea7e4CXtRNPktq11nsmzm1bGEnLEEnS0qyUSlOmqq4FssSoD086iyRJkrQam+9KkiRJklrjmVJJkiRJS9p61hU2YdfYeaZUkiRJktQaK6WSJLUoyflJ7klyc9+ws5PcmeTG5u/ZbWaUJGmcrJRKktSuC4CTlxj+lqo6vvmzozJJ0tTymlJJErD222T023+90Z5zThlhos2hqq5JsrXtHJIktWXVSmmSY4F3AzP07m+4q6remuSxwEXAVnr3PDytqr4xvqiSJG0qZyb5eeCTwNxyv7FJdgI7AWZmZpifnx9rqLltC0PPO3MoI8m3ngzDmDl08uscxGrbct++fWP/PIzDRs0taXiDnCldoPdjeEOSRwPXJ/kYsAO4sqrOSXIWcBbwyvFFlSRp03gH8Dp6B4NfB5wL/OJSE1bVLmAXwPbt22t2dnaswdbTA+fctgVOG0G+SfcCOrdtgXNv6l7jsj2nz644fn5+nnF/HsZho+aWNLxVrymtqr1VdUPz+H7gVuBo4FRgdzPZbuB54wopSdJmUlV3V9WDVfVPwDuBE9rOJEnSuKzpsF9zzctTgOuAmara24y6i17z3qXmGbhZ0Siaxqylucc0Nw+Z27bQenOjSWzbaX4PJW1eSY7q+419PnDzStNLmhwvbZNGb+BKaZItwPuBV1TVfUn+eVxVVZJaar61NCsaRXOc1Zqy9Jvm5iE7mhsdt9ncaC3vxbCm+T2UtDkkeS8wCxyR5A7gd4HZJMfT2+HdA7ystYCSFvPSNmnEBqqxJDmIXoX0wqr6QDP47v1HcpMcBdwzrpCSJE2rqnrREoPPm3gQSQNpWjHsbR7fn6T/0rbZZrLdwDxWSqWBDNL7buj9ON5aVW/uG3UZcAZwTvP/g2NJKEmSJHXQuC9t68JlSl24JKxfW1kWvw9deG/260qW9eQY5EzpicCLgZuS3NgMezW9yujFSV4CfAk4bagEkiRp01jP/XClLpnEpW1duEypC5eE9Wsry+LL0rrw3uzXlSzrybHqO1pV1wJZZvQzhlqrJEmStEF5aZs0WqveEkaSJElSzwCXtoGXtklr0o3z8JIkSdLG4KVt0ohZKZWmjPdPkyRpfLy0TRo9m+9K02f//dOeBDwN+NUkT6J3v7Qrq+oJwJXNc0mSJKlVVkqlKVNVe6vqhubx/UD//dN2N5PtBp7XTkJJkiTp22y+q7EZRbf/e845ZQRJNq9R3D9tpXtOjeI+YWu5n9U03IdrOcNuy/33axtFnvW8n6PMsV5d+ZxIkqTBWCmVptSo7p+2ZcuWZe85tWMUBx4W3fdrJdNwH67lDLst99+vbS3bcdQZRp1jvbryOZEkSYOx+a40hVa6f1oz3vunSZIkqROslEpTxvunSZIkaSOx+a40fbx/miRJkjYMK6XSlPH+aZIkSdpIbL4rSZIkSWqNlVJJkiRJUmuslEqSJEmSWmOlVJIkSZLUGiulkiRJkqTWWCmVJEmSJLXGSqkkSZIkqTVWSiVJkiRJrVm1Uprk/CT3JLm5b9jZSe5McmPz9+zxxpQkSZIkTaNBzpReAJy8xPC3VNXxzd+HRxtLkiRJkrQZrFopraprgL+bQBZJkiSp02xFKI3egeuY98wkPw98Epirqm8sNVGSncBOgJmZGebn55dd4Ny2hXXE6Vlp+Yvt27dvTdNvJHPbFpg5dDTbtE2rvT/T/B5KkqROugB4G/DuRcPfUlVvmnwcaeMbtlL6DuB1QDX/zwV+cakJq2oXsAtg+/btNTs7u+xCd5x1xZBxvm3P6csvf7H5+XlWyrOR7TjrCua2LXDuTes57tC+1d7PaX4PJUlS91TVNUm2tp1DmiZD1Viq6u79j5O8E7h8ZIkkSZKkjWfkrQi70CKsa63v2sqy+H3ownuzX1eyrCfHUJXSJEdV1d7m6fOBm1eaXpIkSZpiY2lF2IUWYV1rfddWlsWt97rw3uzXlSzryTHILWHeC3wceGKSO5K8BPj9JDcl+QzwU8CvD7V2SZI2uWU6TXlsko8l+Xzz/zFtZpS0sqq6u6oerKp/At4JnNB2JmkjGaT33RdV1VFVdVBVHVNV51XVi6tqW1X9cFU9t++sqaSW2SugtOFcwMNvvXYWcGVVPQG4snkuqaOSHNX31FaE0hoNcp9SSRvLBXhvYWnDWObWa6cCu5vHu4HnTTSUpGXZilAavW40Dpc0MvYKKE2Fmb5WSHcBM8tNuJZOU0ZhPR2MdKmzlLXoau5pvW1a13NX1YuWGHzexINIU8RKqbR5DNUr4Eo7B5v13sLjyDHstty/szyKPKOobEzr+9OmqqoktcL4gTtNGYX13L6tS52lrEVXc0/rbdM2am5Jw+veN6ykcRi6V8AtW7Ysu3OwWe8tPI4cw27L/TvLa9mOo84w6hzr1ZXPyTrdvb+n++ZatXvaDiRJ0rh4Tam0CdgroLThXPqSwXIAAA/HSURBVAac0Tw+A/hgi1kkSRqrqTtTunUNR/rnti087MzAnnNOGXUkqXXeW1jqrqbTlFngiCR3AL8LnANc3HSg8iXgtPYSSpI0XlNXKZU2u2V2cGeTHE+v+e4e4GWtBZT0EMt0mgLwjIkGkSSpJVZKpSljr4DayNbS2mU5F5x82AiSSJKkSfGaUkmSJElSazxTKknSJjGKM9GSJI2aZ0olSZIkSa2xUipJkiRJao2VUkmSJElSa6yUSpIkSZJaY6VUkiRJktQaK6WSJEmSpNZ4Sxh12mq3L5jbtsCOFabZc84po44kSZIkaYQ8UypJkiRJao1nSiVJkiRpzFZrAbiaaW4BuOqZ0iTnJ7knyc19wx6b5GNJPt/8f8x4Y0qSJEmSptEgzXcvAE5eNOws4MqqegJwZfNckiRJmmqesJFGb9VKaVVdA/zdosGnArubx7uB5404lyRJktRFF+AJG2mkhr2mdKaq9jaP7wJmlpswyU5gJ8DMzAzz8/PLLnRu28KQcYYzc+jD17lSvo1kbtvCkq9v2qz2Gqfl/ZQkSd1QVdck2bpo8KnAbPN4NzAPvHJioaQNbt0dHVVVJakVxu8CdgFs3769Zmdnl13WSrf2GIe5bQuce9NDN8Ge02cnmmFcdpx1xZKvb9qs9hqn5f2UJEmdNpYTNvv27Wv9AHvXTnS0lWXx+zDMe7Pe3Mutrwufk/XmGLbGcneSo6pqb5KjgHuGXI6kEUtyPvAc4J6q+qFm2GOBi4CtwB7gtKr6RlsZJUmaVqM8YTM/P89K4yehayc62sqy+ETHMO/Nek/ALXeypQufk/XmGPY+pZcBZzSPzwA+OORyJI3eBXitiyRJk3R3c6IGT9hIazfILWHeC3wceGKSO5K8BDgHeGaSzwM/3TyX1AF2TiZJ0sR5wkZah1XPfVfVi5YZ9YwRZ5E0PkNf67LS9QGjuKZjLdceTMM1E8sZdlvuv7ZmFHnW836OKscoPlNd+ZxImk7NCZtZ4IgkdwC/S+8EzcXNyZsvAae1l1DaeLrROFzSxKz1WpctW7Yse33AKDonW0tnVNNwzcRyht2W+6+tGUWnXut5P0eVYxSfqQtOPqwTnxNJ08kTNtLoWSmVNgc7J5MkSRrS1kUHTee2LUz8ziHTbNiOjiRtLF7rIkmSpE6yUipNGTsnkyRJ0kZi811pyniti9q0uHmTpPFZrbyt1rxwzzmnjD3DIEaRQ9LGZqW0g9ypkyRJkrRZ2HxXkiRJktQaK6WSJEmSpNbYfFeSpI5Ksge4H3gQWKiq7e0mkiRp9KyUSmrVWq6hXqrTji50kOF14Bqzn6qqr7UdQpKkcbH5riRJkiSpNZ4plSSpuwr4aJIC/qSqdi2eIMlOYCfAzMwM8/Pzyy5sbtvCmGIOZubQ9jMMY1pz/9GFH1z3Oua2rXsRD/vM7tu3b8XPsaTpY6VUkqTu+vGqujPJdwMfS/K5qrqmf4KmoroLYPv27TU7O7vswla6Z+UkzG1b4NybNt6uh7nHa8/psw95Pj8/z0qfYw3Oy0u0Udh8V5KkjqqqO5v/9wCXAie0m0iSpNHr/uEzSRqztR5JXqrDJWnUkhwGHFBV9zePfwZ4bcuxJEkaOSulkiR10wxwaRLo/V6/p6r+ot1IkiSNnpVSSZI6qKpuB57cdg5JksbNa0olSZIkSa2xUipJkiRJas26mu8m2QPcDzwILFTV9lGEkiStjd3+S1L73DeWhjOKa0p/qqq+NoLlSJIkSRud+8bSGtnRkbSJeARXkiRJXbPeSmkBH01SwJ9U1a7FEyTZCewEmJmZYX5+ftmFzW1bWGectZk59OHrXCnfpIxqOyz1+qbNaq/xjy784LrXse3o71z3MjrGI7iSJI3HqvvGkh5uvZXSH6+qO5N8N/CxJJ+rqmv6J2gK4y6A7du31+zs7LILm/TN6Oe2LXDuTQ/dBHtOn51ohqWMajss9fqmzSReYxc+E5IkaUNYdd94LSds9u3bt64TJtN4oqMrWdrIsdxnYb2fk1FZT4517c1X1Z3N/3uSXAqcAFyz8lySWuQRXEmSxmSQfeO1nLCZn59npfGrmcYTHV3J0kaO5U6UrPdzMirryTH0lkxyGHBAVd3fPP4Z4LXDLk/SRKz5CO5KR72mpcn9Wl9HV47SQneydCUHdOeIsaTNxX1jaXjrqd7PAJcm2b+c91TVX4wklaSxGOYI7pYtW5Y96jUtTe7X+jq6cpQWupOlKzkALjj5sE4cMZa06bhvLA1p6D2IqrodePIIs0gaI4/gSpI0Pu4bS8PrxmFtSZPgEVxJkjaQm+78+4m3SpLaYKVU2iQ8gitJkqQuOqDtAJIkSZKkzctKqSRJkiSpNVZKJUmSJEmt8ZrSMdjqBemSJEmSNBDPlEqSJEmSWmOlVJIkSZLUGiulkiRJkqTWWCmVJEmSJLXGSqkkSZIkqTX2vitJkiRJHbfcHT7mti2wY0J3/9hzziljWa5nSiVJkiRJrbFSKkmSJElqjZVSSZIkSVJrrJRKkiRJklpjpVSSJEmS1Bp735W0oS3XE50kSZI2Bs+USpIkSZJas65KaZKTk/xNktuSnDWqUJLGwzIrbSyWWWljscxKwxm6UprkEcDbgWcBTwJelORJowomabQss9LGYpmVNhbLrDS89ZwpPQG4rapur6pvAe8DTh1NLEljYJmVNhbLrLSxWGalIaWqhpsxeQFwclW9tHn+YuDHqurMRdPtBHY2T58I/M3wcUfuCOBrbYcYo2l/fdCN1/h9VXVkyxlWtY4y+3Xa38b7deH9hu7kgO5k6UoOWD3LtJfZLv3OLtalz8lamHuyFufezGW2K+9hV3JAd7J0JQd0J8v+HGsus2PvfbeqdgG7xr2eYST5ZFVtbzvHuEz764PN8RonbXGZ7dI27kqWruSA7mTpSg7oVpZJ6PLv7GIb9b0x92Rt1NyDWkuZ7cq26EoO6E6WruSA7mRZT471NN+9Ezi27/kxzTBJ3WSZlTYWy6y0sVhmpSGtp1L6v4EnJDkuycHAC4HLRhNL0hhYZqWNxTIrbSyWWWlIQzffraqFJGcCfwk8Aji/qm4ZWbLJ2BDNndZh2l8fbI7XOBLrKLNd2sZdydKVHNCdLF3JAd3KMrQp+Z1dbKO+N+aerA2Ze0xltivbois5oDtZupIDupNl6BxDd3QkSZIkSdJ6raf5riRJkiRJ62KlVJIkSZLUmk1ZKU1ybJKrknw2yS1JXt52pnFI8ogkn0pyedtZRi3J4UkuSfK5JLcmeXrbmTa6JCcn+ZsktyU5a4nxj0xyUTP+uiRbW8qxI8lXk9zY/L10TDnOT3JPkpuXGZ8kf9jk/EySHxlHjgGzzCb5+75t8jtjyrHqd+cktsuAOSayTTS4JHuS3NS8H59sO8+gNuLvTZIn9n32b0xyX5JXtJ1rEEl+vSnXNyd5b5JD2s40bn63LpnlkCSfSPLpJstrlphm7PslA+aYyH5Js65l9+0ntZ82YJa1b5Oq2nR/wFHAjzSPHw38v8CT2s41htf5G8B7gMvbzjKG17YbeGnz+GDg8LYzbeQ/eh0yfAH4F832/PTiMgH8B+CPm8cvBC5qKccO4G0T2CY/AfwIcPMy458NfAQI8DTguhazzE6inA/y3TmJ7TJgjolsE//W9L7tAY5oO8cQuTf0703zvXoXvZvZt55nlaxHA18EDm2eXwzsaDvXBF63360PzxJgS/P4IOA64GmLppnEfskgOSayX9Ksa9l9+0lsjzVkWfM22ZRnSqtqb1Xd0Dy+H7iV3hfh1EhyDHAK8KdtZxm1JN9Jbyf9PICq+lZV3dtuqg3vBOC2qrq9qr4FvA84ddE0p9LbOQO4BHhGkrSQYyKq6hrg71aY5FTg3dXz18DhSY5qKctEDPjdOfbtshm+w9UNU/J78wzgC1X1pbaDDOhA4NAkBwKPAr7Scp6x87t1ySxVVfuapwc1f4t7Zx37fsmAOSZigH37SeynDZplzTZlpbRfc2r7KfSOfEyTPwB+C/intoOMwXHAV4F3Nc0G/jTJYW2H2uCOBr7c9/wOHv5D9M/TVNUC8PfAd7WQA+Bnm+ZLlyQ5donxkzBo1kl5etO86CNJfnDcK1vhu3Oi22WV7/CJbhOtqoCPJrk+yc62wwxoGn5vXgi8t+0Qg6iqO4E3AX8L7AX+vqo+2m6qyfK79SEZHpHkRuAe4GNVtew2GeN+ySA5YDL7Javt209kewyYBda4TTZ1pTTJFuD9wCuq6r6284xKkucA91TV9W1nGZMD6TVlfEdVPQX4JvCwaw81tT4EbK2qHwY+xrePCm5mN9Brmvdk4I+A/z7OlXXlu3OVHBPdJhrIj1fVjwDPAn41yU+0HWgAG/r3JsnBwHOBP287yyCSPIbe2Z7jgMcBhyX59+2mmhy/Wx+qqh6squOBY4ATkvzQuNa1zhxj3y/p0r79gFnWvE02baU0yUH0CtyFVfWBtvOM2InAc5Psodf88aQk/63dSCN1B3BH35GqS+jtNGh4dwL9R7GOaYYtOU3TrOo7ga9POkdVfb2qHmie/inw1BFnGNQg22wiquq+/c2LqurDwEFJjhjHugb47pzIdlktxyS3iQbTnAWjqu4BLqXXXL/rNvrvzbOAG6rq7raDDOingS9W1Ver6h+BDwD/V8uZJsLv1uU1TeavAk5eNGoS+yWr5pjQfskg+/aT2h6rZhlmm2zKSmnTvvo84NaqenPbeUatql5VVcdU1VZ6zXb+qqqm5khjVd0FfDnJE5tBzwA+22KkafC/gSckOa45sv5C4LJF01wGnNE8fgG9z9Wor6tYNceia2ieS++alzZcBvx8ep5Gr5nZ3jaCJPme/deNJDmB3nf7yH+IBvzuHPt2GSTHpLaJBpPksCSP3v8Y+Blgyd6ku2QKfm9exAZputv4W+BpSR7VlN9n0N53/MT43brkeo5Mcnjz+FDgmcDnFk029v2SQXJMYr9kwH37SeynDZRlmG1y4EhTbhwnAi8GbmraiAO8ujnio43hPwIXNhWX24FfaDnPhlZVC0nOBP6SXk+N51fVLUleC3yyqi6j90P1Z0luo9fpzgtbyvFrSZ4LLDQ5dow6B0CS99LrZfCIJHcAv0uvgwOq6o+BD9PrDfE24B8Y42dwgCwvAH4lyQLwf4AXjuOHiGW+O4Hv7csyie0ySI5JbRMNZga4tNmXPRB4T1X9RbuRBrYhf2+ayv8zgZe1nWVQVXVdkkvoNRFdAD4F7Go31UT43fpwRwG7kzyCXsX34qq6fNL7JQPmmMh+yVJa2B6DZlnzNom/0ZIkSZKktmzK5ruSJEmSpG6wUipJkiRJao2VUkmSJElSa6yUSpIkSZJaY6VUkiRJktQaK6WSJEmSpNZYKZUkSZIkteb/B3tNuyBCeYdEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histograms for each attribute before pre-processing\n",
    "X_original.hist(layout=(dispRow,dispCol))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n"
     ]
    }
   ],
   "source": [
    "tobe_transformed_cols = X_original.columns.tolist()\n",
    "# tobe_transformed_cols.remove('some_column_label')\n",
    "print(tobe_transformed_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.900681</td>\n",
       "      <td>1.032057</td>\n",
       "      <td>-1.341272</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.143017</td>\n",
       "      <td>-0.124958</td>\n",
       "      <td>-1.341272</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.385353</td>\n",
       "      <td>0.337848</td>\n",
       "      <td>-1.398138</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.506521</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>-1.284407</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.021849</td>\n",
       "      <td>1.263460</td>\n",
       "      <td>-1.341272</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2.249683</td>\n",
       "      <td>-0.124958</td>\n",
       "      <td>1.331416</td>\n",
       "      <td>1.447956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.800654</td>\n",
       "      <td>1.047087</td>\n",
       "      <td>1.579429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.674501</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>0.990221</td>\n",
       "      <td>0.790591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.189830</td>\n",
       "      <td>-0.124958</td>\n",
       "      <td>0.592162</td>\n",
       "      <td>0.790591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1.280340</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>0.933356</td>\n",
       "      <td>1.185010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0       -0.900681     1.032057     -1.341272    -1.312977\n",
       "1       -1.143017    -0.124958     -1.341272    -1.312977\n",
       "2       -1.385353     0.337848     -1.398138    -1.312977\n",
       "3       -1.506521     0.106445     -1.284407    -1.312977\n",
       "4       -1.021849     1.263460     -1.341272    -1.312977\n",
       "..            ...          ...           ...          ...\n",
       "135      2.249683    -0.124958      1.331416     1.447956\n",
       "136      0.553333     0.800654      1.047087     1.579429\n",
       "137      0.674501     0.106445      0.990221     0.790591\n",
       "138      0.189830    -0.124958      0.592162     0.790591\n",
       "139      1.280340     0.106445      0.933356     1.185010\n",
       "\n",
       "[140 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply feature scaling and transformation\n",
    "# X_original = X_original.astype(float)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_original[tobe_transformed_cols] = scaler.fit_transform(X_original[tobe_transformed_cols])\n",
    "\n",
    "X_original.head(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histograms for each attribute after pre-processing\n",
    "X_original.hist(layout=(dispRow,dispCol))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.d) Splitting Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot-encoding before splitting into trainig and test\n",
    "# X_original = pd.get_dummies(X_original)\n",
    "# print(X_original.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Encode class values as integers and perform one-hot-encoding\n",
    "# y_encoded = y_original.to_numpy()\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(y_original)\n",
    "y_transformed = encoder.transform(y_original)\n",
    "y_encoded = tf.keras.utils.to_categorical(y_transformed)\n",
    "print(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (112, 4) X_train.type: <class 'numpy.ndarray'>\n",
      "y_train.shape: (112, 3) y_train.type: <class 'numpy.ndarray'>\n",
      "X_test.shape: (38, 4) X_test.type: <class 'numpy.ndarray'>\n",
      "y_test.shape: (38, 3) y_test.type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X_original.to_numpy()\n",
    "if (splitDataset):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=splitPercentage, \n",
    "                                                        stratify=y_encoded, random_state=seedNum)\n",
    "else:\n",
    "    X_train, y_train = X_encoded, y_encoded\n",
    "    X_test, y_test = X_encoded, y_encoded\n",
    "print(\"X_train.shape: {} X_train.type: {}\".format(X_train.shape, type(X_train)))\n",
    "print(\"y_train.shape: {} y_train.type: {}\".format(y_train.shape, type(y_train)))\n",
    "print(\"X_test.shape: {} X_test.type: {}\".format(X_test.shape, type(X_test)))\n",
    "print(\"y_test.shape: {} y_test.type: {}\".format(y_test.shape, type(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 2. Load Data completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3. Define and Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 3. Define and Fit Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the baseline model for benchmarking\n",
    "def create_default_model():\n",
    "    default_model = Sequential()\n",
    "    default_model.add(Dense(10, input_shape=(X_train.shape[1],), activation='relu', kernel_initializer=default_kernel_init))\n",
    "    default_model.add(Dense(3, activation='softmax', kernel_initializer=default_kernel_init))\n",
    "    default_model.compile(loss=default_loss, optimizer=default_optimizer, metrics=default_metrics)\n",
    "    return default_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 7ms/sample - loss: 1.2518 - accuracy: 0.2679 - val_loss: 1.1923 - val_accuracy: 0.3421\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 256us/sample - loss: 1.2218 - accuracy: 0.2768 - val_loss: 1.1602 - val_accuracy: 0.4211\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 1.1897 - accuracy: 0.3214 - val_loss: 1.1300 - val_accuracy: 0.4211\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 1.1606 - accuracy: 0.3750 - val_loss: 1.1007 - val_accuracy: 0.4474\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 1.1311 - accuracy: 0.4107 - val_loss: 1.0728 - val_accuracy: 0.5263\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 257us/sample - loss: 1.1034 - accuracy: 0.4286 - val_loss: 1.0457 - val_accuracy: 0.5263\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 1.0780 - accuracy: 0.4375 - val_loss: 1.0194 - val_accuracy: 0.5263\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 1.0525 - accuracy: 0.4643 - val_loss: 0.9943 - val_accuracy: 0.5789\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 278us/sample - loss: 1.0264 - accuracy: 0.4821 - val_loss: 0.9704 - val_accuracy: 0.6053\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 1.0029 - accuracy: 0.4821 - val_loss: 0.9467 - val_accuracy: 0.6316\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 0.9793 - accuracy: 0.5089 - val_loss: 0.9237 - val_accuracy: 0.6842\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 0.9565 - accuracy: 0.5446 - val_loss: 0.9013 - val_accuracy: 0.6842\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 256us/sample - loss: 0.9353 - accuracy: 0.5446 - val_loss: 0.8789 - val_accuracy: 0.6842\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 0.9150 - accuracy: 0.5625 - val_loss: 0.8571 - val_accuracy: 0.7632\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 0.8942 - accuracy: 0.5982 - val_loss: 0.8367 - val_accuracy: 0.7368\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.8756 - accuracy: 0.6161 - val_loss: 0.8165 - val_accuracy: 0.7632\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.8577 - accuracy: 0.6161 - val_loss: 0.7971 - val_accuracy: 0.7632\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 0.8397 - accuracy: 0.6161 - val_loss: 0.7788 - val_accuracy: 0.7632\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 0.8229 - accuracy: 0.6250 - val_loss: 0.7609 - val_accuracy: 0.7632\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 0.8069 - accuracy: 0.6250 - val_loss: 0.7437 - val_accuracy: 0.7632\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.7916 - accuracy: 0.6250 - val_loss: 0.7267 - val_accuracy: 0.7632\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.7760 - accuracy: 0.6429 - val_loss: 0.7106 - val_accuracy: 0.7632\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 0.7614 - accuracy: 0.6429 - val_loss: 0.6949 - val_accuracy: 0.7632\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 0.7474 - accuracy: 0.6429 - val_loss: 0.6798 - val_accuracy: 0.7632\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.7335 - accuracy: 0.6607 - val_loss: 0.6657 - val_accuracy: 0.7368\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 0.7199 - accuracy: 0.6786 - val_loss: 0.6524 - val_accuracy: 0.7368\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 0.7082 - accuracy: 0.6786 - val_loss: 0.6391 - val_accuracy: 0.7368\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.6957 - accuracy: 0.6786 - val_loss: 0.6263 - val_accuracy: 0.7632\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 0.6844 - accuracy: 0.6786 - val_loss: 0.6139 - val_accuracy: 0.7368\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 253us/sample - loss: 0.6731 - accuracy: 0.6786 - val_loss: 0.6018 - val_accuracy: 0.7368\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 0.6625 - accuracy: 0.6786 - val_loss: 0.5901 - val_accuracy: 0.7368\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.6524 - accuracy: 0.6875 - val_loss: 0.5789 - val_accuracy: 0.7368\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 0.6419 - accuracy: 0.6964 - val_loss: 0.5685 - val_accuracy: 0.7368\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 257us/sample - loss: 0.6328 - accuracy: 0.6964 - val_loss: 0.5578 - val_accuracy: 0.7368\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 360us/sample - loss: 0.6232 - accuracy: 0.7054 - val_loss: 0.5479 - val_accuracy: 0.7368\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 261us/sample - loss: 0.6143 - accuracy: 0.7143 - val_loss: 0.5383 - val_accuracy: 0.7368\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 0.6061 - accuracy: 0.7143 - val_loss: 0.5289 - val_accuracy: 0.7632\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 0.5976 - accuracy: 0.7232 - val_loss: 0.5204 - val_accuracy: 0.7632\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 256us/sample - loss: 0.5898 - accuracy: 0.7411 - val_loss: 0.5123 - val_accuracy: 0.7632\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 0.5822 - accuracy: 0.7500 - val_loss: 0.5044 - val_accuracy: 0.7632\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 275us/sample - loss: 0.5750 - accuracy: 0.7500 - val_loss: 0.4968 - val_accuracy: 0.7632\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 0.5681 - accuracy: 0.7500 - val_loss: 0.4895 - val_accuracy: 0.7632\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 0.5614 - accuracy: 0.7500 - val_loss: 0.4823 - val_accuracy: 0.7632\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 252us/sample - loss: 0.5552 - accuracy: 0.7500 - val_loss: 0.4754 - val_accuracy: 0.7632\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 259us/sample - loss: 0.5489 - accuracy: 0.7500 - val_loss: 0.4688 - val_accuracy: 0.7895\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 0.5428 - accuracy: 0.7589 - val_loss: 0.4626 - val_accuracy: 0.7895\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.5374 - accuracy: 0.7589 - val_loss: 0.4564 - val_accuracy: 0.7895\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.5314 - accuracy: 0.7589 - val_loss: 0.4506 - val_accuracy: 0.7895\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.5263 - accuracy: 0.7589 - val_loss: 0.4446 - val_accuracy: 0.7895\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 0.5212 - accuracy: 0.7589 - val_loss: 0.4388 - val_accuracy: 0.8158\n",
      "Total time for model fitting: 0:00:02.740890\n"
     ]
    }
   ],
   "source": [
    "startTimeModule = datetime.now()\n",
    "\n",
    "# Initialize the baseline model\n",
    "reset_random(seedNum)\n",
    "baseline_model = create_default_model()\n",
    "baseline_hist = baseline_model.fit(X_train, y_train, epochs=default_epoch, batch_size=default_batch,\n",
    "                                   validation_data=(X_test, y_test), verbose=1)\n",
    "print('Total time for model fitting:', (datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize model training hisotry\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12,12))\n",
    "plt.subplot(211)\n",
    "plt.plot(baseline_hist.history['accuracy'], color='blue', label='train')\n",
    "plt.plot(baseline_hist.history['val_accuracy'], color='red', label='test')\n",
    "plt.title('Baseline Model Training Performance (Accuracy)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.subplot(212)\n",
    "plt.plot(baseline_hist.history['loss'], color='blue', label='train')\n",
    "plt.plot(baseline_hist.history['val_loss'], color='red', label='test')\n",
    "plt.title('Baseline Model Training Performance (Loss)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 3. Define and Fit Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4. Optimize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 4. Optimize Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras model required for KerasClassifier\n",
    "def create_customized_model(optimizer, kernel_init):\n",
    "    customized_model = Sequential()\n",
    "    customized_model.add(Dense(10, input_shape=(X_train.shape[1],), activation='relu', kernel_initializer=kernel_init))\n",
    "    customized_model.add(Dense(3, activation='softmax', kernel_initializer=kernel_init))\n",
    "    customized_model.compile(loss=default_loss, optimizer=optimizer, metrics=default_metrics)\n",
    "    return customized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer candidate #1 has the object ID of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fc734eb1250>\n",
      "Optimizer candidate #2 has the object ID of <tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7fc734eb1c10>\n",
      "Optimizer candidate #3 has the object ID of <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7fc734eb1090>\n",
      "Initializer candidate #1 has the object ID of <tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7fc734eb1150>\n",
      "Initializer candidate #2 has the object ID of <tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fc734eb1a50>\n",
      "Initializer candidate #3 has the object ID of <tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7fc7348861d0>\n",
      "\n",
      "Forming the grid-search model #0 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fc734eb1250>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7fc734eb1150>, epochs=50, batch_size=16\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 7ms/sample - loss: 1.2377 - accuracy: 0.2679 - val_loss: 1.1691 - val_accuracy: 0.3947\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 1.1876 - accuracy: 0.3304 - val_loss: 1.1161 - val_accuracy: 0.4211\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 308us/sample - loss: 1.1358 - accuracy: 0.4018 - val_loss: 1.0684 - val_accuracy: 0.5263\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 1.0902 - accuracy: 0.4286 - val_loss: 1.0237 - val_accuracy: 0.5263\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 1.0459 - accuracy: 0.4643 - val_loss: 0.9826 - val_accuracy: 0.6053\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 1.0048 - accuracy: 0.4911 - val_loss: 0.9437 - val_accuracy: 0.6316\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 0.9690 - accuracy: 0.5089 - val_loss: 0.9056 - val_accuracy: 0.6842\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.9324 - accuracy: 0.5536 - val_loss: 0.8700 - val_accuracy: 0.7368\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.8973 - accuracy: 0.5893 - val_loss: 0.8363 - val_accuracy: 0.7368\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.8672 - accuracy: 0.6161 - val_loss: 0.8038 - val_accuracy: 0.7632\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 324us/sample - loss: 0.8378 - accuracy: 0.6161 - val_loss: 0.7738 - val_accuracy: 0.7632\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.8103 - accuracy: 0.6250 - val_loss: 0.7458 - val_accuracy: 0.7632\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.7856 - accuracy: 0.6339 - val_loss: 0.7190 - val_accuracy: 0.7632\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 0.7617 - accuracy: 0.6429 - val_loss: 0.6932 - val_accuracy: 0.7632\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.7373 - accuracy: 0.6607 - val_loss: 0.6700 - val_accuracy: 0.7368\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 0.7165 - accuracy: 0.6786 - val_loss: 0.6473 - val_accuracy: 0.7105\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 312us/sample - loss: 0.6962 - accuracy: 0.6786 - val_loss: 0.6255 - val_accuracy: 0.7368\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 365us/sample - loss: 0.6766 - accuracy: 0.6786 - val_loss: 0.6059 - val_accuracy: 0.7368\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.6591 - accuracy: 0.6875 - val_loss: 0.5871 - val_accuracy: 0.7368\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 0.6427 - accuracy: 0.6964 - val_loss: 0.5699 - val_accuracy: 0.7368\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 0.6276 - accuracy: 0.6964 - val_loss: 0.5532 - val_accuracy: 0.7368\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.6127 - accuracy: 0.7054 - val_loss: 0.5380 - val_accuracy: 0.7368\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.5993 - accuracy: 0.7143 - val_loss: 0.5232 - val_accuracy: 0.7632\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 324us/sample - loss: 0.5865 - accuracy: 0.7232 - val_loss: 0.5093 - val_accuracy: 0.7632\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 330us/sample - loss: 0.5742 - accuracy: 0.7500 - val_loss: 0.4966 - val_accuracy: 0.7632\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 0.5624 - accuracy: 0.7500 - val_loss: 0.4853 - val_accuracy: 0.7632\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.5529 - accuracy: 0.7500 - val_loss: 0.4739 - val_accuracy: 0.7632\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 327us/sample - loss: 0.5423 - accuracy: 0.7589 - val_loss: 0.4634 - val_accuracy: 0.7895\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 324us/sample - loss: 0.5330 - accuracy: 0.7589 - val_loss: 0.4537 - val_accuracy: 0.7895\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.5241 - accuracy: 0.7589 - val_loss: 0.4441 - val_accuracy: 0.7895\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 329us/sample - loss: 0.5159 - accuracy: 0.7589 - val_loss: 0.4349 - val_accuracy: 0.8158\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 0.5077 - accuracy: 0.7589 - val_loss: 0.4263 - val_accuracy: 0.8158\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.4995 - accuracy: 0.7589 - val_loss: 0.4186 - val_accuracy: 0.8158\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.4928 - accuracy: 0.7679 - val_loss: 0.4105 - val_accuracy: 0.8421\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 321us/sample - loss: 0.4853 - accuracy: 0.7679 - val_loss: 0.4034 - val_accuracy: 0.8421\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 0.4790 - accuracy: 0.7768 - val_loss: 0.3963 - val_accuracy: 0.8421\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.4730 - accuracy: 0.7768 - val_loss: 0.3892 - val_accuracy: 0.8421\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 349us/sample - loss: 0.4664 - accuracy: 0.7768 - val_loss: 0.3830 - val_accuracy: 0.8421\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.4605 - accuracy: 0.7768 - val_loss: 0.3773 - val_accuracy: 0.8421\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 0.4551 - accuracy: 0.7857 - val_loss: 0.3716 - val_accuracy: 0.8421\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 0.4498 - accuracy: 0.7946 - val_loss: 0.3660 - val_accuracy: 0.8684\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 329us/sample - loss: 0.4443 - accuracy: 0.7946 - val_loss: 0.3609 - val_accuracy: 0.8684\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 0.4395 - accuracy: 0.7946 - val_loss: 0.3556 - val_accuracy: 0.8684\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 322us/sample - loss: 0.4345 - accuracy: 0.7946 - val_loss: 0.3509 - val_accuracy: 0.8684\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 0.4298 - accuracy: 0.8036 - val_loss: 0.3462 - val_accuracy: 0.8684\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 322us/sample - loss: 0.4251 - accuracy: 0.8036 - val_loss: 0.3420 - val_accuracy: 0.8684\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 0.4212 - accuracy: 0.8036 - val_loss: 0.3375 - val_accuracy: 0.8684\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 305us/sample - loss: 0.4165 - accuracy: 0.8036 - val_loss: 0.3338 - val_accuracy: 0.8684\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 296us/sample - loss: 0.4127 - accuracy: 0.8036 - val_loss: 0.3301 - val_accuracy: 0.8684\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 315us/sample - loss: 0.4087 - accuracy: 0.8036 - val_loss: 0.3262 - val_accuracy: 0.8684\n",
      "\n",
      "Forming the grid-search model #1 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fc734eb1250>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7fc734eb1150>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 7ms/sample - loss: 1.2401 - accuracy: 0.2679 - val_loss: 1.1457 - val_accuracy: 0.4211\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 253us/sample - loss: 1.1590 - accuracy: 0.3750 - val_loss: 1.0478 - val_accuracy: 0.5263\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 1.0602 - accuracy: 0.4643 - val_loss: 0.9584 - val_accuracy: 0.6053\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 0.9733 - accuracy: 0.5446 - val_loss: 0.8770 - val_accuracy: 0.6842\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 0.8943 - accuracy: 0.5714 - val_loss: 0.8044 - val_accuracy: 0.7632\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 0.8284 - accuracy: 0.6250 - val_loss: 0.7419 - val_accuracy: 0.7632\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.7771 - accuracy: 0.6429 - val_loss: 0.6881 - val_accuracy: 0.7632\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.7288 - accuracy: 0.6518 - val_loss: 0.6432 - val_accuracy: 0.7368\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 0.6867 - accuracy: 0.6696 - val_loss: 0.6040 - val_accuracy: 0.7368\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 0.6544 - accuracy: 0.6786 - val_loss: 0.5697 - val_accuracy: 0.7368\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 0.6251 - accuracy: 0.7054 - val_loss: 0.5406 - val_accuracy: 0.7368\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 0.5996 - accuracy: 0.7143 - val_loss: 0.5154 - val_accuracy: 0.7632\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 253us/sample - loss: 0.5788 - accuracy: 0.7411 - val_loss: 0.4940 - val_accuracy: 0.7632\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 0.5609 - accuracy: 0.7500 - val_loss: 0.4750 - val_accuracy: 0.7632\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.5437 - accuracy: 0.7411 - val_loss: 0.4589 - val_accuracy: 0.7895\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 0.5303 - accuracy: 0.7500 - val_loss: 0.4440 - val_accuracy: 0.7895\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 264us/sample - loss: 0.5173 - accuracy: 0.7589 - val_loss: 0.4309 - val_accuracy: 0.8158\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.5052 - accuracy: 0.7679 - val_loss: 0.4195 - val_accuracy: 0.8158\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 0.4953 - accuracy: 0.7679 - val_loss: 0.4085 - val_accuracy: 0.8421\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 252us/sample - loss: 0.4854 - accuracy: 0.7768 - val_loss: 0.3988 - val_accuracy: 0.8421\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 0.4769 - accuracy: 0.7768 - val_loss: 0.3893 - val_accuracy: 0.8421\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 0.4683 - accuracy: 0.7768 - val_loss: 0.3810 - val_accuracy: 0.8421\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 0.4610 - accuracy: 0.7857 - val_loss: 0.3731 - val_accuracy: 0.8684\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 0.4539 - accuracy: 0.7857 - val_loss: 0.3659 - val_accuracy: 0.8684\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 0.4471 - accuracy: 0.7946 - val_loss: 0.3592 - val_accuracy: 0.8684\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 0.4406 - accuracy: 0.7946 - val_loss: 0.3533 - val_accuracy: 0.8684\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 0.4350 - accuracy: 0.7946 - val_loss: 0.3475 - val_accuracy: 0.8684\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 0.4295 - accuracy: 0.8036 - val_loss: 0.3420 - val_accuracy: 0.8684\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 261us/sample - loss: 0.4240 - accuracy: 0.8036 - val_loss: 0.3368 - val_accuracy: 0.8684\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 0.4190 - accuracy: 0.8036 - val_loss: 0.3317 - val_accuracy: 0.8684\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 262us/sample - loss: 0.4144 - accuracy: 0.8036 - val_loss: 0.3269 - val_accuracy: 0.8684\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.4096 - accuracy: 0.8036 - val_loss: 0.3225 - val_accuracy: 0.8684\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.4050 - accuracy: 0.8036 - val_loss: 0.3185 - val_accuracy: 0.8684\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 262us/sample - loss: 0.4010 - accuracy: 0.8036 - val_loss: 0.3146 - val_accuracy: 0.8684\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 0.3967 - accuracy: 0.8036 - val_loss: 0.3110 - val_accuracy: 0.8684\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 0.3928 - accuracy: 0.8036 - val_loss: 0.3074 - val_accuracy: 0.8684\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.3892 - accuracy: 0.8036 - val_loss: 0.3040 - val_accuracy: 0.8684\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 0.3854 - accuracy: 0.8036 - val_loss: 0.3011 - val_accuracy: 0.8684\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 0.3820 - accuracy: 0.8036 - val_loss: 0.2985 - val_accuracy: 0.8684\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 0.3787 - accuracy: 0.8036 - val_loss: 0.2958 - val_accuracy: 0.8684\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 0.3756 - accuracy: 0.8036 - val_loss: 0.2932 - val_accuracy: 0.8684\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 0.3724 - accuracy: 0.8125 - val_loss: 0.2910 - val_accuracy: 0.8684\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 265us/sample - loss: 0.3694 - accuracy: 0.8125 - val_loss: 0.2884 - val_accuracy: 0.8684\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 257us/sample - loss: 0.3664 - accuracy: 0.8125 - val_loss: 0.2862 - val_accuracy: 0.8684\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 0.3635 - accuracy: 0.8125 - val_loss: 0.2839 - val_accuracy: 0.8684\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 252us/sample - loss: 0.3606 - accuracy: 0.8125 - val_loss: 0.2819 - val_accuracy: 0.8684\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 253us/sample - loss: 0.3581 - accuracy: 0.8125 - val_loss: 0.2796 - val_accuracy: 0.8684\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 0.3551 - accuracy: 0.8125 - val_loss: 0.2776 - val_accuracy: 0.8684\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 0.3525 - accuracy: 0.8125 - val_loss: 0.2756 - val_accuracy: 0.8684\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 0.3500 - accuracy: 0.8214 - val_loss: 0.2735 - val_accuracy: 0.8684\n",
      "\n",
      "Forming the grid-search model #2 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fc734eb1250>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7fc734eb1150>, epochs=50, batch_size=64\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 7ms/sample - loss: 1.2557 - accuracy: 0.2679 - val_loss: 1.1840 - val_accuracy: 0.3421\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 1.2132 - accuracy: 0.2768 - val_loss: 1.1279 - val_accuracy: 0.4211\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 208us/sample - loss: 1.1555 - accuracy: 0.3571 - val_loss: 1.0687 - val_accuracy: 0.5263\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 171us/sample - loss: 1.0971 - accuracy: 0.4286 - val_loss: 1.0104 - val_accuracy: 0.5789\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 187us/sample - loss: 1.0374 - accuracy: 0.4732 - val_loss: 0.9548 - val_accuracy: 0.6053\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 191us/sample - loss: 0.9814 - accuracy: 0.5089 - val_loss: 0.9019 - val_accuracy: 0.6579\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 182us/sample - loss: 0.9335 - accuracy: 0.5357 - val_loss: 0.8507 - val_accuracy: 0.7368\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 176us/sample - loss: 0.8853 - accuracy: 0.5982 - val_loss: 0.8044 - val_accuracy: 0.7632\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 197us/sample - loss: 0.8412 - accuracy: 0.6161 - val_loss: 0.7620 - val_accuracy: 0.7632\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 0.8039 - accuracy: 0.6250 - val_loss: 0.7231 - val_accuracy: 0.7632\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 0.7682 - accuracy: 0.6339 - val_loss: 0.6878 - val_accuracy: 0.7632\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.7347 - accuracy: 0.6339 - val_loss: 0.6556 - val_accuracy: 0.7368\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 202us/sample - loss: 0.7063 - accuracy: 0.6696 - val_loss: 0.6261 - val_accuracy: 0.7368\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 0.6816 - accuracy: 0.6786 - val_loss: 0.5988 - val_accuracy: 0.7632\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 185us/sample - loss: 0.6565 - accuracy: 0.6786 - val_loss: 0.5744 - val_accuracy: 0.7368\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 191us/sample - loss: 0.6361 - accuracy: 0.6964 - val_loss: 0.5522 - val_accuracy: 0.7368\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 167us/sample - loss: 0.6169 - accuracy: 0.7054 - val_loss: 0.5321 - val_accuracy: 0.7632\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 193us/sample - loss: 0.5988 - accuracy: 0.7232 - val_loss: 0.5140 - val_accuracy: 0.7632\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 173us/sample - loss: 0.5836 - accuracy: 0.7500 - val_loss: 0.4973 - val_accuracy: 0.7632\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 183us/sample - loss: 0.5696 - accuracy: 0.7411 - val_loss: 0.4823 - val_accuracy: 0.7632\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 165us/sample - loss: 0.5566 - accuracy: 0.7411 - val_loss: 0.4685 - val_accuracy: 0.7895\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.5444 - accuracy: 0.7500 - val_loss: 0.4560 - val_accuracy: 0.7895\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 173us/sample - loss: 0.5338 - accuracy: 0.7500 - val_loss: 0.4444 - val_accuracy: 0.7895\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 210us/sample - loss: 0.5240 - accuracy: 0.7500 - val_loss: 0.4338 - val_accuracy: 0.8158\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 0.5146 - accuracy: 0.7500 - val_loss: 0.4240 - val_accuracy: 0.8158\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 211us/sample - loss: 0.5055 - accuracy: 0.7589 - val_loss: 0.4150 - val_accuracy: 0.8421\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 199us/sample - loss: 0.4982 - accuracy: 0.7589 - val_loss: 0.4066 - val_accuracy: 0.8421\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 194us/sample - loss: 0.4907 - accuracy: 0.7589 - val_loss: 0.3988 - val_accuracy: 0.8421\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 187us/sample - loss: 0.4836 - accuracy: 0.7768 - val_loss: 0.3915 - val_accuracy: 0.8421\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 201us/sample - loss: 0.4772 - accuracy: 0.7768 - val_loss: 0.3846 - val_accuracy: 0.8421\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 187us/sample - loss: 0.4714 - accuracy: 0.7768 - val_loss: 0.3782 - val_accuracy: 0.8421\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 0.4655 - accuracy: 0.7857 - val_loss: 0.3723 - val_accuracy: 0.8684\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 196us/sample - loss: 0.4597 - accuracy: 0.7946 - val_loss: 0.3667 - val_accuracy: 0.8684\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.4549 - accuracy: 0.7946 - val_loss: 0.3615 - val_accuracy: 0.8684\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 193us/sample - loss: 0.4496 - accuracy: 0.7946 - val_loss: 0.3566 - val_accuracy: 0.8684\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 0.4449 - accuracy: 0.7946 - val_loss: 0.3519 - val_accuracy: 0.8684\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 178us/sample - loss: 0.4407 - accuracy: 0.8036 - val_loss: 0.3475 - val_accuracy: 0.8684\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 189us/sample - loss: 0.4362 - accuracy: 0.8036 - val_loss: 0.3433 - val_accuracy: 0.8684\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 0.4318 - accuracy: 0.8036 - val_loss: 0.3395 - val_accuracy: 0.8684\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 191us/sample - loss: 0.4279 - accuracy: 0.8036 - val_loss: 0.3357 - val_accuracy: 0.8684\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 215us/sample - loss: 0.4241 - accuracy: 0.8036 - val_loss: 0.3321 - val_accuracy: 0.8684\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 197us/sample - loss: 0.4203 - accuracy: 0.8036 - val_loss: 0.3287 - val_accuracy: 0.8684\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 200us/sample - loss: 0.4170 - accuracy: 0.8036 - val_loss: 0.3254 - val_accuracy: 0.8684\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 186us/sample - loss: 0.4134 - accuracy: 0.8036 - val_loss: 0.3223 - val_accuracy: 0.8684\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 178us/sample - loss: 0.4101 - accuracy: 0.8036 - val_loss: 0.3193 - val_accuracy: 0.8684\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 192us/sample - loss: 0.4068 - accuracy: 0.8036 - val_loss: 0.3165 - val_accuracy: 0.8684\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 182us/sample - loss: 0.4040 - accuracy: 0.8036 - val_loss: 0.3137 - val_accuracy: 0.8684\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.4007 - accuracy: 0.8036 - val_loss: 0.3111 - val_accuracy: 0.8684\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 203us/sample - loss: 0.3979 - accuracy: 0.8036 - val_loss: 0.3086 - val_accuracy: 0.8684\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 194us/sample - loss: 0.3951 - accuracy: 0.8036 - val_loss: 0.3062 - val_accuracy: 0.8684\n",
      "\n",
      "Forming the grid-search model #3 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fc734eb1250>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fc734eb1a50>, epochs=50, batch_size=16\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 7ms/sample - loss: 1.1910 - accuracy: 0.3571 - val_loss: 1.0852 - val_accuracy: 0.4474\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 1.0665 - accuracy: 0.4286 - val_loss: 0.9425 - val_accuracy: 0.6316\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 314us/sample - loss: 0.9436 - accuracy: 0.5893 - val_loss: 0.8295 - val_accuracy: 0.8158\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 323us/sample - loss: 0.8465 - accuracy: 0.7232 - val_loss: 0.7390 - val_accuracy: 0.8947\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.7701 - accuracy: 0.7589 - val_loss: 0.6632 - val_accuracy: 0.9211\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 0.7064 - accuracy: 0.7768 - val_loss: 0.6008 - val_accuracy: 0.9211\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.6541 - accuracy: 0.7768 - val_loss: 0.5508 - val_accuracy: 0.8947\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 356us/sample - loss: 0.6119 - accuracy: 0.7768 - val_loss: 0.5098 - val_accuracy: 0.8947\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 318us/sample - loss: 0.5738 - accuracy: 0.7768 - val_loss: 0.4779 - val_accuracy: 0.8947\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 326us/sample - loss: 0.5437 - accuracy: 0.7946 - val_loss: 0.4495 - val_accuracy: 0.8947\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.5171 - accuracy: 0.8036 - val_loss: 0.4251 - val_accuracy: 0.9211\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.4952 - accuracy: 0.8125 - val_loss: 0.4039 - val_accuracy: 0.9211\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 326us/sample - loss: 0.4746 - accuracy: 0.8214 - val_loss: 0.3863 - val_accuracy: 0.9211\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 310us/sample - loss: 0.4571 - accuracy: 0.8214 - val_loss: 0.3703 - val_accuracy: 0.9211\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 282us/sample - loss: 0.4416 - accuracy: 0.8214 - val_loss: 0.3572 - val_accuracy: 0.9211\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 292us/sample - loss: 0.4278 - accuracy: 0.8214 - val_loss: 0.3436 - val_accuracy: 0.9211\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 324us/sample - loss: 0.4149 - accuracy: 0.8304 - val_loss: 0.3319 - val_accuracy: 0.9211\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 272us/sample - loss: 0.4026 - accuracy: 0.8214 - val_loss: 0.3219 - val_accuracy: 0.9211\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 327us/sample - loss: 0.3921 - accuracy: 0.8304 - val_loss: 0.3129 - val_accuracy: 0.9211\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 316us/sample - loss: 0.3817 - accuracy: 0.8393 - val_loss: 0.3054 - val_accuracy: 0.9474\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.3722 - accuracy: 0.8482 - val_loss: 0.2971 - val_accuracy: 0.9474\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 330us/sample - loss: 0.3632 - accuracy: 0.8482 - val_loss: 0.2901 - val_accuracy: 0.9474\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 370us/sample - loss: 0.3549 - accuracy: 0.8482 - val_loss: 0.2837 - val_accuracy: 0.9474\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 324us/sample - loss: 0.3469 - accuracy: 0.8571 - val_loss: 0.2772 - val_accuracy: 0.9474\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 347us/sample - loss: 0.3392 - accuracy: 0.8571 - val_loss: 0.2714 - val_accuracy: 0.9474\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.3319 - accuracy: 0.8661 - val_loss: 0.2665 - val_accuracy: 0.9474\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 0.3252 - accuracy: 0.8750 - val_loss: 0.2618 - val_accuracy: 0.9474\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 329us/sample - loss: 0.3183 - accuracy: 0.8750 - val_loss: 0.2576 - val_accuracy: 0.9737\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 0.3116 - accuracy: 0.8929 - val_loss: 0.2535 - val_accuracy: 0.9737\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 329us/sample - loss: 0.3052 - accuracy: 0.9018 - val_loss: 0.2490 - val_accuracy: 0.9737\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 0.2998 - accuracy: 0.9018 - val_loss: 0.2457 - val_accuracy: 0.9737\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 0.2935 - accuracy: 0.9107 - val_loss: 0.2418 - val_accuracy: 0.9737\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 355us/sample - loss: 0.2878 - accuracy: 0.9107 - val_loss: 0.2381 - val_accuracy: 0.9737\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 349us/sample - loss: 0.2827 - accuracy: 0.9107 - val_loss: 0.2347 - val_accuracy: 0.9737\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 0.2770 - accuracy: 0.9107 - val_loss: 0.2319 - val_accuracy: 0.9737\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.2718 - accuracy: 0.9107 - val_loss: 0.2292 - val_accuracy: 0.9737\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 0.2670 - accuracy: 0.9196 - val_loss: 0.2263 - val_accuracy: 0.9737\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.2620 - accuracy: 0.9286 - val_loss: 0.2238 - val_accuracy: 0.9737\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.2573 - accuracy: 0.9375 - val_loss: 0.2216 - val_accuracy: 0.9737\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.2526 - accuracy: 0.9464 - val_loss: 0.2190 - val_accuracy: 0.9737\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 368us/sample - loss: 0.2481 - accuracy: 0.9375 - val_loss: 0.2173 - val_accuracy: 0.9737\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 318us/sample - loss: 0.2437 - accuracy: 0.9375 - val_loss: 0.2155 - val_accuracy: 0.9737\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.2392 - accuracy: 0.9375 - val_loss: 0.2131 - val_accuracy: 0.9737\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 0.2349 - accuracy: 0.9375 - val_loss: 0.2112 - val_accuracy: 0.9737\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.2308 - accuracy: 0.9375 - val_loss: 0.2086 - val_accuracy: 0.9737\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 0.2269 - accuracy: 0.9375 - val_loss: 0.2070 - val_accuracy: 0.9737\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 360us/sample - loss: 0.2232 - accuracy: 0.9375 - val_loss: 0.2051 - val_accuracy: 0.9737\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 0.2193 - accuracy: 0.9375 - val_loss: 0.2034 - val_accuracy: 0.9737\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.2162 - accuracy: 0.9375 - val_loss: 0.2021 - val_accuracy: 0.9737\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 323us/sample - loss: 0.2123 - accuracy: 0.9375 - val_loss: 0.2007 - val_accuracy: 0.9737\n",
      "\n",
      "Forming the grid-search model #4 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fc734eb1250>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fc734eb1a50>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 7ms/sample - loss: 1.2172 - accuracy: 0.3036 - val_loss: 1.1365 - val_accuracy: 0.4211\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 1.1401 - accuracy: 0.3839 - val_loss: 1.0364 - val_accuracy: 0.4474\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 1.0488 - accuracy: 0.4286 - val_loss: 0.9474 - val_accuracy: 0.5789\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 0.9665 - accuracy: 0.5893 - val_loss: 0.8669 - val_accuracy: 0.8158\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.8969 - accuracy: 0.6786 - val_loss: 0.7937 - val_accuracy: 0.8684\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 0.8333 - accuracy: 0.7321 - val_loss: 0.7294 - val_accuracy: 0.8684\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 0.7784 - accuracy: 0.7500 - val_loss: 0.6741 - val_accuracy: 0.9211\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 253us/sample - loss: 0.7323 - accuracy: 0.7679 - val_loss: 0.6252 - val_accuracy: 0.8947\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 259us/sample - loss: 0.6869 - accuracy: 0.7768 - val_loss: 0.5842 - val_accuracy: 0.8947\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 0.6505 - accuracy: 0.7768 - val_loss: 0.5476 - val_accuracy: 0.8947\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 0.6172 - accuracy: 0.7768 - val_loss: 0.5155 - val_accuracy: 0.8947\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 220us/sample - loss: 0.5881 - accuracy: 0.7768 - val_loss: 0.4880 - val_accuracy: 0.9211\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 260us/sample - loss: 0.5617 - accuracy: 0.7946 - val_loss: 0.4647 - val_accuracy: 0.9211\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 0.5386 - accuracy: 0.8036 - val_loss: 0.4436 - val_accuracy: 0.9211\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 252us/sample - loss: 0.5181 - accuracy: 0.8036 - val_loss: 0.4253 - val_accuracy: 0.9211\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 252us/sample - loss: 0.4997 - accuracy: 0.8125 - val_loss: 0.4081 - val_accuracy: 0.9211\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 259us/sample - loss: 0.4832 - accuracy: 0.8214 - val_loss: 0.3933 - val_accuracy: 0.9211\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.4677 - accuracy: 0.8214 - val_loss: 0.3802 - val_accuracy: 0.9211\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 0.4545 - accuracy: 0.8125 - val_loss: 0.3680 - val_accuracy: 0.9211\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 0.4416 - accuracy: 0.8214 - val_loss: 0.3570 - val_accuracy: 0.9211\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.4305 - accuracy: 0.8214 - val_loss: 0.3459 - val_accuracy: 0.9211\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 0.4196 - accuracy: 0.8214 - val_loss: 0.3361 - val_accuracy: 0.9211\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.4098 - accuracy: 0.8214 - val_loss: 0.3270 - val_accuracy: 0.9211\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.4005 - accuracy: 0.8393 - val_loss: 0.3183 - val_accuracy: 0.9211\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 0.3919 - accuracy: 0.8393 - val_loss: 0.3104 - val_accuracy: 0.9211\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 264us/sample - loss: 0.3836 - accuracy: 0.8393 - val_loss: 0.3035 - val_accuracy: 0.9474\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.3760 - accuracy: 0.8393 - val_loss: 0.2971 - val_accuracy: 0.9474\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 0.3689 - accuracy: 0.8482 - val_loss: 0.2911 - val_accuracy: 0.9474\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 0.3618 - accuracy: 0.8482 - val_loss: 0.2852 - val_accuracy: 0.9474\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.3552 - accuracy: 0.8482 - val_loss: 0.2794 - val_accuracy: 0.9474\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 0.3492 - accuracy: 0.8571 - val_loss: 0.2745 - val_accuracy: 0.9737\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 0.3428 - accuracy: 0.8571 - val_loss: 0.2695 - val_accuracy: 0.9737\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 0.3369 - accuracy: 0.8571 - val_loss: 0.2652 - val_accuracy: 0.9737\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.3314 - accuracy: 0.8571 - val_loss: 0.2613 - val_accuracy: 0.9737\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 0.3258 - accuracy: 0.8661 - val_loss: 0.2576 - val_accuracy: 0.9737\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.3205 - accuracy: 0.8750 - val_loss: 0.2540 - val_accuracy: 0.9737\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 0.3154 - accuracy: 0.8750 - val_loss: 0.2505 - val_accuracy: 0.9737\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 0.3104 - accuracy: 0.8839 - val_loss: 0.2475 - val_accuracy: 0.9737\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.3056 - accuracy: 0.8839 - val_loss: 0.2446 - val_accuracy: 0.9737\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 261us/sample - loss: 0.3008 - accuracy: 0.8839 - val_loss: 0.2417 - val_accuracy: 0.9737\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.2963 - accuracy: 0.9018 - val_loss: 0.2394 - val_accuracy: 0.9737\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.2917 - accuracy: 0.9018 - val_loss: 0.2373 - val_accuracy: 0.9737\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 0.2873 - accuracy: 0.9107 - val_loss: 0.2348 - val_accuracy: 0.9737\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 262us/sample - loss: 0.2830 - accuracy: 0.9107 - val_loss: 0.2329 - val_accuracy: 0.9737\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 0.2789 - accuracy: 0.9107 - val_loss: 0.2308 - val_accuracy: 0.9737\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 257us/sample - loss: 0.2749 - accuracy: 0.9196 - val_loss: 0.2294 - val_accuracy: 0.9737\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 0.2710 - accuracy: 0.9196 - val_loss: 0.2275 - val_accuracy: 0.9737\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 259us/sample - loss: 0.2668 - accuracy: 0.9196 - val_loss: 0.2258 - val_accuracy: 0.9737\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.2631 - accuracy: 0.9286 - val_loss: 0.2242 - val_accuracy: 0.9737\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 253us/sample - loss: 0.2595 - accuracy: 0.9375 - val_loss: 0.2225 - val_accuracy: 0.9737\n",
      "\n",
      "Forming the grid-search model #5 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fc734eb1250>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fc734eb1a50>, epochs=50, batch_size=64\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 7ms/sample - loss: 1.2312 - accuracy: 0.2768 - val_loss: 1.1789 - val_accuracy: 0.3421\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 206us/sample - loss: 1.1954 - accuracy: 0.3304 - val_loss: 1.1282 - val_accuracy: 0.4211\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 164us/sample - loss: 1.1470 - accuracy: 0.3750 - val_loss: 1.0748 - val_accuracy: 0.4211\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 1.0967 - accuracy: 0.3929 - val_loss: 1.0215 - val_accuracy: 0.4737\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 1.0487 - accuracy: 0.4375 - val_loss: 0.9701 - val_accuracy: 0.5263\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 170us/sample - loss: 1.0015 - accuracy: 0.5357 - val_loss: 0.9216 - val_accuracy: 0.7632\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 190us/sample - loss: 0.9592 - accuracy: 0.6161 - val_loss: 0.8763 - val_accuracy: 0.8158\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.9206 - accuracy: 0.6786 - val_loss: 0.8337 - val_accuracy: 0.8684\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 0.8816 - accuracy: 0.7232 - val_loss: 0.7938 - val_accuracy: 0.8947\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 190us/sample - loss: 0.8473 - accuracy: 0.7321 - val_loss: 0.7563 - val_accuracy: 0.8947\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 220us/sample - loss: 0.8150 - accuracy: 0.7411 - val_loss: 0.7214 - val_accuracy: 0.8947\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 186us/sample - loss: 0.7837 - accuracy: 0.7589 - val_loss: 0.6892 - val_accuracy: 0.9211\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 186us/sample - loss: 0.7553 - accuracy: 0.7679 - val_loss: 0.6593 - val_accuracy: 0.8947\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 191us/sample - loss: 0.7283 - accuracy: 0.7768 - val_loss: 0.6315 - val_accuracy: 0.8947\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 0.7027 - accuracy: 0.7768 - val_loss: 0.6058 - val_accuracy: 0.8947\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 0.6796 - accuracy: 0.7768 - val_loss: 0.5818 - val_accuracy: 0.8947\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 0.6574 - accuracy: 0.7768 - val_loss: 0.5598 - val_accuracy: 0.8947\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 196us/sample - loss: 0.6368 - accuracy: 0.7857 - val_loss: 0.5394 - val_accuracy: 0.8947\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 198us/sample - loss: 0.6170 - accuracy: 0.7857 - val_loss: 0.5205 - val_accuracy: 0.8947\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 177us/sample - loss: 0.5984 - accuracy: 0.7946 - val_loss: 0.5031 - val_accuracy: 0.8947\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 216us/sample - loss: 0.5814 - accuracy: 0.7946 - val_loss: 0.4869 - val_accuracy: 0.9211\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 199us/sample - loss: 0.5652 - accuracy: 0.7946 - val_loss: 0.4719 - val_accuracy: 0.9211\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 178us/sample - loss: 0.5504 - accuracy: 0.8036 - val_loss: 0.4579 - val_accuracy: 0.9211\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 272us/sample - loss: 0.5364 - accuracy: 0.8036 - val_loss: 0.4448 - val_accuracy: 0.9211\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 207us/sample - loss: 0.5231 - accuracy: 0.8036 - val_loss: 0.4325 - val_accuracy: 0.9211\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 203us/sample - loss: 0.5105 - accuracy: 0.8214 - val_loss: 0.4212 - val_accuracy: 0.9211\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 0.4986 - accuracy: 0.8214 - val_loss: 0.4104 - val_accuracy: 0.9211\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 0.4876 - accuracy: 0.8214 - val_loss: 0.4002 - val_accuracy: 0.9211\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 0.4771 - accuracy: 0.8214 - val_loss: 0.3905 - val_accuracy: 0.9211\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 206us/sample - loss: 0.4672 - accuracy: 0.8214 - val_loss: 0.3813 - val_accuracy: 0.9211\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 190us/sample - loss: 0.4579 - accuracy: 0.8304 - val_loss: 0.3727 - val_accuracy: 0.9211\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 189us/sample - loss: 0.4489 - accuracy: 0.8214 - val_loss: 0.3646 - val_accuracy: 0.9211\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 212us/sample - loss: 0.4407 - accuracy: 0.8214 - val_loss: 0.3569 - val_accuracy: 0.9211\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 204us/sample - loss: 0.4328 - accuracy: 0.8214 - val_loss: 0.3497 - val_accuracy: 0.9211\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 176us/sample - loss: 0.4251 - accuracy: 0.8214 - val_loss: 0.3430 - val_accuracy: 0.9211\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 196us/sample - loss: 0.4179 - accuracy: 0.8304 - val_loss: 0.3365 - val_accuracy: 0.9211\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 193us/sample - loss: 0.4113 - accuracy: 0.8393 - val_loss: 0.3304 - val_accuracy: 0.9211\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.4046 - accuracy: 0.8393 - val_loss: 0.3248 - val_accuracy: 0.9211\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 186us/sample - loss: 0.3983 - accuracy: 0.8393 - val_loss: 0.3194 - val_accuracy: 0.9211\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 190us/sample - loss: 0.3922 - accuracy: 0.8393 - val_loss: 0.3143 - val_accuracy: 0.9211\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 201us/sample - loss: 0.3865 - accuracy: 0.8482 - val_loss: 0.3096 - val_accuracy: 0.9474\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 0.3808 - accuracy: 0.8482 - val_loss: 0.3051 - val_accuracy: 0.9474\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 0.3759 - accuracy: 0.8482 - val_loss: 0.3008 - val_accuracy: 0.9474\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 201us/sample - loss: 0.3705 - accuracy: 0.8482 - val_loss: 0.2967 - val_accuracy: 0.9737\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 294us/sample - loss: 0.3656 - accuracy: 0.8571 - val_loss: 0.2926 - val_accuracy: 0.9737\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 177us/sample - loss: 0.3608 - accuracy: 0.8571 - val_loss: 0.2890 - val_accuracy: 0.9737\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.3563 - accuracy: 0.8571 - val_loss: 0.2854 - val_accuracy: 0.9737\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 196us/sample - loss: 0.3516 - accuracy: 0.8571 - val_loss: 0.2820 - val_accuracy: 0.9737\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 200us/sample - loss: 0.3474 - accuracy: 0.8571 - val_loss: 0.2788 - val_accuracy: 0.9737\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 177us/sample - loss: 0.3432 - accuracy: 0.8571 - val_loss: 0.2757 - val_accuracy: 0.9737\n",
      "\n",
      "Forming the grid-search model #6 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fc734eb1250>, kernel=<tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7fc7348861d0>, epochs=50, batch_size=16\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 7ms/sample - loss: 1.0909 - accuracy: 0.6071 - val_loss: 1.0731 - val_accuracy: 0.6842\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 319us/sample - loss: 1.0518 - accuracy: 0.6607 - val_loss: 1.0019 - val_accuracy: 0.6842\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 323us/sample - loss: 0.9616 - accuracy: 0.6607 - val_loss: 0.8880 - val_accuracy: 0.6842\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.8445 - accuracy: 0.6607 - val_loss: 0.7616 - val_accuracy: 0.6842\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 311us/sample - loss: 0.7277 - accuracy: 0.6607 - val_loss: 0.6541 - val_accuracy: 0.6842\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 0.6397 - accuracy: 0.6607 - val_loss: 0.5767 - val_accuracy: 0.6842\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 0.5797 - accuracy: 0.6607 - val_loss: 0.5241 - val_accuracy: 0.6842\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 0.5423 - accuracy: 0.6607 - val_loss: 0.4891 - val_accuracy: 0.6842\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.5131 - accuracy: 0.6607 - val_loss: 0.4654 - val_accuracy: 0.6842\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.4924 - accuracy: 0.6786 - val_loss: 0.4460 - val_accuracy: 0.7105\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 0.4754 - accuracy: 0.6875 - val_loss: 0.4301 - val_accuracy: 0.7368\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.4614 - accuracy: 0.7054 - val_loss: 0.4170 - val_accuracy: 0.7895\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 319us/sample - loss: 0.4478 - accuracy: 0.7321 - val_loss: 0.4055 - val_accuracy: 0.7895\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 352us/sample - loss: 0.4366 - accuracy: 0.7679 - val_loss: 0.3950 - val_accuracy: 0.8421\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 0.4261 - accuracy: 0.8036 - val_loss: 0.3858 - val_accuracy: 0.8421\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 308us/sample - loss: 0.4171 - accuracy: 0.8036 - val_loss: 0.3758 - val_accuracy: 0.8421\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 298us/sample - loss: 0.4075 - accuracy: 0.8036 - val_loss: 0.3672 - val_accuracy: 0.8421\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 0.3986 - accuracy: 0.8214 - val_loss: 0.3590 - val_accuracy: 0.8684\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 0.3912 - accuracy: 0.8214 - val_loss: 0.3516 - val_accuracy: 0.8684\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.3828 - accuracy: 0.8214 - val_loss: 0.3444 - val_accuracy: 0.8947\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 319us/sample - loss: 0.3755 - accuracy: 0.8304 - val_loss: 0.3366 - val_accuracy: 0.9211\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 0.3680 - accuracy: 0.8482 - val_loss: 0.3293 - val_accuracy: 0.9211\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 324us/sample - loss: 0.3610 - accuracy: 0.8482 - val_loss: 0.3227 - val_accuracy: 0.9211\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 346us/sample - loss: 0.3541 - accuracy: 0.8482 - val_loss: 0.3158 - val_accuracy: 0.9211\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.3475 - accuracy: 0.8482 - val_loss: 0.3094 - val_accuracy: 0.9211\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 306us/sample - loss: 0.3410 - accuracy: 0.8482 - val_loss: 0.3036 - val_accuracy: 0.9211\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 0.3352 - accuracy: 0.8571 - val_loss: 0.2977 - val_accuracy: 0.9474\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 0.3294 - accuracy: 0.8661 - val_loss: 0.2925 - val_accuracy: 0.9737\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 324us/sample - loss: 0.3229 - accuracy: 0.8929 - val_loss: 0.2872 - val_accuracy: 0.9737\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 313us/sample - loss: 0.3171 - accuracy: 0.8929 - val_loss: 0.2817 - val_accuracy: 0.9737\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 312us/sample - loss: 0.3123 - accuracy: 0.8929 - val_loss: 0.2770 - val_accuracy: 0.9737\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 0.3061 - accuracy: 0.8929 - val_loss: 0.2718 - val_accuracy: 0.9737\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 330us/sample - loss: 0.3006 - accuracy: 0.8929 - val_loss: 0.2670 - val_accuracy: 0.9737\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 329us/sample - loss: 0.2959 - accuracy: 0.9018 - val_loss: 0.2623 - val_accuracy: 0.9737\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 0.2904 - accuracy: 0.9018 - val_loss: 0.2582 - val_accuracy: 0.9737\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.2855 - accuracy: 0.9018 - val_loss: 0.2542 - val_accuracy: 0.9737\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 0.2809 - accuracy: 0.9375 - val_loss: 0.2499 - val_accuracy: 0.9737\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 0.2760 - accuracy: 0.9375 - val_loss: 0.2461 - val_accuracy: 0.9737\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 0.2713 - accuracy: 0.9375 - val_loss: 0.2424 - val_accuracy: 0.9737\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 322us/sample - loss: 0.2671 - accuracy: 0.9375 - val_loss: 0.2386 - val_accuracy: 0.9737\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 310us/sample - loss: 0.2628 - accuracy: 0.9375 - val_loss: 0.2354 - val_accuracy: 0.9737\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 319us/sample - loss: 0.2581 - accuracy: 0.9464 - val_loss: 0.2323 - val_accuracy: 0.9737\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 301us/sample - loss: 0.2542 - accuracy: 0.9464 - val_loss: 0.2289 - val_accuracy: 0.9737\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 313us/sample - loss: 0.2498 - accuracy: 0.9554 - val_loss: 0.2257 - val_accuracy: 0.9737\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 0.2459 - accuracy: 0.9554 - val_loss: 0.2224 - val_accuracy: 0.9737\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 327us/sample - loss: 0.2419 - accuracy: 0.9554 - val_loss: 0.2199 - val_accuracy: 0.9737\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 319us/sample - loss: 0.2384 - accuracy: 0.9643 - val_loss: 0.2170 - val_accuracy: 0.9737\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 321us/sample - loss: 0.2343 - accuracy: 0.9643 - val_loss: 0.2146 - val_accuracy: 0.9737\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 327us/sample - loss: 0.2310 - accuracy: 0.9554 - val_loss: 0.2123 - val_accuracy: 0.9737\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 0.2273 - accuracy: 0.9732 - val_loss: 0.2100 - val_accuracy: 0.9737\n",
      "\n",
      "Forming the grid-search model #7 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fc734eb1250>, kernel=<tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7fc7348861d0>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 7ms/sample - loss: 1.0960 - accuracy: 0.4643 - val_loss: 1.0875 - val_accuracy: 0.7368\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 1.0826 - accuracy: 0.6786 - val_loss: 1.0628 - val_accuracy: 0.7368\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 1.0526 - accuracy: 0.6875 - val_loss: 1.0202 - val_accuracy: 0.7368\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 1.0068 - accuracy: 0.6786 - val_loss: 0.9596 - val_accuracy: 0.7105\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 0.9414 - accuracy: 0.6607 - val_loss: 0.8849 - val_accuracy: 0.6842\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 0.8684 - accuracy: 0.6607 - val_loss: 0.8045 - val_accuracy: 0.6842\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 0.7908 - accuracy: 0.6607 - val_loss: 0.7275 - val_accuracy: 0.6842\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 0.7255 - accuracy: 0.6607 - val_loss: 0.6600 - val_accuracy: 0.6842\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 271us/sample - loss: 0.6627 - accuracy: 0.6607 - val_loss: 0.6067 - val_accuracy: 0.6842\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 0.6171 - accuracy: 0.6607 - val_loss: 0.5637 - val_accuracy: 0.6842\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 0.5813 - accuracy: 0.6607 - val_loss: 0.5298 - val_accuracy: 0.6842\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 261us/sample - loss: 0.5522 - accuracy: 0.6607 - val_loss: 0.5033 - val_accuracy: 0.6842\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 0.5298 - accuracy: 0.6607 - val_loss: 0.4820 - val_accuracy: 0.6842\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 258us/sample - loss: 0.5116 - accuracy: 0.6786 - val_loss: 0.4642 - val_accuracy: 0.6842\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 0.4957 - accuracy: 0.6964 - val_loss: 0.4496 - val_accuracy: 0.7368\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 0.4826 - accuracy: 0.6964 - val_loss: 0.4365 - val_accuracy: 0.7632\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 256us/sample - loss: 0.4705 - accuracy: 0.7054 - val_loss: 0.4259 - val_accuracy: 0.7895\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 0.4595 - accuracy: 0.7321 - val_loss: 0.4166 - val_accuracy: 0.8158\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.4508 - accuracy: 0.7679 - val_loss: 0.4080 - val_accuracy: 0.8421\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 0.4415 - accuracy: 0.7857 - val_loss: 0.3998 - val_accuracy: 0.8421\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.4338 - accuracy: 0.8036 - val_loss: 0.3917 - val_accuracy: 0.8421\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 0.4259 - accuracy: 0.8036 - val_loss: 0.3839 - val_accuracy: 0.8421\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 0.4187 - accuracy: 0.8125 - val_loss: 0.3768 - val_accuracy: 0.8684\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 0.4119 - accuracy: 0.8214 - val_loss: 0.3697 - val_accuracy: 0.8684\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 0.4054 - accuracy: 0.8125 - val_loss: 0.3630 - val_accuracy: 0.8684\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 0.3990 - accuracy: 0.8125 - val_loss: 0.3569 - val_accuracy: 0.8684\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 0.3930 - accuracy: 0.8125 - val_loss: 0.3508 - val_accuracy: 0.8684\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 0.3875 - accuracy: 0.8214 - val_loss: 0.3450 - val_accuracy: 0.9211\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.3813 - accuracy: 0.8304 - val_loss: 0.3390 - val_accuracy: 0.9211\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.3759 - accuracy: 0.8304 - val_loss: 0.3331 - val_accuracy: 0.9211\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 290us/sample - loss: 0.3709 - accuracy: 0.8482 - val_loss: 0.3278 - val_accuracy: 0.9211\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 0.3653 - accuracy: 0.8482 - val_loss: 0.3222 - val_accuracy: 0.9211\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 0.3600 - accuracy: 0.8482 - val_loss: 0.3171 - val_accuracy: 0.9211\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 0.3553 - accuracy: 0.8482 - val_loss: 0.3122 - val_accuracy: 0.9211\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 252us/sample - loss: 0.3501 - accuracy: 0.8482 - val_loss: 0.3075 - val_accuracy: 0.9211\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 0.3454 - accuracy: 0.8482 - val_loss: 0.3029 - val_accuracy: 0.9211\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 0.3409 - accuracy: 0.8571 - val_loss: 0.2982 - val_accuracy: 0.9474\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.3361 - accuracy: 0.8661 - val_loss: 0.2939 - val_accuracy: 0.9474\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 0.3316 - accuracy: 0.8661 - val_loss: 0.2898 - val_accuracy: 0.9737\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.3275 - accuracy: 0.8750 - val_loss: 0.2858 - val_accuracy: 0.9737\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 252us/sample - loss: 0.3234 - accuracy: 0.8750 - val_loss: 0.2824 - val_accuracy: 0.9737\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 270us/sample - loss: 0.3187 - accuracy: 0.8839 - val_loss: 0.2790 - val_accuracy: 0.9737\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.3149 - accuracy: 0.8929 - val_loss: 0.2755 - val_accuracy: 0.9737\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 0.3107 - accuracy: 0.8929 - val_loss: 0.2722 - val_accuracy: 0.9737\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.3069 - accuracy: 0.8929 - val_loss: 0.2690 - val_accuracy: 0.9737\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 264us/sample - loss: 0.3029 - accuracy: 0.8929 - val_loss: 0.2664 - val_accuracy: 0.9737\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.2994 - accuracy: 0.8929 - val_loss: 0.2635 - val_accuracy: 0.9737\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 0.2950 - accuracy: 0.9018 - val_loss: 0.2608 - val_accuracy: 0.9737\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 0.2914 - accuracy: 0.9018 - val_loss: 0.2580 - val_accuracy: 0.9737\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 0.2880 - accuracy: 0.9196 - val_loss: 0.2553 - val_accuracy: 0.9737\n",
      "\n",
      "Forming the grid-search model #8 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fc734eb1250>, kernel=<tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7fc7348861d0>, epochs=50, batch_size=64\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 7ms/sample - loss: 1.0977 - accuracy: 0.2679 - val_loss: 1.0939 - val_accuracy: 0.3947\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 178us/sample - loss: 1.0935 - accuracy: 0.4732 - val_loss: 1.0868 - val_accuracy: 0.7368\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 168us/sample - loss: 1.0856 - accuracy: 0.6786 - val_loss: 1.0760 - val_accuracy: 0.8421\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 208us/sample - loss: 1.0742 - accuracy: 0.8036 - val_loss: 1.0604 - val_accuracy: 0.8947\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 1.0574 - accuracy: 0.8036 - val_loss: 1.0398 - val_accuracy: 0.8421\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 211us/sample - loss: 1.0368 - accuracy: 0.7946 - val_loss: 1.0140 - val_accuracy: 0.8158\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 1.0104 - accuracy: 0.7321 - val_loss: 0.9833 - val_accuracy: 0.7368\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 194us/sample - loss: 0.9815 - accuracy: 0.6964 - val_loss: 0.9480 - val_accuracy: 0.6842\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 182us/sample - loss: 0.9463 - accuracy: 0.6696 - val_loss: 0.9093 - val_accuracy: 0.6842\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 173us/sample - loss: 0.9082 - accuracy: 0.6607 - val_loss: 0.8679 - val_accuracy: 0.6842\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 200us/sample - loss: 0.8688 - accuracy: 0.6607 - val_loss: 0.8252 - val_accuracy: 0.6842\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.8272 - accuracy: 0.6607 - val_loss: 0.7827 - val_accuracy: 0.6842\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 0.7869 - accuracy: 0.6607 - val_loss: 0.7414 - val_accuracy: 0.6842\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.7473 - accuracy: 0.6607 - val_loss: 0.7024 - val_accuracy: 0.6842\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.7108 - accuracy: 0.6607 - val_loss: 0.6662 - val_accuracy: 0.6842\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 0.6783 - accuracy: 0.6607 - val_loss: 0.6333 - val_accuracy: 0.6842\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 187us/sample - loss: 0.6475 - accuracy: 0.6607 - val_loss: 0.6042 - val_accuracy: 0.6842\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 199us/sample - loss: 0.6218 - accuracy: 0.6607 - val_loss: 0.5783 - val_accuracy: 0.6842\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 217us/sample - loss: 0.5979 - accuracy: 0.6607 - val_loss: 0.5555 - val_accuracy: 0.6842\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 176us/sample - loss: 0.5779 - accuracy: 0.6607 - val_loss: 0.5355 - val_accuracy: 0.6842\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 209us/sample - loss: 0.5603 - accuracy: 0.6607 - val_loss: 0.5178 - val_accuracy: 0.6842\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 185us/sample - loss: 0.5448 - accuracy: 0.6607 - val_loss: 0.5021 - val_accuracy: 0.6842\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 199us/sample - loss: 0.5309 - accuracy: 0.6786 - val_loss: 0.4881 - val_accuracy: 0.6842\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 205us/sample - loss: 0.5189 - accuracy: 0.6964 - val_loss: 0.4754 - val_accuracy: 0.7368\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 215us/sample - loss: 0.5079 - accuracy: 0.6964 - val_loss: 0.4638 - val_accuracy: 0.7368\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 190us/sample - loss: 0.4976 - accuracy: 0.6964 - val_loss: 0.4534 - val_accuracy: 0.7632\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 196us/sample - loss: 0.4886 - accuracy: 0.7143 - val_loss: 0.4437 - val_accuracy: 0.7895\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 210us/sample - loss: 0.4803 - accuracy: 0.7232 - val_loss: 0.4348 - val_accuracy: 0.7895\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 205us/sample - loss: 0.4722 - accuracy: 0.7232 - val_loss: 0.4265 - val_accuracy: 0.8158\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 189us/sample - loss: 0.4648 - accuracy: 0.7411 - val_loss: 0.4188 - val_accuracy: 0.8158\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 189us/sample - loss: 0.4581 - accuracy: 0.7768 - val_loss: 0.4116 - val_accuracy: 0.8421\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 193us/sample - loss: 0.4514 - accuracy: 0.7679 - val_loss: 0.4048 - val_accuracy: 0.8421\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 0.4451 - accuracy: 0.7946 - val_loss: 0.3984 - val_accuracy: 0.8684\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 187us/sample - loss: 0.4393 - accuracy: 0.7946 - val_loss: 0.3923 - val_accuracy: 0.8684\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 197us/sample - loss: 0.4334 - accuracy: 0.7946 - val_loss: 0.3866 - val_accuracy: 0.8684\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 200us/sample - loss: 0.4280 - accuracy: 0.8036 - val_loss: 0.3812 - val_accuracy: 0.8684\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 192us/sample - loss: 0.4231 - accuracy: 0.8125 - val_loss: 0.3760 - val_accuracy: 0.8684\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 201us/sample - loss: 0.4180 - accuracy: 0.8125 - val_loss: 0.3710 - val_accuracy: 0.8684\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.4130 - accuracy: 0.8125 - val_loss: 0.3662 - val_accuracy: 0.8947\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 208us/sample - loss: 0.4085 - accuracy: 0.8125 - val_loss: 0.3616 - val_accuracy: 0.8947\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 204us/sample - loss: 0.4040 - accuracy: 0.8125 - val_loss: 0.3573 - val_accuracy: 0.9211\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 203us/sample - loss: 0.3994 - accuracy: 0.8214 - val_loss: 0.3531 - val_accuracy: 0.9211\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 214us/sample - loss: 0.3958 - accuracy: 0.8304 - val_loss: 0.3491 - val_accuracy: 0.9211\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 194us/sample - loss: 0.3914 - accuracy: 0.8393 - val_loss: 0.3450 - val_accuracy: 0.9211\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 183us/sample - loss: 0.3874 - accuracy: 0.8393 - val_loss: 0.3409 - val_accuracy: 0.9211\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 213us/sample - loss: 0.3834 - accuracy: 0.8482 - val_loss: 0.3370 - val_accuracy: 0.9211\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 185us/sample - loss: 0.3799 - accuracy: 0.8482 - val_loss: 0.3332 - val_accuracy: 0.9211\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 197us/sample - loss: 0.3758 - accuracy: 0.8482 - val_loss: 0.3294 - val_accuracy: 0.9211\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 0.3723 - accuracy: 0.8482 - val_loss: 0.3258 - val_accuracy: 0.9211\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 0.3687 - accuracy: 0.8482 - val_loss: 0.3223 - val_accuracy: 0.9211\n",
      "\n",
      "Forming the grid-search model #9 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7fc734eb1c10>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7fc734eb1150>, epochs=50, batch_size=16\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 8ms/sample - loss: 1.2049 - accuracy: 0.3036 - val_loss: 1.1141 - val_accuracy: 0.4211\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 1.1316 - accuracy: 0.3839 - val_loss: 1.0591 - val_accuracy: 0.5263\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 310us/sample - loss: 1.0808 - accuracy: 0.4375 - val_loss: 1.0121 - val_accuracy: 0.5526\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 310us/sample - loss: 1.0361 - accuracy: 0.4732 - val_loss: 0.9703 - val_accuracy: 0.6053\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 313us/sample - loss: 0.9942 - accuracy: 0.4821 - val_loss: 0.9300 - val_accuracy: 0.6579\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 0.9550 - accuracy: 0.5357 - val_loss: 0.8919 - val_accuracy: 0.6842\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 329us/sample - loss: 0.9194 - accuracy: 0.5714 - val_loss: 0.8563 - val_accuracy: 0.7632\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 0.8868 - accuracy: 0.6071 - val_loss: 0.8227 - val_accuracy: 0.7368\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 398us/sample - loss: 0.8543 - accuracy: 0.6161 - val_loss: 0.7895 - val_accuracy: 0.7632\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 326us/sample - loss: 0.8241 - accuracy: 0.6250 - val_loss: 0.7583 - val_accuracy: 0.7632\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.7955 - accuracy: 0.6250 - val_loss: 0.7283 - val_accuracy: 0.7632\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 312us/sample - loss: 0.7677 - accuracy: 0.6339 - val_loss: 0.6992 - val_accuracy: 0.7632\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 307us/sample - loss: 0.7410 - accuracy: 0.6607 - val_loss: 0.6718 - val_accuracy: 0.7632\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 314us/sample - loss: 0.7154 - accuracy: 0.6696 - val_loss: 0.6457 - val_accuracy: 0.7105\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.6918 - accuracy: 0.6786 - val_loss: 0.6207 - val_accuracy: 0.7368\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 327us/sample - loss: 0.6693 - accuracy: 0.6786 - val_loss: 0.5977 - val_accuracy: 0.7368\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 0.6484 - accuracy: 0.6875 - val_loss: 0.5756 - val_accuracy: 0.7368\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 309us/sample - loss: 0.6289 - accuracy: 0.6964 - val_loss: 0.5550 - val_accuracy: 0.7368\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 322us/sample - loss: 0.6104 - accuracy: 0.7054 - val_loss: 0.5361 - val_accuracy: 0.7368\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.5941 - accuracy: 0.7232 - val_loss: 0.5187 - val_accuracy: 0.7632\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 0.5781 - accuracy: 0.7321 - val_loss: 0.5024 - val_accuracy: 0.7632\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 0.5633 - accuracy: 0.7500 - val_loss: 0.4867 - val_accuracy: 0.7632\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.5493 - accuracy: 0.7500 - val_loss: 0.4723 - val_accuracy: 0.7895\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.5362 - accuracy: 0.7589 - val_loss: 0.4587 - val_accuracy: 0.7895\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 0.5236 - accuracy: 0.7589 - val_loss: 0.4456 - val_accuracy: 0.7895\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 407us/sample - loss: 0.5119 - accuracy: 0.7589 - val_loss: 0.4329 - val_accuracy: 0.8158\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 0.5015 - accuracy: 0.7589 - val_loss: 0.4224 - val_accuracy: 0.8158\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 322us/sample - loss: 0.4909 - accuracy: 0.7589 - val_loss: 0.4117 - val_accuracy: 0.8421\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 324us/sample - loss: 0.4811 - accuracy: 0.7679 - val_loss: 0.4014 - val_accuracy: 0.8421\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 0.4716 - accuracy: 0.7768 - val_loss: 0.3916 - val_accuracy: 0.8421\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 349us/sample - loss: 0.4626 - accuracy: 0.7768 - val_loss: 0.3826 - val_accuracy: 0.8421\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 0.4540 - accuracy: 0.7857 - val_loss: 0.3741 - val_accuracy: 0.8421\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 330us/sample - loss: 0.4460 - accuracy: 0.7857 - val_loss: 0.3658 - val_accuracy: 0.8684\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.4384 - accuracy: 0.7946 - val_loss: 0.3584 - val_accuracy: 0.8684\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 0.4311 - accuracy: 0.7946 - val_loss: 0.3512 - val_accuracy: 0.8684\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.4244 - accuracy: 0.8036 - val_loss: 0.3445 - val_accuracy: 0.8684\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 0.4180 - accuracy: 0.8036 - val_loss: 0.3386 - val_accuracy: 0.8684\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 314us/sample - loss: 0.4117 - accuracy: 0.8036 - val_loss: 0.3326 - val_accuracy: 0.8684\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.4056 - accuracy: 0.8036 - val_loss: 0.3265 - val_accuracy: 0.8684\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 315us/sample - loss: 0.4002 - accuracy: 0.8036 - val_loss: 0.3211 - val_accuracy: 0.8684\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 321us/sample - loss: 0.3947 - accuracy: 0.8036 - val_loss: 0.3161 - val_accuracy: 0.8684\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 283us/sample - loss: 0.3896 - accuracy: 0.8036 - val_loss: 0.3112 - val_accuracy: 0.8684\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 0.3846 - accuracy: 0.8036 - val_loss: 0.3066 - val_accuracy: 0.8684\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 318us/sample - loss: 0.3795 - accuracy: 0.8036 - val_loss: 0.3019 - val_accuracy: 0.8684\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 323us/sample - loss: 0.3753 - accuracy: 0.8036 - val_loss: 0.2974 - val_accuracy: 0.8684\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 0.3703 - accuracy: 0.8036 - val_loss: 0.2932 - val_accuracy: 0.8684\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 313us/sample - loss: 0.3662 - accuracy: 0.8036 - val_loss: 0.2895 - val_accuracy: 0.8684\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 0.3617 - accuracy: 0.8036 - val_loss: 0.2855 - val_accuracy: 0.8684\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 356us/sample - loss: 0.3577 - accuracy: 0.8036 - val_loss: 0.2819 - val_accuracy: 0.8684\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.3534 - accuracy: 0.8125 - val_loss: 0.2782 - val_accuracy: 0.8684\n",
      "\n",
      "Forming the grid-search model #10 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7fc734eb1c10>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7fc734eb1150>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 8ms/sample - loss: 1.2306 - accuracy: 0.2768 - val_loss: 1.1461 - val_accuracy: 0.4211\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 1.1739 - accuracy: 0.3571 - val_loss: 1.1073 - val_accuracy: 0.4211\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 1.1373 - accuracy: 0.4107 - val_loss: 1.0728 - val_accuracy: 0.5263\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 1.1038 - accuracy: 0.4286 - val_loss: 1.0436 - val_accuracy: 0.5263\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 1.0754 - accuracy: 0.4464 - val_loss: 1.0153 - val_accuracy: 0.5263\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 1.0478 - accuracy: 0.4554 - val_loss: 0.9882 - val_accuracy: 0.6053\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 1.0211 - accuracy: 0.4821 - val_loss: 0.9637 - val_accuracy: 0.6316\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 0.9965 - accuracy: 0.4911 - val_loss: 0.9398 - val_accuracy: 0.6579\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 0.9730 - accuracy: 0.5179 - val_loss: 0.9160 - val_accuracy: 0.6842\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 253us/sample - loss: 0.9497 - accuracy: 0.5446 - val_loss: 0.8922 - val_accuracy: 0.6842\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 0.9277 - accuracy: 0.5536 - val_loss: 0.8689 - val_accuracy: 0.6842\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.9063 - accuracy: 0.5714 - val_loss: 0.8469 - val_accuracy: 0.7632\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 227us/sample - loss: 0.8856 - accuracy: 0.6071 - val_loss: 0.8259 - val_accuracy: 0.7368\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 0.8660 - accuracy: 0.6161 - val_loss: 0.8061 - val_accuracy: 0.7632\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 0.8473 - accuracy: 0.6161 - val_loss: 0.7848 - val_accuracy: 0.7632\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 0.8285 - accuracy: 0.6250 - val_loss: 0.7654 - val_accuracy: 0.7632\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 0.8106 - accuracy: 0.6250 - val_loss: 0.7474 - val_accuracy: 0.7632\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.7939 - accuracy: 0.6250 - val_loss: 0.7283 - val_accuracy: 0.7632\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.7762 - accuracy: 0.6339 - val_loss: 0.7105 - val_accuracy: 0.7632\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 267us/sample - loss: 0.7600 - accuracy: 0.6429 - val_loss: 0.6928 - val_accuracy: 0.7632\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 0.7437 - accuracy: 0.6429 - val_loss: 0.6772 - val_accuracy: 0.7632\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 0.7286 - accuracy: 0.6518 - val_loss: 0.6612 - val_accuracy: 0.7368\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 0.7138 - accuracy: 0.6696 - val_loss: 0.6465 - val_accuracy: 0.7368\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.7003 - accuracy: 0.6875 - val_loss: 0.6323 - val_accuracy: 0.7368\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 0.6871 - accuracy: 0.6875 - val_loss: 0.6185 - val_accuracy: 0.7368\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 252us/sample - loss: 0.6743 - accuracy: 0.6786 - val_loss: 0.6039 - val_accuracy: 0.7368\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 252us/sample - loss: 0.6613 - accuracy: 0.6786 - val_loss: 0.5905 - val_accuracy: 0.7368\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.6491 - accuracy: 0.6786 - val_loss: 0.5764 - val_accuracy: 0.7368\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 0.6367 - accuracy: 0.6964 - val_loss: 0.5635 - val_accuracy: 0.7368\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 253us/sample - loss: 0.6250 - accuracy: 0.6964 - val_loss: 0.5507 - val_accuracy: 0.7368\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.6141 - accuracy: 0.7054 - val_loss: 0.5395 - val_accuracy: 0.7368\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 0.6036 - accuracy: 0.7143 - val_loss: 0.5286 - val_accuracy: 0.7632\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 0.5935 - accuracy: 0.7232 - val_loss: 0.5169 - val_accuracy: 0.7632\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.5832 - accuracy: 0.7321 - val_loss: 0.5070 - val_accuracy: 0.7632\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.5742 - accuracy: 0.7500 - val_loss: 0.4967 - val_accuracy: 0.7632\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 0.5651 - accuracy: 0.7500 - val_loss: 0.4876 - val_accuracy: 0.7632\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 303us/sample - loss: 0.5568 - accuracy: 0.7500 - val_loss: 0.4794 - val_accuracy: 0.7632\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 288us/sample - loss: 0.5483 - accuracy: 0.7500 - val_loss: 0.4708 - val_accuracy: 0.7895\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 0.5406 - accuracy: 0.7500 - val_loss: 0.4626 - val_accuracy: 0.7895\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 0.5333 - accuracy: 0.7589 - val_loss: 0.4543 - val_accuracy: 0.7895\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 262us/sample - loss: 0.5257 - accuracy: 0.7589 - val_loss: 0.4465 - val_accuracy: 0.7895\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 0.5184 - accuracy: 0.7589 - val_loss: 0.4392 - val_accuracy: 0.7895\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.5117 - accuracy: 0.7589 - val_loss: 0.4320 - val_accuracy: 0.8158\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 0.5046 - accuracy: 0.7589 - val_loss: 0.4250 - val_accuracy: 0.8158\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.4985 - accuracy: 0.7589 - val_loss: 0.4182 - val_accuracy: 0.8158\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 261us/sample - loss: 0.4920 - accuracy: 0.7589 - val_loss: 0.4114 - val_accuracy: 0.8421\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 260us/sample - loss: 0.4864 - accuracy: 0.7679 - val_loss: 0.4052 - val_accuracy: 0.8421\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 0.4801 - accuracy: 0.7679 - val_loss: 0.3984 - val_accuracy: 0.8421\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 0.4744 - accuracy: 0.7768 - val_loss: 0.3927 - val_accuracy: 0.8421\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 262us/sample - loss: 0.4689 - accuracy: 0.7768 - val_loss: 0.3872 - val_accuracy: 0.8421\n",
      "\n",
      "Forming the grid-search model #11 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7fc734eb1c10>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7fc734eb1150>, epochs=50, batch_size=64\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 8ms/sample - loss: 1.2516 - accuracy: 0.2589 - val_loss: 1.1781 - val_accuracy: 0.3684\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 183us/sample - loss: 1.2111 - accuracy: 0.2768 - val_loss: 1.1496 - val_accuracy: 0.4211\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 187us/sample - loss: 1.1839 - accuracy: 0.3214 - val_loss: 1.1259 - val_accuracy: 0.4211\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 1.1609 - accuracy: 0.3661 - val_loss: 1.1052 - val_accuracy: 0.4474\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 1.1410 - accuracy: 0.3839 - val_loss: 1.0861 - val_accuracy: 0.4737\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 1.1225 - accuracy: 0.4107 - val_loss: 1.0687 - val_accuracy: 0.5263\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 187us/sample - loss: 1.1058 - accuracy: 0.4286 - val_loss: 1.0531 - val_accuracy: 0.5263\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 183us/sample - loss: 1.0903 - accuracy: 0.4375 - val_loss: 1.0380 - val_accuracy: 0.5263\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 183us/sample - loss: 1.0751 - accuracy: 0.4375 - val_loss: 1.0230 - val_accuracy: 0.5263\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 185us/sample - loss: 1.0604 - accuracy: 0.4464 - val_loss: 1.0089 - val_accuracy: 0.5263\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 1.0464 - accuracy: 0.4643 - val_loss: 0.9949 - val_accuracy: 0.5789\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 183us/sample - loss: 1.0327 - accuracy: 0.4554 - val_loss: 0.9812 - val_accuracy: 0.5789\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 189us/sample - loss: 1.0189 - accuracy: 0.4821 - val_loss: 0.9677 - val_accuracy: 0.6053\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 214us/sample - loss: 1.0054 - accuracy: 0.4821 - val_loss: 0.9547 - val_accuracy: 0.6316\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 201us/sample - loss: 0.9925 - accuracy: 0.4821 - val_loss: 0.9415 - val_accuracy: 0.6579\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 196us/sample - loss: 0.9797 - accuracy: 0.5000 - val_loss: 0.9287 - val_accuracy: 0.6579\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.9672 - accuracy: 0.5179 - val_loss: 0.9162 - val_accuracy: 0.6579\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 189us/sample - loss: 0.9558 - accuracy: 0.5357 - val_loss: 0.9037 - val_accuracy: 0.6579\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 191us/sample - loss: 0.9433 - accuracy: 0.5446 - val_loss: 0.8912 - val_accuracy: 0.6842\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 0.9319 - accuracy: 0.5536 - val_loss: 0.8791 - val_accuracy: 0.6842\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 189us/sample - loss: 0.9207 - accuracy: 0.5625 - val_loss: 0.8674 - val_accuracy: 0.6842\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 183us/sample - loss: 0.9095 - accuracy: 0.5714 - val_loss: 0.8557 - val_accuracy: 0.7368\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 0.8985 - accuracy: 0.5804 - val_loss: 0.8442 - val_accuracy: 0.7368\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 191us/sample - loss: 0.8880 - accuracy: 0.5893 - val_loss: 0.8331 - val_accuracy: 0.7632\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 201us/sample - loss: 0.8776 - accuracy: 0.5982 - val_loss: 0.8222 - val_accuracy: 0.7632\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 194us/sample - loss: 0.8679 - accuracy: 0.6161 - val_loss: 0.8111 - val_accuracy: 0.7632\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 0.8574 - accuracy: 0.6161 - val_loss: 0.8005 - val_accuracy: 0.7632\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 0.8476 - accuracy: 0.6161 - val_loss: 0.7899 - val_accuracy: 0.7632\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 220us/sample - loss: 0.8379 - accuracy: 0.6161 - val_loss: 0.7793 - val_accuracy: 0.7632\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 183us/sample - loss: 0.8282 - accuracy: 0.6250 - val_loss: 0.7687 - val_accuracy: 0.7632\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 0.8186 - accuracy: 0.6250 - val_loss: 0.7587 - val_accuracy: 0.7632\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 173us/sample - loss: 0.8093 - accuracy: 0.6250 - val_loss: 0.7488 - val_accuracy: 0.7632\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 163us/sample - loss: 0.8005 - accuracy: 0.6250 - val_loss: 0.7389 - val_accuracy: 0.7632\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 177us/sample - loss: 0.7913 - accuracy: 0.6250 - val_loss: 0.7295 - val_accuracy: 0.7632\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.7826 - accuracy: 0.6429 - val_loss: 0.7198 - val_accuracy: 0.7632\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 193us/sample - loss: 0.7736 - accuracy: 0.6429 - val_loss: 0.7103 - val_accuracy: 0.7632\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 0.7649 - accuracy: 0.6429 - val_loss: 0.7012 - val_accuracy: 0.7632\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 177us/sample - loss: 0.7561 - accuracy: 0.6429 - val_loss: 0.6923 - val_accuracy: 0.7632\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 171us/sample - loss: 0.7477 - accuracy: 0.6429 - val_loss: 0.6833 - val_accuracy: 0.7632\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 177us/sample - loss: 0.7399 - accuracy: 0.6339 - val_loss: 0.6747 - val_accuracy: 0.7632\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 269us/sample - loss: 0.7314 - accuracy: 0.6339 - val_loss: 0.6661 - val_accuracy: 0.7632\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 185us/sample - loss: 0.7237 - accuracy: 0.6518 - val_loss: 0.6577 - val_accuracy: 0.7632\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 205us/sample - loss: 0.7160 - accuracy: 0.6607 - val_loss: 0.6494 - val_accuracy: 0.7368\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.7081 - accuracy: 0.6786 - val_loss: 0.6415 - val_accuracy: 0.7368\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 0.7007 - accuracy: 0.6786 - val_loss: 0.6334 - val_accuracy: 0.7368\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 198us/sample - loss: 0.6933 - accuracy: 0.6786 - val_loss: 0.6253 - val_accuracy: 0.7632\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 185us/sample - loss: 0.6865 - accuracy: 0.6786 - val_loss: 0.6178 - val_accuracy: 0.7632\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 190us/sample - loss: 0.6790 - accuracy: 0.6786 - val_loss: 0.6099 - val_accuracy: 0.7632\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 0.6722 - accuracy: 0.6786 - val_loss: 0.6026 - val_accuracy: 0.7632\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 0.6659 - accuracy: 0.6786 - val_loss: 0.5957 - val_accuracy: 0.7632\n",
      "\n",
      "Forming the grid-search model #12 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7fc734eb1c10>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fc734eb1a50>, epochs=50, batch_size=16\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 8ms/sample - loss: 1.2023 - accuracy: 0.3304 - val_loss: 1.1421 - val_accuracy: 0.4211\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 319us/sample - loss: 1.1534 - accuracy: 0.3661 - val_loss: 1.1012 - val_accuracy: 0.4211\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 303us/sample - loss: 1.1187 - accuracy: 0.4018 - val_loss: 1.0655 - val_accuracy: 0.4474\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 1.0868 - accuracy: 0.4018 - val_loss: 1.0320 - val_accuracy: 0.4474\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 358us/sample - loss: 1.0569 - accuracy: 0.4107 - val_loss: 1.0007 - val_accuracy: 0.4737\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 1.0289 - accuracy: 0.4196 - val_loss: 0.9712 - val_accuracy: 0.5526\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 1.0021 - accuracy: 0.4911 - val_loss: 0.9428 - val_accuracy: 0.6053\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 0.9779 - accuracy: 0.5446 - val_loss: 0.9170 - val_accuracy: 0.6316\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 315us/sample - loss: 0.9532 - accuracy: 0.5982 - val_loss: 0.8902 - val_accuracy: 0.7895\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 327us/sample - loss: 0.9292 - accuracy: 0.6250 - val_loss: 0.8643 - val_accuracy: 0.8158\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 306us/sample - loss: 0.9062 - accuracy: 0.6607 - val_loss: 0.8392 - val_accuracy: 0.8158\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 314us/sample - loss: 0.8832 - accuracy: 0.6964 - val_loss: 0.8139 - val_accuracy: 0.8421\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 0.8606 - accuracy: 0.7321 - val_loss: 0.7892 - val_accuracy: 0.8947\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 316us/sample - loss: 0.8382 - accuracy: 0.7411 - val_loss: 0.7645 - val_accuracy: 0.9211\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 381us/sample - loss: 0.8167 - accuracy: 0.7411 - val_loss: 0.7408 - val_accuracy: 0.8947\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 313us/sample - loss: 0.7957 - accuracy: 0.7321 - val_loss: 0.7186 - val_accuracy: 0.9211\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.7751 - accuracy: 0.7679 - val_loss: 0.6962 - val_accuracy: 0.9211\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 312us/sample - loss: 0.7550 - accuracy: 0.7857 - val_loss: 0.6747 - val_accuracy: 0.9211\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 330us/sample - loss: 0.7353 - accuracy: 0.7768 - val_loss: 0.6536 - val_accuracy: 0.9211\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.7166 - accuracy: 0.7768 - val_loss: 0.6340 - val_accuracy: 0.9211\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 0.6982 - accuracy: 0.7768 - val_loss: 0.6151 - val_accuracy: 0.9211\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.6804 - accuracy: 0.7857 - val_loss: 0.5969 - val_accuracy: 0.9211\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 0.6635 - accuracy: 0.7857 - val_loss: 0.5794 - val_accuracy: 0.9211\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 355us/sample - loss: 0.6465 - accuracy: 0.7857 - val_loss: 0.5623 - val_accuracy: 0.9211\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 318us/sample - loss: 0.6299 - accuracy: 0.7857 - val_loss: 0.5455 - val_accuracy: 0.9211\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 415us/sample - loss: 0.6143 - accuracy: 0.8036 - val_loss: 0.5296 - val_accuracy: 0.9211\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 0.5997 - accuracy: 0.8036 - val_loss: 0.5152 - val_accuracy: 0.9211\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 0.5848 - accuracy: 0.8036 - val_loss: 0.5005 - val_accuracy: 0.9211\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 0.5702 - accuracy: 0.8036 - val_loss: 0.4860 - val_accuracy: 0.9211\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 313us/sample - loss: 0.5564 - accuracy: 0.8036 - val_loss: 0.4720 - val_accuracy: 0.9211\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 0.5429 - accuracy: 0.8125 - val_loss: 0.4589 - val_accuracy: 0.9211\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 0.5298 - accuracy: 0.8214 - val_loss: 0.4466 - val_accuracy: 0.9211\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.5176 - accuracy: 0.8214 - val_loss: 0.4346 - val_accuracy: 0.9211\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 307us/sample - loss: 0.5059 - accuracy: 0.8214 - val_loss: 0.4234 - val_accuracy: 0.9211\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 354us/sample - loss: 0.4942 - accuracy: 0.8214 - val_loss: 0.4128 - val_accuracy: 0.9211\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 299us/sample - loss: 0.4834 - accuracy: 0.8214 - val_loss: 0.4025 - val_accuracy: 0.9211\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.4729 - accuracy: 0.8214 - val_loss: 0.3928 - val_accuracy: 0.9211\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 0.4626 - accuracy: 0.8214 - val_loss: 0.3833 - val_accuracy: 0.9211\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 322us/sample - loss: 0.4526 - accuracy: 0.8214 - val_loss: 0.3740 - val_accuracy: 0.9211\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 307us/sample - loss: 0.4439 - accuracy: 0.8214 - val_loss: 0.3659 - val_accuracy: 0.9211\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.4350 - accuracy: 0.8304 - val_loss: 0.3580 - val_accuracy: 0.9211\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 309us/sample - loss: 0.4267 - accuracy: 0.8304 - val_loss: 0.3506 - val_accuracy: 0.9211\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 0.4186 - accuracy: 0.8304 - val_loss: 0.3431 - val_accuracy: 0.9211\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 300us/sample - loss: 0.4104 - accuracy: 0.8304 - val_loss: 0.3358 - val_accuracy: 0.9211\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 327us/sample - loss: 0.4035 - accuracy: 0.8393 - val_loss: 0.3290 - val_accuracy: 0.9211\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 303us/sample - loss: 0.3954 - accuracy: 0.8393 - val_loss: 0.3224 - val_accuracy: 0.9211\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 307us/sample - loss: 0.3886 - accuracy: 0.8304 - val_loss: 0.3161 - val_accuracy: 0.9211\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 0.3812 - accuracy: 0.8393 - val_loss: 0.3098 - val_accuracy: 0.9211\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 315us/sample - loss: 0.3746 - accuracy: 0.8393 - val_loss: 0.3039 - val_accuracy: 0.9474\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 0.3675 - accuracy: 0.8393 - val_loss: 0.2977 - val_accuracy: 0.9474\n",
      "\n",
      "Forming the grid-search model #13 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7fc734eb1c10>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fc734eb1a50>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 8ms/sample - loss: 1.2178 - accuracy: 0.3036 - val_loss: 1.1633 - val_accuracy: 0.3947\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 1.1803 - accuracy: 0.3393 - val_loss: 1.1348 - val_accuracy: 0.4211\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 1.1558 - accuracy: 0.3661 - val_loss: 1.1091 - val_accuracy: 0.4211\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 1.1329 - accuracy: 0.3929 - val_loss: 1.0857 - val_accuracy: 0.4474\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 1.1127 - accuracy: 0.3929 - val_loss: 1.0647 - val_accuracy: 0.4474\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 1.0941 - accuracy: 0.4018 - val_loss: 1.0446 - val_accuracy: 0.4474\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 1.0753 - accuracy: 0.4018 - val_loss: 1.0246 - val_accuracy: 0.4474\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 227us/sample - loss: 1.0578 - accuracy: 0.4107 - val_loss: 1.0071 - val_accuracy: 0.4737\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 264us/sample - loss: 1.0412 - accuracy: 0.4196 - val_loss: 0.9875 - val_accuracy: 0.5526\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 1.0239 - accuracy: 0.4375 - val_loss: 0.9691 - val_accuracy: 0.5526\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 1.0079 - accuracy: 0.4821 - val_loss: 0.9521 - val_accuracy: 0.5526\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 0.9925 - accuracy: 0.5268 - val_loss: 0.9356 - val_accuracy: 0.6316\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 0.9772 - accuracy: 0.5804 - val_loss: 0.9188 - val_accuracy: 0.6842\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 0.9619 - accuracy: 0.5982 - val_loss: 0.9023 - val_accuracy: 0.7632\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 199us/sample - loss: 0.9470 - accuracy: 0.6071 - val_loss: 0.8853 - val_accuracy: 0.8158\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.9325 - accuracy: 0.6429 - val_loss: 0.8703 - val_accuracy: 0.8158\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.9183 - accuracy: 0.6696 - val_loss: 0.8549 - val_accuracy: 0.8158\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.9044 - accuracy: 0.6875 - val_loss: 0.8388 - val_accuracy: 0.8421\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 263us/sample - loss: 0.8904 - accuracy: 0.7232 - val_loss: 0.8226 - val_accuracy: 0.8421\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 0.8765 - accuracy: 0.7411 - val_loss: 0.8078 - val_accuracy: 0.9211\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 258us/sample - loss: 0.8632 - accuracy: 0.7411 - val_loss: 0.7927 - val_accuracy: 0.9211\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.8497 - accuracy: 0.7411 - val_loss: 0.7786 - val_accuracy: 0.9211\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 0.8370 - accuracy: 0.7411 - val_loss: 0.7639 - val_accuracy: 0.9211\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 273us/sample - loss: 0.8240 - accuracy: 0.7411 - val_loss: 0.7499 - val_accuracy: 0.9211\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 0.8113 - accuracy: 0.7411 - val_loss: 0.7362 - val_accuracy: 0.9211\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 276us/sample - loss: 0.7991 - accuracy: 0.7411 - val_loss: 0.7224 - val_accuracy: 0.9211\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 257us/sample - loss: 0.7864 - accuracy: 0.7500 - val_loss: 0.7090 - val_accuracy: 0.9211\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 0.7742 - accuracy: 0.7589 - val_loss: 0.6951 - val_accuracy: 0.9211\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 264us/sample - loss: 0.7616 - accuracy: 0.7679 - val_loss: 0.6817 - val_accuracy: 0.9211\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 0.7498 - accuracy: 0.7679 - val_loss: 0.6697 - val_accuracy: 0.9211\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 253us/sample - loss: 0.7383 - accuracy: 0.7679 - val_loss: 0.6569 - val_accuracy: 0.9211\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.7268 - accuracy: 0.7768 - val_loss: 0.6452 - val_accuracy: 0.9211\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 0.7156 - accuracy: 0.7768 - val_loss: 0.6337 - val_accuracy: 0.9211\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 0.7050 - accuracy: 0.7768 - val_loss: 0.6223 - val_accuracy: 0.9211\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 0.6941 - accuracy: 0.7768 - val_loss: 0.6105 - val_accuracy: 0.9211\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.6834 - accuracy: 0.7946 - val_loss: 0.5991 - val_accuracy: 0.9211\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 256us/sample - loss: 0.6727 - accuracy: 0.7946 - val_loss: 0.5889 - val_accuracy: 0.9211\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 256us/sample - loss: 0.6622 - accuracy: 0.7946 - val_loss: 0.5779 - val_accuracy: 0.9211\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.6519 - accuracy: 0.7946 - val_loss: 0.5676 - val_accuracy: 0.9211\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 0.6427 - accuracy: 0.8036 - val_loss: 0.5583 - val_accuracy: 0.9211\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 0.6329 - accuracy: 0.8036 - val_loss: 0.5484 - val_accuracy: 0.9211\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 0.6235 - accuracy: 0.8036 - val_loss: 0.5392 - val_accuracy: 0.9211\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 0.6145 - accuracy: 0.8036 - val_loss: 0.5302 - val_accuracy: 0.9211\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.6050 - accuracy: 0.8036 - val_loss: 0.5209 - val_accuracy: 0.9211\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 0.5963 - accuracy: 0.8036 - val_loss: 0.5126 - val_accuracy: 0.9211\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 0.5873 - accuracy: 0.8036 - val_loss: 0.5031 - val_accuracy: 0.9211\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 0.5787 - accuracy: 0.8036 - val_loss: 0.4944 - val_accuracy: 0.9211\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.5696 - accuracy: 0.8036 - val_loss: 0.4859 - val_accuracy: 0.9211\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 0.5614 - accuracy: 0.8036 - val_loss: 0.4777 - val_accuracy: 0.9211\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.5531 - accuracy: 0.8125 - val_loss: 0.4694 - val_accuracy: 0.9211\n",
      "\n",
      "Forming the grid-search model #14 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7fc734eb1c10>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fc734eb1a50>, epochs=50, batch_size=64\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 11ms/sample - loss: 1.2299 - accuracy: 0.2768 - val_loss: 1.1833 - val_accuracy: 0.3421\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 197us/sample - loss: 1.2034 - accuracy: 0.3125 - val_loss: 1.1632 - val_accuracy: 0.3684\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 170us/sample - loss: 1.1850 - accuracy: 0.3304 - val_loss: 1.1458 - val_accuracy: 0.4211\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 166us/sample - loss: 1.1697 - accuracy: 0.3393 - val_loss: 1.1303 - val_accuracy: 0.4211\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 200us/sample - loss: 1.1561 - accuracy: 0.3571 - val_loss: 1.1161 - val_accuracy: 0.4211\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 1.1439 - accuracy: 0.3661 - val_loss: 1.1030 - val_accuracy: 0.4211\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 1.1320 - accuracy: 0.3929 - val_loss: 1.0908 - val_accuracy: 0.4211\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 186us/sample - loss: 1.1213 - accuracy: 0.3929 - val_loss: 1.0795 - val_accuracy: 0.4211\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 175us/sample - loss: 1.1109 - accuracy: 0.3929 - val_loss: 1.0682 - val_accuracy: 0.4474\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 196us/sample - loss: 1.1008 - accuracy: 0.4018 - val_loss: 1.0572 - val_accuracy: 0.4474\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 199us/sample - loss: 1.0912 - accuracy: 0.4018 - val_loss: 1.0466 - val_accuracy: 0.4474\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 1.0817 - accuracy: 0.4018 - val_loss: 1.0359 - val_accuracy: 0.4474\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 1.0719 - accuracy: 0.4107 - val_loss: 1.0256 - val_accuracy: 0.4737\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 206us/sample - loss: 1.0626 - accuracy: 0.4107 - val_loss: 1.0152 - val_accuracy: 0.4737\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 187us/sample - loss: 1.0534 - accuracy: 0.4018 - val_loss: 1.0049 - val_accuracy: 0.5000\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 207us/sample - loss: 1.0445 - accuracy: 0.4196 - val_loss: 0.9952 - val_accuracy: 0.5263\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 1.0354 - accuracy: 0.4375 - val_loss: 0.9853 - val_accuracy: 0.5526\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 208us/sample - loss: 1.0267 - accuracy: 0.4732 - val_loss: 0.9759 - val_accuracy: 0.5526\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 1.0181 - accuracy: 0.4821 - val_loss: 0.9664 - val_accuracy: 0.5526\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 171us/sample - loss: 1.0098 - accuracy: 0.5000 - val_loss: 0.9571 - val_accuracy: 0.5526\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 197us/sample - loss: 1.0015 - accuracy: 0.5357 - val_loss: 0.9482 - val_accuracy: 0.6316\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 177us/sample - loss: 0.9932 - accuracy: 0.5625 - val_loss: 0.9392 - val_accuracy: 0.6316\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 0.9851 - accuracy: 0.5804 - val_loss: 0.9302 - val_accuracy: 0.6842\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 203us/sample - loss: 0.9771 - accuracy: 0.5982 - val_loss: 0.9214 - val_accuracy: 0.7105\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 175us/sample - loss: 0.9692 - accuracy: 0.5982 - val_loss: 0.9126 - val_accuracy: 0.7368\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 171us/sample - loss: 0.9616 - accuracy: 0.5893 - val_loss: 0.9038 - val_accuracy: 0.7632\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 0.9535 - accuracy: 0.5982 - val_loss: 0.8951 - val_accuracy: 0.7895\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 200us/sample - loss: 0.9458 - accuracy: 0.6250 - val_loss: 0.8863 - val_accuracy: 0.8158\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 182us/sample - loss: 0.9380 - accuracy: 0.6607 - val_loss: 0.8777 - val_accuracy: 0.8158\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 0.9305 - accuracy: 0.6607 - val_loss: 0.8694 - val_accuracy: 0.8421\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 0.9230 - accuracy: 0.6696 - val_loss: 0.8610 - val_accuracy: 0.8421\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 175us/sample - loss: 0.9156 - accuracy: 0.6786 - val_loss: 0.8531 - val_accuracy: 0.8684\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 175us/sample - loss: 0.9082 - accuracy: 0.6875 - val_loss: 0.8450 - val_accuracy: 0.8684\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 204us/sample - loss: 0.9010 - accuracy: 0.6964 - val_loss: 0.8370 - val_accuracy: 0.8684\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 192us/sample - loss: 0.8939 - accuracy: 0.7232 - val_loss: 0.8290 - val_accuracy: 0.8684\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 162us/sample - loss: 0.8865 - accuracy: 0.7321 - val_loss: 0.8210 - val_accuracy: 0.8947\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 203us/sample - loss: 0.8795 - accuracy: 0.7411 - val_loss: 0.8131 - val_accuracy: 0.9211\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 201us/sample - loss: 0.8722 - accuracy: 0.7411 - val_loss: 0.8052 - val_accuracy: 0.9211\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 0.8651 - accuracy: 0.7411 - val_loss: 0.7972 - val_accuracy: 0.9211\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 182us/sample - loss: 0.8588 - accuracy: 0.7411 - val_loss: 0.7897 - val_accuracy: 0.9211\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 202us/sample - loss: 0.8512 - accuracy: 0.7411 - val_loss: 0.7820 - val_accuracy: 0.9211\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 198us/sample - loss: 0.8446 - accuracy: 0.7411 - val_loss: 0.7745 - val_accuracy: 0.9211\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 190us/sample - loss: 0.8379 - accuracy: 0.7411 - val_loss: 0.7669 - val_accuracy: 0.9211\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 0.8308 - accuracy: 0.7411 - val_loss: 0.7595 - val_accuracy: 0.9211\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 197us/sample - loss: 0.8240 - accuracy: 0.7411 - val_loss: 0.7522 - val_accuracy: 0.9211\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 0.8173 - accuracy: 0.7411 - val_loss: 0.7446 - val_accuracy: 0.9211\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 0.8108 - accuracy: 0.7411 - val_loss: 0.7374 - val_accuracy: 0.8947\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 182us/sample - loss: 0.8038 - accuracy: 0.7411 - val_loss: 0.7301 - val_accuracy: 0.9211\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 190us/sample - loss: 0.7974 - accuracy: 0.7500 - val_loss: 0.7229 - val_accuracy: 0.9211\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 177us/sample - loss: 0.7909 - accuracy: 0.7589 - val_loss: 0.7157 - val_accuracy: 0.9211\n",
      "\n",
      "Forming the grid-search model #15 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7fc734eb1c10>, kernel=<tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7fc7348861d0>, epochs=50, batch_size=16\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 8ms/sample - loss: 1.0943 - accuracy: 0.5982 - val_loss: 1.0879 - val_accuracy: 0.7105\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 296us/sample - loss: 1.0850 - accuracy: 0.6607 - val_loss: 1.0779 - val_accuracy: 0.6842\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 311us/sample - loss: 1.0746 - accuracy: 0.6696 - val_loss: 1.0658 - val_accuracy: 0.6842\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 1.0624 - accuracy: 0.6607 - val_loss: 1.0522 - val_accuracy: 0.6842\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 1.0482 - accuracy: 0.6607 - val_loss: 1.0364 - val_accuracy: 0.6842\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 307us/sample - loss: 1.0325 - accuracy: 0.6607 - val_loss: 1.0192 - val_accuracy: 0.6842\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 1.0155 - accuracy: 0.6607 - val_loss: 1.0007 - val_accuracy: 0.6842\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 294us/sample - loss: 0.9980 - accuracy: 0.6607 - val_loss: 0.9822 - val_accuracy: 0.6842\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 0.9791 - accuracy: 0.6607 - val_loss: 0.9619 - val_accuracy: 0.6842\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 0.9594 - accuracy: 0.6607 - val_loss: 0.9410 - val_accuracy: 0.6842\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 330us/sample - loss: 0.9390 - accuracy: 0.6607 - val_loss: 0.9195 - val_accuracy: 0.6842\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 0.9178 - accuracy: 0.6607 - val_loss: 0.8971 - val_accuracy: 0.6842\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.8962 - accuracy: 0.6607 - val_loss: 0.8743 - val_accuracy: 0.6842\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 346us/sample - loss: 0.8739 - accuracy: 0.6607 - val_loss: 0.8509 - val_accuracy: 0.6842\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 319us/sample - loss: 0.8521 - accuracy: 0.6607 - val_loss: 0.8284 - val_accuracy: 0.6842\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 339us/sample - loss: 0.8305 - accuracy: 0.6607 - val_loss: 0.8063 - val_accuracy: 0.6842\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 0.8089 - accuracy: 0.6607 - val_loss: 0.7837 - val_accuracy: 0.6842\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.8066 - accuracy: 0.62 - 0s 324us/sample - loss: 0.7875 - accuracy: 0.6607 - val_loss: 0.7616 - val_accuracy: 0.6842\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 358us/sample - loss: 0.7664 - accuracy: 0.6607 - val_loss: 0.7397 - val_accuracy: 0.6842\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.7461 - accuracy: 0.6607 - val_loss: 0.7192 - val_accuracy: 0.6842\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 0.7266 - accuracy: 0.6607 - val_loss: 0.6993 - val_accuracy: 0.6842\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 0.7078 - accuracy: 0.6607 - val_loss: 0.6802 - val_accuracy: 0.6842\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 0.6904 - accuracy: 0.6607 - val_loss: 0.6623 - val_accuracy: 0.6842\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 0.6732 - accuracy: 0.6607 - val_loss: 0.6448 - val_accuracy: 0.6842\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 0.6568 - accuracy: 0.6607 - val_loss: 0.6279 - val_accuracy: 0.6842\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 326us/sample - loss: 0.6415 - accuracy: 0.6607 - val_loss: 0.6121 - val_accuracy: 0.6842\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 324us/sample - loss: 0.6276 - accuracy: 0.6607 - val_loss: 0.5979 - val_accuracy: 0.6842\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.6139 - accuracy: 0.6607 - val_loss: 0.5840 - val_accuracy: 0.6842\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 0.6011 - accuracy: 0.6607 - val_loss: 0.5707 - val_accuracy: 0.6842\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 0.5893 - accuracy: 0.6607 - val_loss: 0.5584 - val_accuracy: 0.6842\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 0.5782 - accuracy: 0.6607 - val_loss: 0.5467 - val_accuracy: 0.6842\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 345us/sample - loss: 0.5677 - accuracy: 0.6607 - val_loss: 0.5362 - val_accuracy: 0.6842\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.5582 - accuracy: 0.6607 - val_loss: 0.5261 - val_accuracy: 0.6842\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 324us/sample - loss: 0.5492 - accuracy: 0.6607 - val_loss: 0.5166 - val_accuracy: 0.6842\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 314us/sample - loss: 0.5406 - accuracy: 0.6607 - val_loss: 0.5077 - val_accuracy: 0.6842\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 313us/sample - loss: 0.5327 - accuracy: 0.6607 - val_loss: 0.4991 - val_accuracy: 0.6842\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 0.5252 - accuracy: 0.6696 - val_loss: 0.4913 - val_accuracy: 0.6842\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 318us/sample - loss: 0.5180 - accuracy: 0.6786 - val_loss: 0.4837 - val_accuracy: 0.7105\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.5111 - accuracy: 0.6875 - val_loss: 0.4765 - val_accuracy: 0.7105\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 0.5054 - accuracy: 0.6786 - val_loss: 0.4699 - val_accuracy: 0.7105\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.4995 - accuracy: 0.6875 - val_loss: 0.4639 - val_accuracy: 0.7105\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 304us/sample - loss: 0.4939 - accuracy: 0.6875 - val_loss: 0.4582 - val_accuracy: 0.7105\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.4886 - accuracy: 0.6875 - val_loss: 0.4526 - val_accuracy: 0.7105\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.4834 - accuracy: 0.6875 - val_loss: 0.4473 - val_accuracy: 0.7368\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.4790 - accuracy: 0.6875 - val_loss: 0.4422 - val_accuracy: 0.7368\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 312us/sample - loss: 0.4738 - accuracy: 0.6875 - val_loss: 0.4374 - val_accuracy: 0.7368\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 327us/sample - loss: 0.4697 - accuracy: 0.6964 - val_loss: 0.4328 - val_accuracy: 0.7368\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 322us/sample - loss: 0.4651 - accuracy: 0.7054 - val_loss: 0.4282 - val_accuracy: 0.7368\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 310us/sample - loss: 0.4608 - accuracy: 0.7054 - val_loss: 0.4238 - val_accuracy: 0.7632\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 336us/sample - loss: 0.4564 - accuracy: 0.7143 - val_loss: 0.4192 - val_accuracy: 0.7895\n",
      "\n",
      "Forming the grid-search model #16 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7fc734eb1c10>, kernel=<tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7fc7348861d0>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.0965 - accuracy: 0.4643 - val_loss: 1.0919 - val_accuracy: 0.6842\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 1.0912 - accuracy: 0.6339 - val_loss: 1.0865 - val_accuracy: 0.9211\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 257us/sample - loss: 1.0858 - accuracy: 0.7321 - val_loss: 1.0803 - val_accuracy: 0.7895\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 1.0796 - accuracy: 0.7500 - val_loss: 1.0739 - val_accuracy: 0.7368\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 1.0733 - accuracy: 0.6786 - val_loss: 1.0667 - val_accuracy: 0.7368\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 261us/sample - loss: 1.0661 - accuracy: 0.7054 - val_loss: 1.0587 - val_accuracy: 0.6842\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 1.0580 - accuracy: 0.6786 - val_loss: 1.0497 - val_accuracy: 0.6842\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 1.0495 - accuracy: 0.6607 - val_loss: 1.0410 - val_accuracy: 0.7105\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 262us/sample - loss: 1.0407 - accuracy: 0.6786 - val_loss: 1.0309 - val_accuracy: 0.6842\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 1.0308 - accuracy: 0.6607 - val_loss: 1.0203 - val_accuracy: 0.6842\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 1.0206 - accuracy: 0.6607 - val_loss: 1.0099 - val_accuracy: 0.6842\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 1.0104 - accuracy: 0.6607 - val_loss: 0.9986 - val_accuracy: 0.6842\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 0.9994 - accuracy: 0.6607 - val_loss: 0.9867 - val_accuracy: 0.6842\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 0.9878 - accuracy: 0.6607 - val_loss: 0.9743 - val_accuracy: 0.6842\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 0.9760 - accuracy: 0.6607 - val_loss: 0.9624 - val_accuracy: 0.6842\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.9644 - accuracy: 0.6607 - val_loss: 0.9500 - val_accuracy: 0.6842\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.9522 - accuracy: 0.6696 - val_loss: 0.9372 - val_accuracy: 0.6842\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 0.9399 - accuracy: 0.6696 - val_loss: 0.9239 - val_accuracy: 0.6842\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 0.9270 - accuracy: 0.6696 - val_loss: 0.9101 - val_accuracy: 0.6842\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 266us/sample - loss: 0.9141 - accuracy: 0.6607 - val_loss: 0.8971 - val_accuracy: 0.6842\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 0.9014 - accuracy: 0.6696 - val_loss: 0.8834 - val_accuracy: 0.6842\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 0.8882 - accuracy: 0.6607 - val_loss: 0.8702 - val_accuracy: 0.6842\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 258us/sample - loss: 0.8754 - accuracy: 0.6607 - val_loss: 0.8566 - val_accuracy: 0.6842\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 259us/sample - loss: 0.8625 - accuracy: 0.6607 - val_loss: 0.8434 - val_accuracy: 0.6842\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 0.8498 - accuracy: 0.6607 - val_loss: 0.8297 - val_accuracy: 0.6842\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.8369 - accuracy: 0.6607 - val_loss: 0.8167 - val_accuracy: 0.6842\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 259us/sample - loss: 0.8242 - accuracy: 0.6607 - val_loss: 0.8034 - val_accuracy: 0.6842\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 265us/sample - loss: 0.8113 - accuracy: 0.6607 - val_loss: 0.7896 - val_accuracy: 0.6842\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 0.7982 - accuracy: 0.6607 - val_loss: 0.7763 - val_accuracy: 0.6842\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 253us/sample - loss: 0.7858 - accuracy: 0.6607 - val_loss: 0.7640 - val_accuracy: 0.6842\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.7739 - accuracy: 0.6607 - val_loss: 0.7510 - val_accuracy: 0.6842\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 221us/sample - loss: 0.7615 - accuracy: 0.6607 - val_loss: 0.7385 - val_accuracy: 0.6842\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 256us/sample - loss: 0.7495 - accuracy: 0.6607 - val_loss: 0.7267 - val_accuracy: 0.6842\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 0.7382 - accuracy: 0.6607 - val_loss: 0.7148 - val_accuracy: 0.6842\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.7268 - accuracy: 0.6607 - val_loss: 0.7027 - val_accuracy: 0.6842\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.7154 - accuracy: 0.6607 - val_loss: 0.6905 - val_accuracy: 0.6842\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 0.7040 - accuracy: 0.6607 - val_loss: 0.6793 - val_accuracy: 0.6842\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 0.6932 - accuracy: 0.6607 - val_loss: 0.6678 - val_accuracy: 0.6842\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.6826 - accuracy: 0.6607 - val_loss: 0.6569 - val_accuracy: 0.6842\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 257us/sample - loss: 0.6732 - accuracy: 0.6607 - val_loss: 0.6472 - val_accuracy: 0.6842\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 0.6635 - accuracy: 0.6607 - val_loss: 0.6370 - val_accuracy: 0.6842\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 0.6540 - accuracy: 0.6607 - val_loss: 0.6277 - val_accuracy: 0.6842\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.6452 - accuracy: 0.6607 - val_loss: 0.6184 - val_accuracy: 0.6842\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 256us/sample - loss: 0.6363 - accuracy: 0.6607 - val_loss: 0.6092 - val_accuracy: 0.6842\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.6280 - accuracy: 0.6607 - val_loss: 0.6010 - val_accuracy: 0.6842\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 0.6199 - accuracy: 0.6607 - val_loss: 0.5921 - val_accuracy: 0.6842\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.6121 - accuracy: 0.6607 - val_loss: 0.5839 - val_accuracy: 0.6842\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.6043 - accuracy: 0.6607 - val_loss: 0.5761 - val_accuracy: 0.6842\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.5971 - accuracy: 0.6607 - val_loss: 0.5687 - val_accuracy: 0.6842\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.5902 - accuracy: 0.6607 - val_loss: 0.5609 - val_accuracy: 0.6842\n",
      "\n",
      "Forming the grid-search model #17 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7fc734eb1c10>, kernel=<tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7fc7348861d0>, epochs=50, batch_size=64\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 8ms/sample - loss: 1.0976 - accuracy: 0.2679 - val_loss: 1.0947 - val_accuracy: 0.5263\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 210us/sample - loss: 1.0949 - accuracy: 0.5179 - val_loss: 1.0918 - val_accuracy: 0.8158\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 1.0919 - accuracy: 0.6875 - val_loss: 1.0889 - val_accuracy: 0.7895\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 1.0891 - accuracy: 0.7857 - val_loss: 1.0858 - val_accuracy: 0.8158\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 1.0862 - accuracy: 0.7411 - val_loss: 1.0826 - val_accuracy: 0.7895\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 220us/sample - loss: 1.0831 - accuracy: 0.7857 - val_loss: 1.0794 - val_accuracy: 0.7895\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 1.0798 - accuracy: 0.7232 - val_loss: 1.0760 - val_accuracy: 0.7895\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 198us/sample - loss: 1.0766 - accuracy: 0.7143 - val_loss: 1.0726 - val_accuracy: 0.7895\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 1.0732 - accuracy: 0.7321 - val_loss: 1.0689 - val_accuracy: 0.7632\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 1.0697 - accuracy: 0.6964 - val_loss: 1.0651 - val_accuracy: 0.7632\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 196us/sample - loss: 1.0660 - accuracy: 0.6786 - val_loss: 1.0610 - val_accuracy: 0.7368\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 163us/sample - loss: 1.0620 - accuracy: 0.6964 - val_loss: 1.0567 - val_accuracy: 0.7368\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 182us/sample - loss: 1.0577 - accuracy: 0.6875 - val_loss: 1.0522 - val_accuracy: 0.7632\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 185us/sample - loss: 1.0533 - accuracy: 0.6964 - val_loss: 1.0474 - val_accuracy: 0.7632\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 1.0487 - accuracy: 0.6786 - val_loss: 1.0425 - val_accuracy: 0.7632\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 185us/sample - loss: 1.0441 - accuracy: 0.6607 - val_loss: 1.0376 - val_accuracy: 0.7632\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 191us/sample - loss: 1.0391 - accuracy: 0.6786 - val_loss: 1.0324 - val_accuracy: 0.7368\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 186us/sample - loss: 1.0342 - accuracy: 0.6607 - val_loss: 1.0272 - val_accuracy: 0.7368\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 1.0291 - accuracy: 0.6696 - val_loss: 1.0219 - val_accuracy: 0.7105\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 183us/sample - loss: 1.0241 - accuracy: 0.6786 - val_loss: 1.0163 - val_accuracy: 0.7105\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 192us/sample - loss: 1.0186 - accuracy: 0.6875 - val_loss: 1.0106 - val_accuracy: 0.7105\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 186us/sample - loss: 1.0131 - accuracy: 0.6696 - val_loss: 1.0049 - val_accuracy: 0.7105\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 185us/sample - loss: 1.0075 - accuracy: 0.6786 - val_loss: 0.9992 - val_accuracy: 0.6842\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 1.0021 - accuracy: 0.6696 - val_loss: 0.9935 - val_accuracy: 0.6842\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 186us/sample - loss: 0.9965 - accuracy: 0.6696 - val_loss: 0.9876 - val_accuracy: 0.6842\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 170us/sample - loss: 0.9912 - accuracy: 0.6696 - val_loss: 0.9818 - val_accuracy: 0.6842\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.9853 - accuracy: 0.6696 - val_loss: 0.9758 - val_accuracy: 0.6842\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 0.9794 - accuracy: 0.6786 - val_loss: 0.9695 - val_accuracy: 0.6842\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 171us/sample - loss: 0.9733 - accuracy: 0.6786 - val_loss: 0.9632 - val_accuracy: 0.6842\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 182us/sample - loss: 0.9674 - accuracy: 0.6786 - val_loss: 0.9569 - val_accuracy: 0.6842\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 182us/sample - loss: 0.9612 - accuracy: 0.6786 - val_loss: 0.9504 - val_accuracy: 0.6842\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 191us/sample - loss: 0.9551 - accuracy: 0.6607 - val_loss: 0.9438 - val_accuracy: 0.6842\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 0.9486 - accuracy: 0.6696 - val_loss: 0.9374 - val_accuracy: 0.6842\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 0.9423 - accuracy: 0.6607 - val_loss: 0.9307 - val_accuracy: 0.6842\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 0.9359 - accuracy: 0.6607 - val_loss: 0.9240 - val_accuracy: 0.6842\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 168us/sample - loss: 0.9295 - accuracy: 0.6607 - val_loss: 0.9173 - val_accuracy: 0.6842\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 217us/sample - loss: 0.9230 - accuracy: 0.6696 - val_loss: 0.9105 - val_accuracy: 0.6842\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 0.9163 - accuracy: 0.6607 - val_loss: 0.9036 - val_accuracy: 0.6842\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 186us/sample - loss: 0.9097 - accuracy: 0.6607 - val_loss: 0.8967 - val_accuracy: 0.6842\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 200us/sample - loss: 0.9036 - accuracy: 0.6607 - val_loss: 0.8898 - val_accuracy: 0.6842\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 192us/sample - loss: 0.8965 - accuracy: 0.6607 - val_loss: 0.8830 - val_accuracy: 0.6842\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 192us/sample - loss: 0.8901 - accuracy: 0.6607 - val_loss: 0.8762 - val_accuracy: 0.6842\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.8835 - accuracy: 0.6607 - val_loss: 0.8692 - val_accuracy: 0.6842\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 202us/sample - loss: 0.8766 - accuracy: 0.6607 - val_loss: 0.8621 - val_accuracy: 0.6842\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 165us/sample - loss: 0.8698 - accuracy: 0.6607 - val_loss: 0.8551 - val_accuracy: 0.6842\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 0.8630 - accuracy: 0.6607 - val_loss: 0.8481 - val_accuracy: 0.6842\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 191us/sample - loss: 0.8564 - accuracy: 0.6607 - val_loss: 0.8409 - val_accuracy: 0.6842\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.8494 - accuracy: 0.6607 - val_loss: 0.8339 - val_accuracy: 0.6842\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 186us/sample - loss: 0.8428 - accuracy: 0.6607 - val_loss: 0.8269 - val_accuracy: 0.6842\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 178us/sample - loss: 0.8363 - accuracy: 0.6607 - val_loss: 0.8200 - val_accuracy: 0.6842\n",
      "\n",
      "Forming the grid-search model #18 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7fc734eb1090>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7fc734eb1150>, epochs=50, batch_size=16\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 6ms/sample - loss: 1.2170 - accuracy: 0.2857 - val_loss: 1.1144 - val_accuracy: 0.4474\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 274us/sample - loss: 1.1198 - accuracy: 0.4107 - val_loss: 1.0276 - val_accuracy: 0.5789\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 1.0422 - accuracy: 0.4911 - val_loss: 0.9568 - val_accuracy: 0.5789\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 0.9781 - accuracy: 0.5268 - val_loss: 0.8978 - val_accuracy: 0.6579\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 293us/sample - loss: 0.9227 - accuracy: 0.5625 - val_loss: 0.8473 - val_accuracy: 0.7105\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 310us/sample - loss: 0.8758 - accuracy: 0.5804 - val_loss: 0.8032 - val_accuracy: 0.7105\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 0.8347 - accuracy: 0.5982 - val_loss: 0.7635 - val_accuracy: 0.7632\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 0.7982 - accuracy: 0.6161 - val_loss: 0.7277 - val_accuracy: 0.7632\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 326us/sample - loss: 0.7646 - accuracy: 0.6429 - val_loss: 0.6946 - val_accuracy: 0.7632\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 303us/sample - loss: 0.7354 - accuracy: 0.6429 - val_loss: 0.6648 - val_accuracy: 0.7632\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 322us/sample - loss: 0.7094 - accuracy: 0.6786 - val_loss: 0.6378 - val_accuracy: 0.7368\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 326us/sample - loss: 0.6856 - accuracy: 0.6964 - val_loss: 0.6132 - val_accuracy: 0.7632\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 300us/sample - loss: 0.6639 - accuracy: 0.6964 - val_loss: 0.5909 - val_accuracy: 0.7368\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 300us/sample - loss: 0.6441 - accuracy: 0.7054 - val_loss: 0.5703 - val_accuracy: 0.7368\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 306us/sample - loss: 0.6261 - accuracy: 0.7143 - val_loss: 0.5513 - val_accuracy: 0.7368\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 324us/sample - loss: 0.6090 - accuracy: 0.7411 - val_loss: 0.5337 - val_accuracy: 0.7632\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 318us/sample - loss: 0.5933 - accuracy: 0.7411 - val_loss: 0.5176 - val_accuracy: 0.7632\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 322us/sample - loss: 0.5790 - accuracy: 0.7500 - val_loss: 0.5027 - val_accuracy: 0.7895\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.5655 - accuracy: 0.7589 - val_loss: 0.4888 - val_accuracy: 0.7895\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 299us/sample - loss: 0.5535 - accuracy: 0.7589 - val_loss: 0.4758 - val_accuracy: 0.8158\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 342us/sample - loss: 0.5417 - accuracy: 0.7589 - val_loss: 0.4638 - val_accuracy: 0.8158\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.5312 - accuracy: 0.7589 - val_loss: 0.4528 - val_accuracy: 0.8421\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 297us/sample - loss: 0.5214 - accuracy: 0.7679 - val_loss: 0.4426 - val_accuracy: 0.8421\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 318us/sample - loss: 0.5121 - accuracy: 0.7768 - val_loss: 0.4332 - val_accuracy: 0.8421\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 0.5035 - accuracy: 0.7768 - val_loss: 0.4244 - val_accuracy: 0.8421\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 322us/sample - loss: 0.4957 - accuracy: 0.7768 - val_loss: 0.4161 - val_accuracy: 0.8421\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 307us/sample - loss: 0.4882 - accuracy: 0.7946 - val_loss: 0.4083 - val_accuracy: 0.8421\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 310us/sample - loss: 0.4804 - accuracy: 0.8036 - val_loss: 0.4010 - val_accuracy: 0.8684\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 321us/sample - loss: 0.4735 - accuracy: 0.8036 - val_loss: 0.3941 - val_accuracy: 0.8684\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 307us/sample - loss: 0.4671 - accuracy: 0.8036 - val_loss: 0.3876 - val_accuracy: 0.8684\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 0.4612 - accuracy: 0.8036 - val_loss: 0.3815 - val_accuracy: 0.8684\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 314us/sample - loss: 0.4552 - accuracy: 0.8036 - val_loss: 0.3757 - val_accuracy: 0.8684\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.4497 - accuracy: 0.8125 - val_loss: 0.3702 - val_accuracy: 0.8684\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 303us/sample - loss: 0.4445 - accuracy: 0.8125 - val_loss: 0.3650 - val_accuracy: 0.8684\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.4393 - accuracy: 0.8125 - val_loss: 0.3600 - val_accuracy: 0.8684\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 0.4345 - accuracy: 0.8125 - val_loss: 0.3553 - val_accuracy: 0.8684\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 310us/sample - loss: 0.4299 - accuracy: 0.8125 - val_loss: 0.3507 - val_accuracy: 0.8684\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 305us/sample - loss: 0.4252 - accuracy: 0.8125 - val_loss: 0.3464 - val_accuracy: 0.8684\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 319us/sample - loss: 0.4210 - accuracy: 0.8125 - val_loss: 0.3423 - val_accuracy: 0.8684\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 292us/sample - loss: 0.4172 - accuracy: 0.8125 - val_loss: 0.3384 - val_accuracy: 0.8684\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 307us/sample - loss: 0.4130 - accuracy: 0.8125 - val_loss: 0.3346 - val_accuracy: 0.8684\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 315us/sample - loss: 0.4091 - accuracy: 0.8125 - val_loss: 0.3309 - val_accuracy: 0.8684\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 324us/sample - loss: 0.4053 - accuracy: 0.8125 - val_loss: 0.3274 - val_accuracy: 0.8684\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 314us/sample - loss: 0.4016 - accuracy: 0.8125 - val_loss: 0.3241 - val_accuracy: 0.8684\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 322us/sample - loss: 0.3985 - accuracy: 0.8125 - val_loss: 0.3209 - val_accuracy: 0.8684\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 0.3947 - accuracy: 0.8125 - val_loss: 0.3177 - val_accuracy: 0.8684\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.3916 - accuracy: 0.8125 - val_loss: 0.3147 - val_accuracy: 0.8684\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.3883 - accuracy: 0.8125 - val_loss: 0.3118 - val_accuracy: 0.8684\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 318us/sample - loss: 0.3854 - accuracy: 0.8125 - val_loss: 0.3090 - val_accuracy: 0.8684\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.3823 - accuracy: 0.8125 - val_loss: 0.3063 - val_accuracy: 0.8684\n",
      "\n",
      "Forming the grid-search model #19 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7fc734eb1090>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7fc734eb1150>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 1.2429 - accuracy: 0.2679 - val_loss: 1.1568 - val_accuracy: 0.3947\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 1.1800 - accuracy: 0.3482 - val_loss: 1.1016 - val_accuracy: 0.4737\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 1.1283 - accuracy: 0.4018 - val_loss: 1.0502 - val_accuracy: 0.5526\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 1.0800 - accuracy: 0.4464 - val_loss: 1.0078 - val_accuracy: 0.5789\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 1.0394 - accuracy: 0.5000 - val_loss: 0.9680 - val_accuracy: 0.5789\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 1.0015 - accuracy: 0.5268 - val_loss: 0.9314 - val_accuracy: 0.6316\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 391us/sample - loss: 0.9664 - accuracy: 0.5268 - val_loss: 0.8993 - val_accuracy: 0.6579\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.9355 - accuracy: 0.5357 - val_loss: 0.8696 - val_accuracy: 0.6842\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.9070 - accuracy: 0.5536 - val_loss: 0.8421 - val_accuracy: 0.7105\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 0.8806 - accuracy: 0.5893 - val_loss: 0.8167 - val_accuracy: 0.6842\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 0.8563 - accuracy: 0.6071 - val_loss: 0.7923 - val_accuracy: 0.7105\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 0.8332 - accuracy: 0.5982 - val_loss: 0.7698 - val_accuracy: 0.7368\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 0.8115 - accuracy: 0.6161 - val_loss: 0.7489 - val_accuracy: 0.7632\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.7916 - accuracy: 0.6161 - val_loss: 0.7297 - val_accuracy: 0.7632\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.7734 - accuracy: 0.6161 - val_loss: 0.7096 - val_accuracy: 0.7632\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.7555 - accuracy: 0.6429 - val_loss: 0.6915 - val_accuracy: 0.7632\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 0.7391 - accuracy: 0.6429 - val_loss: 0.6750 - val_accuracy: 0.7632\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.7242 - accuracy: 0.6518 - val_loss: 0.6577 - val_accuracy: 0.7632\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 0.7087 - accuracy: 0.6696 - val_loss: 0.6421 - val_accuracy: 0.7368\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.6951 - accuracy: 0.6875 - val_loss: 0.6264 - val_accuracy: 0.7632\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 0.6812 - accuracy: 0.6964 - val_loss: 0.6129 - val_accuracy: 0.7632\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 0.6689 - accuracy: 0.7054 - val_loss: 0.5995 - val_accuracy: 0.7632\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 0.6570 - accuracy: 0.7054 - val_loss: 0.5875 - val_accuracy: 0.7632\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 261us/sample - loss: 0.6463 - accuracy: 0.7143 - val_loss: 0.5761 - val_accuracy: 0.7368\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 0.6361 - accuracy: 0.7143 - val_loss: 0.5655 - val_accuracy: 0.7368\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.6264 - accuracy: 0.7232 - val_loss: 0.5545 - val_accuracy: 0.7368\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 220us/sample - loss: 0.6165 - accuracy: 0.7411 - val_loss: 0.5445 - val_accuracy: 0.7368\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.6073 - accuracy: 0.7411 - val_loss: 0.5341 - val_accuracy: 0.7632\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 216us/sample - loss: 0.5980 - accuracy: 0.7411 - val_loss: 0.5245 - val_accuracy: 0.7632\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.5892 - accuracy: 0.7411 - val_loss: 0.5151 - val_accuracy: 0.7632\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.5809 - accuracy: 0.7589 - val_loss: 0.5064 - val_accuracy: 0.7895\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.5727 - accuracy: 0.7589 - val_loss: 0.4985 - val_accuracy: 0.7895\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.5653 - accuracy: 0.7589 - val_loss: 0.4897 - val_accuracy: 0.7895\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 0.5576 - accuracy: 0.7589 - val_loss: 0.4823 - val_accuracy: 0.8158\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 0.5509 - accuracy: 0.7589 - val_loss: 0.4747 - val_accuracy: 0.8158\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 0.5443 - accuracy: 0.7589 - val_loss: 0.4678 - val_accuracy: 0.8158\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 216us/sample - loss: 0.5382 - accuracy: 0.7589 - val_loss: 0.4616 - val_accuracy: 0.8158\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.5320 - accuracy: 0.7589 - val_loss: 0.4554 - val_accuracy: 0.8421\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 0.5264 - accuracy: 0.7589 - val_loss: 0.4495 - val_accuracy: 0.8421\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 0.5213 - accuracy: 0.7679 - val_loss: 0.4437 - val_accuracy: 0.8421\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 0.5159 - accuracy: 0.7768 - val_loss: 0.4380 - val_accuracy: 0.8421\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 0.5106 - accuracy: 0.7768 - val_loss: 0.4328 - val_accuracy: 0.8421\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 234us/sample - loss: 0.5057 - accuracy: 0.7768 - val_loss: 0.4277 - val_accuracy: 0.8421\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.5006 - accuracy: 0.7768 - val_loss: 0.4229 - val_accuracy: 0.8421\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.4963 - accuracy: 0.7768 - val_loss: 0.4184 - val_accuracy: 0.8421\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 0.4919 - accuracy: 0.7857 - val_loss: 0.4138 - val_accuracy: 0.8421\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.4879 - accuracy: 0.7857 - val_loss: 0.4096 - val_accuracy: 0.8421\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 252us/sample - loss: 0.4835 - accuracy: 0.7946 - val_loss: 0.4050 - val_accuracy: 0.8421\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 0.4795 - accuracy: 0.8036 - val_loss: 0.4009 - val_accuracy: 0.8684\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 0.4756 - accuracy: 0.8036 - val_loss: 0.3969 - val_accuracy: 0.8684\n",
      "\n",
      "Forming the grid-search model #20 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7fc734eb1090>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7fc734eb1150>, epochs=50, batch_size=64\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 1.2563 - accuracy: 0.2679 - val_loss: 1.1912 - val_accuracy: 0.3421\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 187us/sample - loss: 1.2238 - accuracy: 0.2768 - val_loss: 1.1595 - val_accuracy: 0.3947\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 187us/sample - loss: 1.1934 - accuracy: 0.3214 - val_loss: 1.1296 - val_accuracy: 0.4211\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 176us/sample - loss: 1.1648 - accuracy: 0.3571 - val_loss: 1.1018 - val_accuracy: 0.4737\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 176us/sample - loss: 1.1383 - accuracy: 0.4018 - val_loss: 1.0753 - val_accuracy: 0.4737\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 190us/sample - loss: 1.1128 - accuracy: 0.4107 - val_loss: 1.0506 - val_accuracy: 0.5789\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 185us/sample - loss: 1.0896 - accuracy: 0.4286 - val_loss: 1.0284 - val_accuracy: 0.5789\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 1.0678 - accuracy: 0.4554 - val_loss: 1.0071 - val_accuracy: 0.5789\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 1.0468 - accuracy: 0.4911 - val_loss: 0.9866 - val_accuracy: 0.5789\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 1.0268 - accuracy: 0.5089 - val_loss: 0.9674 - val_accuracy: 0.5789\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 212us/sample - loss: 1.0081 - accuracy: 0.5179 - val_loss: 0.9490 - val_accuracy: 0.6053\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 178us/sample - loss: 0.9904 - accuracy: 0.5179 - val_loss: 0.9312 - val_accuracy: 0.6316\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 182us/sample - loss: 0.9730 - accuracy: 0.5179 - val_loss: 0.9143 - val_accuracy: 0.6316\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 165us/sample - loss: 0.9565 - accuracy: 0.5268 - val_loss: 0.8986 - val_accuracy: 0.6579\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 0.9411 - accuracy: 0.5536 - val_loss: 0.8831 - val_accuracy: 0.6579\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 176us/sample - loss: 0.9260 - accuracy: 0.5625 - val_loss: 0.8683 - val_accuracy: 0.6842\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 167us/sample - loss: 0.9116 - accuracy: 0.5625 - val_loss: 0.8543 - val_accuracy: 0.7105\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 186us/sample - loss: 0.8984 - accuracy: 0.5804 - val_loss: 0.8406 - val_accuracy: 0.7105\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 199us/sample - loss: 0.8846 - accuracy: 0.5804 - val_loss: 0.8275 - val_accuracy: 0.7105\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 194us/sample - loss: 0.8720 - accuracy: 0.5893 - val_loss: 0.8151 - val_accuracy: 0.6842\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 203us/sample - loss: 0.8597 - accuracy: 0.6071 - val_loss: 0.8031 - val_accuracy: 0.7105\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 191us/sample - loss: 0.8477 - accuracy: 0.5982 - val_loss: 0.7911 - val_accuracy: 0.7368\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 176us/sample - loss: 0.8362 - accuracy: 0.5982 - val_loss: 0.7798 - val_accuracy: 0.7368\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 167us/sample - loss: 0.8253 - accuracy: 0.6071 - val_loss: 0.7689 - val_accuracy: 0.7368\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 187us/sample - loss: 0.8147 - accuracy: 0.6161 - val_loss: 0.7584 - val_accuracy: 0.7632\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 189us/sample - loss: 0.8048 - accuracy: 0.6161 - val_loss: 0.7477 - val_accuracy: 0.7632\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 0.7945 - accuracy: 0.6161 - val_loss: 0.7377 - val_accuracy: 0.7632\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 182us/sample - loss: 0.7849 - accuracy: 0.6161 - val_loss: 0.7276 - val_accuracy: 0.7632\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.7755 - accuracy: 0.6161 - val_loss: 0.7176 - val_accuracy: 0.7632\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 0.7664 - accuracy: 0.6250 - val_loss: 0.7078 - val_accuracy: 0.7632\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 205us/sample - loss: 0.7575 - accuracy: 0.6429 - val_loss: 0.6985 - val_accuracy: 0.7632\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 190us/sample - loss: 0.7490 - accuracy: 0.6429 - val_loss: 0.6897 - val_accuracy: 0.7632\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 167us/sample - loss: 0.7409 - accuracy: 0.6429 - val_loss: 0.6807 - val_accuracy: 0.7632\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 0.7328 - accuracy: 0.6518 - val_loss: 0.6724 - val_accuracy: 0.7632\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 0.7252 - accuracy: 0.6607 - val_loss: 0.6640 - val_accuracy: 0.7632\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 0.7176 - accuracy: 0.6607 - val_loss: 0.6561 - val_accuracy: 0.7632\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 178us/sample - loss: 0.7104 - accuracy: 0.6786 - val_loss: 0.6484 - val_accuracy: 0.7368\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 0.7034 - accuracy: 0.6786 - val_loss: 0.6410 - val_accuracy: 0.7368\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 0.6966 - accuracy: 0.6964 - val_loss: 0.6336 - val_accuracy: 0.7368\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 198us/sample - loss: 0.6903 - accuracy: 0.6964 - val_loss: 0.6266 - val_accuracy: 0.7632\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 0.6835 - accuracy: 0.6964 - val_loss: 0.6196 - val_accuracy: 0.7632\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 0.6773 - accuracy: 0.6964 - val_loss: 0.6128 - val_accuracy: 0.7632\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 185us/sample - loss: 0.6712 - accuracy: 0.6964 - val_loss: 0.6061 - val_accuracy: 0.7632\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 187us/sample - loss: 0.6651 - accuracy: 0.6964 - val_loss: 0.5998 - val_accuracy: 0.7632\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 175us/sample - loss: 0.6593 - accuracy: 0.7054 - val_loss: 0.5935 - val_accuracy: 0.7368\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 187us/sample - loss: 0.6535 - accuracy: 0.7054 - val_loss: 0.5872 - val_accuracy: 0.7368\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 0.6482 - accuracy: 0.7054 - val_loss: 0.5814 - val_accuracy: 0.7368\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 0.6425 - accuracy: 0.6964 - val_loss: 0.5754 - val_accuracy: 0.7368\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 170us/sample - loss: 0.6372 - accuracy: 0.7054 - val_loss: 0.5697 - val_accuracy: 0.7368\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 183us/sample - loss: 0.6321 - accuracy: 0.7143 - val_loss: 0.5643 - val_accuracy: 0.7368\n",
      "\n",
      "Forming the grid-search model #21 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7fc734eb1090>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fc734eb1a50>, epochs=50, batch_size=16\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 0s 4ms/sample - loss: 1.2203 - accuracy: 0.2946 - val_loss: 1.1720 - val_accuracy: 0.3421\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 312us/sample - loss: 1.1794 - accuracy: 0.3304 - val_loss: 1.1297 - val_accuracy: 0.4211\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 308us/sample - loss: 1.1417 - accuracy: 0.3571 - val_loss: 1.0905 - val_accuracy: 0.4211\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 313us/sample - loss: 1.1064 - accuracy: 0.3929 - val_loss: 1.0539 - val_accuracy: 0.4474\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 281us/sample - loss: 1.0729 - accuracy: 0.4107 - val_loss: 1.0196 - val_accuracy: 0.4737\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 294us/sample - loss: 1.0417 - accuracy: 0.4107 - val_loss: 0.9875 - val_accuracy: 0.5263\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 300us/sample - loss: 1.0121 - accuracy: 0.4375 - val_loss: 0.9570 - val_accuracy: 0.5789\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 330us/sample - loss: 0.9847 - accuracy: 0.5089 - val_loss: 0.9275 - val_accuracy: 0.6316\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 327us/sample - loss: 0.9569 - accuracy: 0.5625 - val_loss: 0.8993 - val_accuracy: 0.7105\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 314us/sample - loss: 0.9311 - accuracy: 0.6250 - val_loss: 0.8722 - val_accuracy: 0.7895\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.9062 - accuracy: 0.6518 - val_loss: 0.8463 - val_accuracy: 0.8158\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 315us/sample - loss: 0.8823 - accuracy: 0.6875 - val_loss: 0.8212 - val_accuracy: 0.8158\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 327us/sample - loss: 0.8591 - accuracy: 0.6964 - val_loss: 0.7969 - val_accuracy: 0.8158\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 322us/sample - loss: 0.8367 - accuracy: 0.7232 - val_loss: 0.7734 - val_accuracy: 0.8421\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 309us/sample - loss: 0.8156 - accuracy: 0.7411 - val_loss: 0.7509 - val_accuracy: 0.8421\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 310us/sample - loss: 0.7949 - accuracy: 0.7589 - val_loss: 0.7294 - val_accuracy: 0.8684\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 309us/sample - loss: 0.7750 - accuracy: 0.7679 - val_loss: 0.7089 - val_accuracy: 0.8684\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 313us/sample - loss: 0.7564 - accuracy: 0.7589 - val_loss: 0.6894 - val_accuracy: 0.8684\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 333us/sample - loss: 0.7386 - accuracy: 0.7589 - val_loss: 0.6709 - val_accuracy: 0.8684\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 351us/sample - loss: 0.7219 - accuracy: 0.7768 - val_loss: 0.6532 - val_accuracy: 0.8684\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 305us/sample - loss: 0.7053 - accuracy: 0.7768 - val_loss: 0.6365 - val_accuracy: 0.8684\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 314us/sample - loss: 0.6897 - accuracy: 0.7768 - val_loss: 0.6205 - val_accuracy: 0.8947\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 324us/sample - loss: 0.6750 - accuracy: 0.7857 - val_loss: 0.6053 - val_accuracy: 0.8947\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 310us/sample - loss: 0.6605 - accuracy: 0.7857 - val_loss: 0.5909 - val_accuracy: 0.8947\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 0.6470 - accuracy: 0.7857 - val_loss: 0.5773 - val_accuracy: 0.8947\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 318us/sample - loss: 0.6345 - accuracy: 0.7857 - val_loss: 0.5644 - val_accuracy: 0.8947\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 323us/sample - loss: 0.6227 - accuracy: 0.7857 - val_loss: 0.5522 - val_accuracy: 0.8947\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 323us/sample - loss: 0.6107 - accuracy: 0.7946 - val_loss: 0.5405 - val_accuracy: 0.8947\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.5996 - accuracy: 0.7946 - val_loss: 0.5294 - val_accuracy: 0.8947\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 323us/sample - loss: 0.5893 - accuracy: 0.7946 - val_loss: 0.5189 - val_accuracy: 0.8947\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 327us/sample - loss: 0.5794 - accuracy: 0.7946 - val_loss: 0.5088 - val_accuracy: 0.8947\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 311us/sample - loss: 0.5697 - accuracy: 0.7946 - val_loss: 0.4993 - val_accuracy: 0.8947\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 314us/sample - loss: 0.5606 - accuracy: 0.7946 - val_loss: 0.4902 - val_accuracy: 0.8947\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 315us/sample - loss: 0.5520 - accuracy: 0.7946 - val_loss: 0.4815 - val_accuracy: 0.8947\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 295us/sample - loss: 0.5435 - accuracy: 0.7857 - val_loss: 0.4732 - val_accuracy: 0.8947\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 279us/sample - loss: 0.5355 - accuracy: 0.7857 - val_loss: 0.4653 - val_accuracy: 0.8947\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 315us/sample - loss: 0.5279 - accuracy: 0.7946 - val_loss: 0.4577 - val_accuracy: 0.8947\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 0.5204 - accuracy: 0.7946 - val_loss: 0.4505 - val_accuracy: 0.8947\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 318us/sample - loss: 0.5133 - accuracy: 0.7946 - val_loss: 0.4436 - val_accuracy: 0.8947\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.5070 - accuracy: 0.7946 - val_loss: 0.4370 - val_accuracy: 0.8947\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 311us/sample - loss: 0.5004 - accuracy: 0.8125 - val_loss: 0.4306 - val_accuracy: 0.8947\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 315us/sample - loss: 0.4940 - accuracy: 0.8036 - val_loss: 0.4245 - val_accuracy: 0.8947\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 353us/sample - loss: 0.4879 - accuracy: 0.8125 - val_loss: 0.4185 - val_accuracy: 0.8947\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 361us/sample - loss: 0.4820 - accuracy: 0.8125 - val_loss: 0.4129 - val_accuracy: 0.8947\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 308us/sample - loss: 0.4769 - accuracy: 0.8214 - val_loss: 0.4074 - val_accuracy: 0.8947\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 323us/sample - loss: 0.4710 - accuracy: 0.8214 - val_loss: 0.4021 - val_accuracy: 0.8947\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.4659 - accuracy: 0.8214 - val_loss: 0.3970 - val_accuracy: 0.8947\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 326us/sample - loss: 0.4606 - accuracy: 0.8214 - val_loss: 0.3921 - val_accuracy: 0.8947\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 316us/sample - loss: 0.4558 - accuracy: 0.8214 - val_loss: 0.3874 - val_accuracy: 0.8947\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 330us/sample - loss: 0.4509 - accuracy: 0.8393 - val_loss: 0.3828 - val_accuracy: 0.8947\n",
      "\n",
      "Forming the grid-search model #22 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7fc734eb1090>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fc734eb1a50>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 1.2302 - accuracy: 0.2768 - val_loss: 1.1916 - val_accuracy: 0.3421\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 1.2068 - accuracy: 0.3125 - val_loss: 1.1678 - val_accuracy: 0.3684\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 1.1847 - accuracy: 0.3393 - val_loss: 1.1429 - val_accuracy: 0.4211\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 1.1619 - accuracy: 0.3482 - val_loss: 1.1193 - val_accuracy: 0.4211\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 1.1406 - accuracy: 0.3661 - val_loss: 1.0971 - val_accuracy: 0.4211\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 1.1204 - accuracy: 0.3929 - val_loss: 1.0754 - val_accuracy: 0.4211\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 1.1000 - accuracy: 0.4018 - val_loss: 1.0542 - val_accuracy: 0.4474\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 1.0808 - accuracy: 0.4018 - val_loss: 1.0354 - val_accuracy: 0.4474\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 1.0628 - accuracy: 0.4018 - val_loss: 1.0155 - val_accuracy: 0.4737\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 1.0445 - accuracy: 0.4107 - val_loss: 0.9966 - val_accuracy: 0.4737\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 1.0273 - accuracy: 0.4196 - val_loss: 0.9791 - val_accuracy: 0.5526\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 1.0110 - accuracy: 0.4464 - val_loss: 0.9620 - val_accuracy: 0.5789\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 0.9948 - accuracy: 0.4821 - val_loss: 0.9449 - val_accuracy: 0.6053\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 0.9789 - accuracy: 0.5268 - val_loss: 0.9283 - val_accuracy: 0.6053\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.9635 - accuracy: 0.5625 - val_loss: 0.9119 - val_accuracy: 0.6579\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 0.9485 - accuracy: 0.5714 - val_loss: 0.8966 - val_accuracy: 0.6842\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 0.9339 - accuracy: 0.5804 - val_loss: 0.8813 - val_accuracy: 0.7895\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 235us/sample - loss: 0.9196 - accuracy: 0.6339 - val_loss: 0.8658 - val_accuracy: 0.7895\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 253us/sample - loss: 0.9055 - accuracy: 0.6518 - val_loss: 0.8505 - val_accuracy: 0.7895\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 261us/sample - loss: 0.8915 - accuracy: 0.6696 - val_loss: 0.8361 - val_accuracy: 0.8158\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 0.8782 - accuracy: 0.6875 - val_loss: 0.8214 - val_accuracy: 0.8158\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 0.8645 - accuracy: 0.7054 - val_loss: 0.8075 - val_accuracy: 0.8158\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.8515 - accuracy: 0.7232 - val_loss: 0.7933 - val_accuracy: 0.8158\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 256us/sample - loss: 0.8386 - accuracy: 0.7232 - val_loss: 0.7798 - val_accuracy: 0.8421\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 0.8262 - accuracy: 0.7232 - val_loss: 0.7667 - val_accuracy: 0.8421\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 0.8143 - accuracy: 0.7232 - val_loss: 0.7539 - val_accuracy: 0.8684\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 0.8025 - accuracy: 0.7589 - val_loss: 0.7415 - val_accuracy: 0.8684\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 251us/sample - loss: 0.7909 - accuracy: 0.7589 - val_loss: 0.7287 - val_accuracy: 0.8684\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.7791 - accuracy: 0.7679 - val_loss: 0.7165 - val_accuracy: 0.8684\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.7681 - accuracy: 0.7679 - val_loss: 0.7053 - val_accuracy: 0.8684\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 0.7577 - accuracy: 0.7679 - val_loss: 0.6933 - val_accuracy: 0.8684\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 250us/sample - loss: 0.7469 - accuracy: 0.7589 - val_loss: 0.6824 - val_accuracy: 0.8684\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 0.7367 - accuracy: 0.7679 - val_loss: 0.6721 - val_accuracy: 0.8684\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.7271 - accuracy: 0.7679 - val_loss: 0.6620 - val_accuracy: 0.8684\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 0.7176 - accuracy: 0.7679 - val_loss: 0.6518 - val_accuracy: 0.8684\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 0.7083 - accuracy: 0.7768 - val_loss: 0.6418 - val_accuracy: 0.8684\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 226us/sample - loss: 0.6991 - accuracy: 0.7857 - val_loss: 0.6327 - val_accuracy: 0.8684\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 262us/sample - loss: 0.6903 - accuracy: 0.7768 - val_loss: 0.6233 - val_accuracy: 0.8947\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 257us/sample - loss: 0.6815 - accuracy: 0.7857 - val_loss: 0.6144 - val_accuracy: 0.8947\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 0.6737 - accuracy: 0.7857 - val_loss: 0.6061 - val_accuracy: 0.8947\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 0.6654 - accuracy: 0.7857 - val_loss: 0.5973 - val_accuracy: 0.8947\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 0.6572 - accuracy: 0.7857 - val_loss: 0.5893 - val_accuracy: 0.8947\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 0.6496 - accuracy: 0.7857 - val_loss: 0.5816 - val_accuracy: 0.8947\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 249us/sample - loss: 0.6419 - accuracy: 0.7857 - val_loss: 0.5739 - val_accuracy: 0.8947\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 0.6349 - accuracy: 0.7857 - val_loss: 0.5672 - val_accuracy: 0.8947\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 0.6280 - accuracy: 0.7857 - val_loss: 0.5598 - val_accuracy: 0.8947\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 254us/sample - loss: 0.6212 - accuracy: 0.7857 - val_loss: 0.5528 - val_accuracy: 0.8947\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 252us/sample - loss: 0.6144 - accuracy: 0.7857 - val_loss: 0.5461 - val_accuracy: 0.8947\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 263us/sample - loss: 0.6081 - accuracy: 0.7857 - val_loss: 0.5397 - val_accuracy: 0.8947\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 259us/sample - loss: 0.6019 - accuracy: 0.7946 - val_loss: 0.5332 - val_accuracy: 0.8947\n",
      "\n",
      "Forming the grid-search model #23 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7fc734eb1090>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fc734eb1a50>, epochs=50, batch_size=64\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 0s 4ms/sample - loss: 1.2351 - accuracy: 0.2679 - val_loss: 1.2043 - val_accuracy: 0.3421\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 227us/sample - loss: 1.2231 - accuracy: 0.2946 - val_loss: 1.1916 - val_accuracy: 0.3421\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 187us/sample - loss: 1.2111 - accuracy: 0.3036 - val_loss: 1.1788 - val_accuracy: 0.3421\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 182us/sample - loss: 1.1993 - accuracy: 0.3125 - val_loss: 1.1660 - val_accuracy: 0.3684\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 176us/sample - loss: 1.1876 - accuracy: 0.3304 - val_loss: 1.1535 - val_accuracy: 0.3947\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 178us/sample - loss: 1.1763 - accuracy: 0.3393 - val_loss: 1.1411 - val_accuracy: 0.3947\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 176us/sample - loss: 1.1648 - accuracy: 0.3482 - val_loss: 1.1294 - val_accuracy: 0.4211\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 1.1541 - accuracy: 0.3482 - val_loss: 1.1182 - val_accuracy: 0.4211\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 185us/sample - loss: 1.1437 - accuracy: 0.3571 - val_loss: 1.1069 - val_accuracy: 0.4211\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 252us/sample - loss: 1.1333 - accuracy: 0.3661 - val_loss: 1.0959 - val_accuracy: 0.4211\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 198us/sample - loss: 1.1233 - accuracy: 0.3750 - val_loss: 1.0852 - val_accuracy: 0.4211\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 1.1134 - accuracy: 0.4018 - val_loss: 1.0744 - val_accuracy: 0.4211\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 173us/sample - loss: 1.1033 - accuracy: 0.4018 - val_loss: 1.0640 - val_accuracy: 0.4211\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 171us/sample - loss: 1.0937 - accuracy: 0.4018 - val_loss: 1.0539 - val_accuracy: 0.4211\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 1.0842 - accuracy: 0.4018 - val_loss: 1.0439 - val_accuracy: 0.4474\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 171us/sample - loss: 1.0749 - accuracy: 0.4018 - val_loss: 1.0342 - val_accuracy: 0.4474\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 183us/sample - loss: 1.0656 - accuracy: 0.4018 - val_loss: 1.0245 - val_accuracy: 0.4474\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 194us/sample - loss: 1.0568 - accuracy: 0.4107 - val_loss: 1.0152 - val_accuracy: 0.4737\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 1.0479 - accuracy: 0.4196 - val_loss: 1.0058 - val_accuracy: 0.4737\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 225us/sample - loss: 1.0394 - accuracy: 0.4196 - val_loss: 0.9967 - val_accuracy: 0.4737\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 1.0308 - accuracy: 0.4196 - val_loss: 0.9878 - val_accuracy: 0.5000\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 190us/sample - loss: 1.0222 - accuracy: 0.4286 - val_loss: 0.9789 - val_accuracy: 0.5789\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 173us/sample - loss: 1.0138 - accuracy: 0.4375 - val_loss: 0.9701 - val_accuracy: 0.6053\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 190us/sample - loss: 1.0057 - accuracy: 0.4643 - val_loss: 0.9615 - val_accuracy: 0.5789\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 196us/sample - loss: 0.9976 - accuracy: 0.4732 - val_loss: 0.9529 - val_accuracy: 0.5789\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.9898 - accuracy: 0.5000 - val_loss: 0.9443 - val_accuracy: 0.6053\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 176us/sample - loss: 0.9817 - accuracy: 0.5268 - val_loss: 0.9359 - val_accuracy: 0.6053\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.9739 - accuracy: 0.5536 - val_loss: 0.9275 - val_accuracy: 0.6316\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 0.9660 - accuracy: 0.5625 - val_loss: 0.9192 - val_accuracy: 0.6316\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.9584 - accuracy: 0.5804 - val_loss: 0.9112 - val_accuracy: 0.6842\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 185us/sample - loss: 0.9508 - accuracy: 0.5804 - val_loss: 0.9031 - val_accuracy: 0.6842\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 178us/sample - loss: 0.9435 - accuracy: 0.5804 - val_loss: 0.8953 - val_accuracy: 0.7368\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 0.9360 - accuracy: 0.5893 - val_loss: 0.8875 - val_accuracy: 0.7368\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 193us/sample - loss: 0.9288 - accuracy: 0.6161 - val_loss: 0.8799 - val_accuracy: 0.7632\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.9217 - accuracy: 0.6339 - val_loss: 0.8723 - val_accuracy: 0.7895\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 0.9146 - accuracy: 0.6518 - val_loss: 0.8649 - val_accuracy: 0.7895\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 176us/sample - loss: 0.9077 - accuracy: 0.6607 - val_loss: 0.8575 - val_accuracy: 0.7895\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 183us/sample - loss: 0.9008 - accuracy: 0.6607 - val_loss: 0.8502 - val_accuracy: 0.8158\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 189us/sample - loss: 0.8940 - accuracy: 0.6607 - val_loss: 0.8429 - val_accuracy: 0.8158\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 0.8877 - accuracy: 0.6607 - val_loss: 0.8359 - val_accuracy: 0.8158\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 224us/sample - loss: 0.8806 - accuracy: 0.6875 - val_loss: 0.8287 - val_accuracy: 0.8158\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 186us/sample - loss: 0.8741 - accuracy: 0.6875 - val_loss: 0.8217 - val_accuracy: 0.8158\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 183us/sample - loss: 0.8676 - accuracy: 0.7143 - val_loss: 0.8145 - val_accuracy: 0.8158\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.8608 - accuracy: 0.7143 - val_loss: 0.8076 - val_accuracy: 0.8158\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 182us/sample - loss: 0.8543 - accuracy: 0.7232 - val_loss: 0.8007 - val_accuracy: 0.8158\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 196us/sample - loss: 0.8478 - accuracy: 0.7232 - val_loss: 0.7938 - val_accuracy: 0.8158\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 178us/sample - loss: 0.8415 - accuracy: 0.7321 - val_loss: 0.7869 - val_accuracy: 0.8158\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 178us/sample - loss: 0.8350 - accuracy: 0.7232 - val_loss: 0.7802 - val_accuracy: 0.8421\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 202us/sample - loss: 0.8289 - accuracy: 0.7232 - val_loss: 0.7736 - val_accuracy: 0.8421\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 176us/sample - loss: 0.8229 - accuracy: 0.7232 - val_loss: 0.7670 - val_accuracy: 0.8421\n",
      "\n",
      "Forming the grid-search model #24 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7fc734eb1090>, kernel=<tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7fc7348861d0>, epochs=50, batch_size=16\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 4ms/sample - loss: 1.0983 - accuracy: 0.2857 - val_loss: 1.0975 - val_accuracy: 0.3947\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 330us/sample - loss: 1.0978 - accuracy: 0.4732 - val_loss: 1.0971 - val_accuracy: 0.4474\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 288us/sample - loss: 1.0975 - accuracy: 0.4554 - val_loss: 1.0967 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 313us/sample - loss: 1.0970 - accuracy: 0.4554 - val_loss: 1.0962 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 305us/sample - loss: 1.0965 - accuracy: 0.5179 - val_loss: 1.0958 - val_accuracy: 0.5263\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 326us/sample - loss: 1.0961 - accuracy: 0.6071 - val_loss: 1.0952 - val_accuracy: 0.5263\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 319us/sample - loss: 1.0956 - accuracy: 0.5804 - val_loss: 1.0947 - val_accuracy: 0.5526\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 329us/sample - loss: 1.0953 - accuracy: 0.5536 - val_loss: 1.0942 - val_accuracy: 0.5526\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 312us/sample - loss: 1.0945 - accuracy: 0.6250 - val_loss: 1.0935 - val_accuracy: 0.5526\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 1.0940 - accuracy: 0.6250 - val_loss: 1.0929 - val_accuracy: 0.5789\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 323us/sample - loss: 1.0933 - accuracy: 0.6607 - val_loss: 1.0922 - val_accuracy: 0.6053\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 1.0926 - accuracy: 0.6339 - val_loss: 1.0915 - val_accuracy: 0.6053\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 1.0919 - accuracy: 0.6696 - val_loss: 1.0907 - val_accuracy: 0.6316\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 1.0911 - accuracy: 0.6429 - val_loss: 1.0898 - val_accuracy: 0.6316\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 1.0904 - accuracy: 0.6429 - val_loss: 1.0889 - val_accuracy: 0.6316\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 300us/sample - loss: 1.0894 - accuracy: 0.7411 - val_loss: 1.0879 - val_accuracy: 0.6316\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 324us/sample - loss: 1.0884 - accuracy: 0.6429 - val_loss: 1.0869 - val_accuracy: 0.6316\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 323us/sample - loss: 1.0873 - accuracy: 0.6518 - val_loss: 1.0858 - val_accuracy: 0.6316\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 1.0862 - accuracy: 0.6429 - val_loss: 1.0845 - val_accuracy: 0.6316\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 319us/sample - loss: 1.0852 - accuracy: 0.6875 - val_loss: 1.0832 - val_accuracy: 0.6316\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 1.0837 - accuracy: 0.6429 - val_loss: 1.0818 - val_accuracy: 0.6316\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 314us/sample - loss: 1.0822 - accuracy: 0.6607 - val_loss: 1.0802 - val_accuracy: 0.6316\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 313us/sample - loss: 1.0808 - accuracy: 0.6518 - val_loss: 1.0786 - val_accuracy: 0.6316\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 309us/sample - loss: 1.0790 - accuracy: 0.6875 - val_loss: 1.0768 - val_accuracy: 0.6842\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 322us/sample - loss: 1.0772 - accuracy: 0.6696 - val_loss: 1.0748 - val_accuracy: 0.6842\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 329us/sample - loss: 1.0754 - accuracy: 0.6786 - val_loss: 1.0727 - val_accuracy: 0.6842\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 332us/sample - loss: 1.0734 - accuracy: 0.7679 - val_loss: 1.0704 - val_accuracy: 0.6842\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 323us/sample - loss: 1.0709 - accuracy: 0.6518 - val_loss: 1.0680 - val_accuracy: 0.7105\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 1.0684 - accuracy: 0.7411 - val_loss: 1.0653 - val_accuracy: 0.7105\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 326us/sample - loss: 1.0658 - accuracy: 0.7768 - val_loss: 1.0624 - val_accuracy: 0.7895\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 301us/sample - loss: 1.0631 - accuracy: 0.6875 - val_loss: 1.0593 - val_accuracy: 0.8158\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 313us/sample - loss: 1.0599 - accuracy: 0.8304 - val_loss: 1.0560 - val_accuracy: 0.8421\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 1.0566 - accuracy: 0.8482 - val_loss: 1.0524 - val_accuracy: 0.8421\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 326us/sample - loss: 1.0531 - accuracy: 0.8214 - val_loss: 1.0485 - val_accuracy: 0.8947\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 309us/sample - loss: 1.0492 - accuracy: 0.8482 - val_loss: 1.0444 - val_accuracy: 0.9211\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 308us/sample - loss: 1.0450 - accuracy: 0.8482 - val_loss: 1.0399 - val_accuracy: 0.9211\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 1.0406 - accuracy: 0.8482 - val_loss: 1.0351 - val_accuracy: 0.9211\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 311us/sample - loss: 1.0359 - accuracy: 0.8750 - val_loss: 1.0300 - val_accuracy: 0.9211\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 306us/sample - loss: 1.0307 - accuracy: 0.8571 - val_loss: 1.0246 - val_accuracy: 0.9737\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 298us/sample - loss: 1.0258 - accuracy: 0.7946 - val_loss: 1.0188 - val_accuracy: 0.9737\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 298us/sample - loss: 1.0197 - accuracy: 0.8482 - val_loss: 1.0127 - val_accuracy: 0.9474\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 307us/sample - loss: 1.0135 - accuracy: 0.8304 - val_loss: 1.0062 - val_accuracy: 0.9474\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 311us/sample - loss: 1.0070 - accuracy: 0.8750 - val_loss: 0.9993 - val_accuracy: 0.8947\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 318us/sample - loss: 1.0002 - accuracy: 0.8125 - val_loss: 0.9920 - val_accuracy: 0.8947\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 310us/sample - loss: 0.9932 - accuracy: 0.8393 - val_loss: 0.9844 - val_accuracy: 0.8947\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 302us/sample - loss: 0.9854 - accuracy: 0.8214 - val_loss: 0.9764 - val_accuracy: 0.8947\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 309us/sample - loss: 0.9778 - accuracy: 0.8304 - val_loss: 0.9680 - val_accuracy: 0.8947\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 0.9693 - accuracy: 0.7679 - val_loss: 0.9594 - val_accuracy: 0.8947\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 322us/sample - loss: 0.9608 - accuracy: 0.7768 - val_loss: 0.9504 - val_accuracy: 0.8421\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 315us/sample - loss: 0.9521 - accuracy: 0.8036 - val_loss: 0.9411 - val_accuracy: 0.8421\n",
      "\n",
      "Forming the grid-search model #25 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7fc734eb1090>, kernel=<tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7fc7348861d0>, epochs=50, batch_size=32\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 1.0983 - accuracy: 0.2321 - val_loss: 1.0977 - val_accuracy: 0.3421\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 1.0980 - accuracy: 0.3304 - val_loss: 1.0975 - val_accuracy: 0.4211\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 240us/sample - loss: 1.0979 - accuracy: 0.3929 - val_loss: 1.0972 - val_accuracy: 0.3684\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 1.0975 - accuracy: 0.3482 - val_loss: 1.0970 - val_accuracy: 0.3947\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 1.0973 - accuracy: 0.4107 - val_loss: 1.0967 - val_accuracy: 0.3947\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 222us/sample - loss: 1.0971 - accuracy: 0.4286 - val_loss: 1.0965 - val_accuracy: 0.4211\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 225us/sample - loss: 1.0968 - accuracy: 0.4821 - val_loss: 1.0962 - val_accuracy: 0.4474\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 236us/sample - loss: 1.0966 - accuracy: 0.3393 - val_loss: 1.0960 - val_accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 1.0963 - accuracy: 0.5536 - val_loss: 1.0957 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 1.0960 - accuracy: 0.5357 - val_loss: 1.0954 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 267us/sample - loss: 1.0957 - accuracy: 0.5179 - val_loss: 1.0951 - val_accuracy: 0.5263\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 1.0955 - accuracy: 0.5893 - val_loss: 1.0948 - val_accuracy: 0.5526\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 219us/sample - loss: 1.0952 - accuracy: 0.6071 - val_loss: 1.0945 - val_accuracy: 0.5526\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 1.0948 - accuracy: 0.6161 - val_loss: 1.0942 - val_accuracy: 0.5526\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 256us/sample - loss: 1.0945 - accuracy: 0.6071 - val_loss: 1.0939 - val_accuracy: 0.5526\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 248us/sample - loss: 1.0943 - accuracy: 0.6250 - val_loss: 1.0935 - val_accuracy: 0.6053\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 1.0939 - accuracy: 0.6429 - val_loss: 1.0932 - val_accuracy: 0.6316\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 1.0936 - accuracy: 0.6429 - val_loss: 1.0928 - val_accuracy: 0.6316\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 1.0932 - accuracy: 0.6429 - val_loss: 1.0924 - val_accuracy: 0.6316\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 247us/sample - loss: 1.0929 - accuracy: 0.6429 - val_loss: 1.0920 - val_accuracy: 0.6316\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 1.0925 - accuracy: 0.6429 - val_loss: 1.0915 - val_accuracy: 0.6316\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 1.0920 - accuracy: 0.6429 - val_loss: 1.0911 - val_accuracy: 0.6316\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 230us/sample - loss: 1.0916 - accuracy: 0.6429 - val_loss: 1.0906 - val_accuracy: 0.6316\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 257us/sample - loss: 1.0911 - accuracy: 0.6429 - val_loss: 1.0901 - val_accuracy: 0.6316\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 1.0907 - accuracy: 0.6429 - val_loss: 1.0896 - val_accuracy: 0.6316\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 1.0902 - accuracy: 0.6429 - val_loss: 1.0891 - val_accuracy: 0.6316\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 1.0897 - accuracy: 0.6429 - val_loss: 1.0886 - val_accuracy: 0.6316\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 1.0891 - accuracy: 0.6429 - val_loss: 1.0879 - val_accuracy: 0.6316\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 1.0885 - accuracy: 0.6429 - val_loss: 1.0873 - val_accuracy: 0.6316\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 245us/sample - loss: 1.0880 - accuracy: 0.6429 - val_loss: 1.0868 - val_accuracy: 0.6316\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 257us/sample - loss: 1.0874 - accuracy: 0.6429 - val_loss: 1.0861 - val_accuracy: 0.6316\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 242us/sample - loss: 1.0868 - accuracy: 0.6429 - val_loss: 1.0854 - val_accuracy: 0.6316\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 1.0861 - accuracy: 0.6429 - val_loss: 1.0848 - val_accuracy: 0.6316\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 1.0854 - accuracy: 0.6429 - val_loss: 1.0840 - val_accuracy: 0.6316\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 252us/sample - loss: 1.0847 - accuracy: 0.6429 - val_loss: 1.0833 - val_accuracy: 0.6316\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 246us/sample - loss: 1.0840 - accuracy: 0.6429 - val_loss: 1.0824 - val_accuracy: 0.6316\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 1.0832 - accuracy: 0.6429 - val_loss: 1.0816 - val_accuracy: 0.6316\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 258us/sample - loss: 1.0823 - accuracy: 0.6429 - val_loss: 1.0807 - val_accuracy: 0.6316\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 243us/sample - loss: 1.0815 - accuracy: 0.6429 - val_loss: 1.0797 - val_accuracy: 0.6316\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 244us/sample - loss: 1.0808 - accuracy: 0.6875 - val_loss: 1.0788 - val_accuracy: 0.6316\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 233us/sample - loss: 1.0798 - accuracy: 0.6429 - val_loss: 1.0778 - val_accuracy: 0.6842\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 255us/sample - loss: 1.0787 - accuracy: 0.7321 - val_loss: 1.0768 - val_accuracy: 0.6842\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 231us/sample - loss: 1.0777 - accuracy: 0.6786 - val_loss: 1.0757 - val_accuracy: 0.7105\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 1.0766 - accuracy: 0.7500 - val_loss: 1.0745 - val_accuracy: 0.7105\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 237us/sample - loss: 1.0755 - accuracy: 0.7679 - val_loss: 1.0734 - val_accuracy: 0.6842\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 239us/sample - loss: 1.0743 - accuracy: 0.6875 - val_loss: 1.0721 - val_accuracy: 0.6842\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 238us/sample - loss: 1.0732 - accuracy: 0.6696 - val_loss: 1.0707 - val_accuracy: 0.6842\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 241us/sample - loss: 1.0717 - accuracy: 0.7589 - val_loss: 1.0694 - val_accuracy: 0.6842\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 253us/sample - loss: 1.0704 - accuracy: 0.7500 - val_loss: 1.0679 - val_accuracy: 0.6842\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 229us/sample - loss: 1.0691 - accuracy: 0.6518 - val_loss: 1.0665 - val_accuracy: 0.7105\n",
      "\n",
      "Forming the grid-search model #26 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7fc734eb1090>, kernel=<tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7fc7348861d0>, epochs=50, batch_size=64\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 1.0983 - accuracy: 0.2589 - val_loss: 1.0978 - val_accuracy: 0.3684\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 189us/sample - loss: 1.0982 - accuracy: 0.3214 - val_loss: 1.0977 - val_accuracy: 0.3421\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 177us/sample - loss: 1.0980 - accuracy: 0.3214 - val_loss: 1.0976 - val_accuracy: 0.3421\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 1.0979 - accuracy: 0.3571 - val_loss: 1.0975 - val_accuracy: 0.3947\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 183us/sample - loss: 1.0978 - accuracy: 0.3661 - val_loss: 1.0974 - val_accuracy: 0.3947\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 1.0977 - accuracy: 0.3929 - val_loss: 1.0972 - val_accuracy: 0.4211\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 1.0976 - accuracy: 0.4375 - val_loss: 1.0971 - val_accuracy: 0.4474\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 202us/sample - loss: 1.0975 - accuracy: 0.4286 - val_loss: 1.0970 - val_accuracy: 0.4474\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 165us/sample - loss: 1.0973 - accuracy: 0.4554 - val_loss: 1.0969 - val_accuracy: 0.4474\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 1.0972 - accuracy: 0.4643 - val_loss: 1.0967 - val_accuracy: 0.4474\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 1.0971 - accuracy: 0.4821 - val_loss: 1.0966 - val_accuracy: 0.4474\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 1.0970 - accuracy: 0.4821 - val_loss: 1.0965 - val_accuracy: 0.4737\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 1.0968 - accuracy: 0.5179 - val_loss: 1.0964 - val_accuracy: 0.5000\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 171us/sample - loss: 1.0967 - accuracy: 0.5000 - val_loss: 1.0962 - val_accuracy: 0.5263\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 189us/sample - loss: 1.0966 - accuracy: 0.5357 - val_loss: 1.0961 - val_accuracy: 0.5263\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 1.0965 - accuracy: 0.5536 - val_loss: 1.0960 - val_accuracy: 0.5263\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 1.0963 - accuracy: 0.5714 - val_loss: 1.0958 - val_accuracy: 0.5263\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 193us/sample - loss: 1.0962 - accuracy: 0.5625 - val_loss: 1.0957 - val_accuracy: 0.5263\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 185us/sample - loss: 1.0960 - accuracy: 0.5804 - val_loss: 1.0956 - val_accuracy: 0.5526\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 177us/sample - loss: 1.0960 - accuracy: 0.5714 - val_loss: 1.0954 - val_accuracy: 0.5526\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 167us/sample - loss: 1.0958 - accuracy: 0.5982 - val_loss: 1.0953 - val_accuracy: 0.5526\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 1.0957 - accuracy: 0.6071 - val_loss: 1.0951 - val_accuracy: 0.5526\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 165us/sample - loss: 1.0955 - accuracy: 0.6071 - val_loss: 1.0950 - val_accuracy: 0.5526\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 1.0953 - accuracy: 0.6161 - val_loss: 1.0948 - val_accuracy: 0.5526\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 186us/sample - loss: 1.0952 - accuracy: 0.6161 - val_loss: 1.0947 - val_accuracy: 0.5526\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 178us/sample - loss: 1.0952 - accuracy: 0.6161 - val_loss: 1.0945 - val_accuracy: 0.5526\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 176us/sample - loss: 1.0949 - accuracy: 0.6339 - val_loss: 1.0944 - val_accuracy: 0.5789\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 178us/sample - loss: 1.0948 - accuracy: 0.6339 - val_loss: 1.0942 - val_accuracy: 0.5789\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 1.0946 - accuracy: 0.6339 - val_loss: 1.0940 - val_accuracy: 0.6053\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 177us/sample - loss: 1.0945 - accuracy: 0.6339 - val_loss: 1.0939 - val_accuracy: 0.6053\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 178us/sample - loss: 1.0943 - accuracy: 0.6429 - val_loss: 1.0937 - val_accuracy: 0.6053\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 1.0942 - accuracy: 0.6429 - val_loss: 1.0935 - val_accuracy: 0.6053\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 1.0940 - accuracy: 0.6429 - val_loss: 1.0933 - val_accuracy: 0.6053\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 176us/sample - loss: 1.0938 - accuracy: 0.6429 - val_loss: 1.0931 - val_accuracy: 0.6053\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 186us/sample - loss: 1.0936 - accuracy: 0.6429 - val_loss: 1.0929 - val_accuracy: 0.6316\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 1.0934 - accuracy: 0.6429 - val_loss: 1.0927 - val_accuracy: 0.6316\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 186us/sample - loss: 1.0932 - accuracy: 0.6429 - val_loss: 1.0925 - val_accuracy: 0.6316\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 190us/sample - loss: 1.0931 - accuracy: 0.6429 - val_loss: 1.0923 - val_accuracy: 0.6316\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 1.0929 - accuracy: 0.6429 - val_loss: 1.0921 - val_accuracy: 0.6316\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 1.0928 - accuracy: 0.6429 - val_loss: 1.0919 - val_accuracy: 0.6316\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 194us/sample - loss: 1.0925 - accuracy: 0.6429 - val_loss: 1.0917 - val_accuracy: 0.6316\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 183us/sample - loss: 1.0923 - accuracy: 0.6429 - val_loss: 1.0915 - val_accuracy: 0.6316\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 185us/sample - loss: 1.0921 - accuracy: 0.6429 - val_loss: 1.0913 - val_accuracy: 0.6316\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 1.0919 - accuracy: 0.6429 - val_loss: 1.0911 - val_accuracy: 0.6316\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 1.0916 - accuracy: 0.6429 - val_loss: 1.0908 - val_accuracy: 0.6316\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 182us/sample - loss: 1.0914 - accuracy: 0.6429 - val_loss: 1.0906 - val_accuracy: 0.6316\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 1.0913 - accuracy: 0.6429 - val_loss: 1.0903 - val_accuracy: 0.6316\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 1.0910 - accuracy: 0.6429 - val_loss: 1.0901 - val_accuracy: 0.6316\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 1.0907 - accuracy: 0.6429 - val_loss: 1.0899 - val_accuracy: 0.6316\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 191us/sample - loss: 1.0906 - accuracy: 0.6429 - val_loss: 1.0896 - val_accuracy: 0.6316\n",
      "\n",
      "Best score (highest validation accuracy) found via grid search: accuracy=0.973684 from model iteration #3\n",
      "The best modeling parameters are: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fc734eb1250>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fc734eb1a50>, epochs=50, batch_size=16\n",
      "Total time for performing grid-search of the best parameters: 0:01:07.205595\n"
     ]
    }
   ],
   "source": [
    "startTimeModule = datetime.now()\n",
    "\n",
    "# Set up grid search using different epochs, batch sizes, and optimizers\n",
    "optz_1 = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "optz_2 = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "optz_3 = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "optimizer_grid = [optz_1, optz_2, optz_3]\n",
    "print('Optimizer candidate #1 has the object ID of', optz_1)\n",
    "print('Optimizer candidate #2 has the object ID of', optz_2)\n",
    "print('Optimizer candidate #3 has the object ID of', optz_3)\n",
    "\n",
    "init_1 = tf.keras.initializers.he_uniform(seed=seedNum)\n",
    "init_2 = tf.keras.initializers.Orthogonal(seed=seedNum)\n",
    "init_3 = tf.keras.initializers.RandomUniform(seed=seedNum)\n",
    "init_grid = [init_1, init_2, init_3]\n",
    "print('Initializer candidate #1 has the object ID of', init_1)\n",
    "print('Initializer candidate #2 has the object ID of', init_2)\n",
    "print('Initializer candidate #3 has the object ID of', init_3)\n",
    "\n",
    "epoch_grid = [default_epoch]\n",
    "batch_grid = [int(default_batch/2), default_batch, int(default_batch*2)]\n",
    "\n",
    "best_score = 0\n",
    "grid_iteration = 0\n",
    "best_iteration = 0\n",
    "best_optimizer = default_optimizer\n",
    "best_kernel_init = default_kernel_init\n",
    "best_epoch = default_epoch\n",
    "best_batch = default_batch\n",
    "\n",
    "for optimizer in optimizer_grid:\n",
    "    for kernel_init in init_grid:\n",
    "        for epoch_num in epoch_grid:\n",
    "            for batch_num in batch_grid:\n",
    "                print('\\nForming the grid-search model #%d using: optimizer=%s, kernel=%s, epochs=%d, batch_size=%d'\n",
    "                      % (grid_iteration, optimizer, kernel_init, epoch_num, batch_num))\n",
    "                reset_random(seedNum)\n",
    "                grid_model = create_customized_model(optimizer, kernel_init)\n",
    "                grid_hist = grid_model.fit(X_train, y_train, epochs=epoch_num, batch_size=batch_num, \n",
    "                                       validation_data=(X_test, y_test), verbose=1)\n",
    "                if(grid_hist.history['val_accuracy'][-1] > best_score):\n",
    "                    best_score = grid_hist.history['val_accuracy'][-1]\n",
    "                    best_iteration = grid_iteration\n",
    "                    best_optimizer = optimizer\n",
    "                    best_kernel_init = kernel_init\n",
    "                    best_epoch = epoch_num\n",
    "                    best_batch = batch_num\n",
    "                grid_iteration = grid_iteration + 1\n",
    "\n",
    "# summarize results\n",
    "print(\"\\nBest score (highest validation accuracy) found via grid search: accuracy=%f from model iteration #%d\"\n",
    "      % (best_score, best_iteration))\n",
    "print('The best modeling parameters are: optimizer=%s, kernel=%s, epochs=%d, batch_size=%d'\n",
    "      % (best_optimizer, best_kernel_init, best_epoch, best_batch))\n",
    "print('Total time for performing grid-search of the best parameters:', (datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "best_kernel_init = tf.keras.initializers.Orthogonal(seed=seedNum)\n",
    "best_epoch = 50\n",
    "best_batch = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 4. Optimize Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5. Finalize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 5. Finalize Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forming the final model using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fc73499c890>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7fc73499c710>, epochs=50, batch_size=16\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 1s 7ms/sample - loss: 1.2221 - accuracy: 0.3125 - val_loss: 1.1785 - val_accuracy: 0.3421\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 0s 312us/sample - loss: 1.1886 - accuracy: 0.3393 - val_loss: 1.1403 - val_accuracy: 0.4211\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 314us/sample - loss: 1.1545 - accuracy: 0.3571 - val_loss: 1.1057 - val_accuracy: 0.4211\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 0s 406us/sample - loss: 1.1224 - accuracy: 0.3929 - val_loss: 1.0733 - val_accuracy: 0.4474\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 312us/sample - loss: 1.0935 - accuracy: 0.4018 - val_loss: 1.0412 - val_accuracy: 0.4474\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 1.0642 - accuracy: 0.4018 - val_loss: 1.0105 - val_accuracy: 0.4737\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 321us/sample - loss: 1.0366 - accuracy: 0.4196 - val_loss: 0.9813 - val_accuracy: 0.5526\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 312us/sample - loss: 1.0115 - accuracy: 0.4554 - val_loss: 0.9526 - val_accuracy: 0.5526\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.9844 - accuracy: 0.5268 - val_loss: 0.9264 - val_accuracy: 0.6316\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 321us/sample - loss: 0.9609 - accuracy: 0.5804 - val_loss: 0.9001 - val_accuracy: 0.7632\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 0.9379 - accuracy: 0.6250 - val_loss: 0.8740 - val_accuracy: 0.8158\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 0.9145 - accuracy: 0.6429 - val_loss: 0.8494 - val_accuracy: 0.8158\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 0s 334us/sample - loss: 0.8927 - accuracy: 0.6786 - val_loss: 0.8252 - val_accuracy: 0.8158\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 0s 297us/sample - loss: 0.8709 - accuracy: 0.7143 - val_loss: 0.8017 - val_accuracy: 0.8421\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 0s 323us/sample - loss: 0.8497 - accuracy: 0.7411 - val_loss: 0.7792 - val_accuracy: 0.8947\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 0s 341us/sample - loss: 0.8301 - accuracy: 0.7411 - val_loss: 0.7563 - val_accuracy: 0.8947\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 0s 293us/sample - loss: 0.8094 - accuracy: 0.7411 - val_loss: 0.7349 - val_accuracy: 0.8684\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.7902 - accuracy: 0.7321 - val_loss: 0.7140 - val_accuracy: 0.9211\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 0s 323us/sample - loss: 0.7708 - accuracy: 0.7500 - val_loss: 0.6942 - val_accuracy: 0.9211\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 0s 329us/sample - loss: 0.7530 - accuracy: 0.7589 - val_loss: 0.6750 - val_accuracy: 0.9211\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 0s 321us/sample - loss: 0.7353 - accuracy: 0.7768 - val_loss: 0.6560 - val_accuracy: 0.9211\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 0s 344us/sample - loss: 0.7180 - accuracy: 0.7768 - val_loss: 0.6379 - val_accuracy: 0.9211\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 0s 324us/sample - loss: 0.7013 - accuracy: 0.7768 - val_loss: 0.6204 - val_accuracy: 0.9211\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 0s 340us/sample - loss: 0.6853 - accuracy: 0.7768 - val_loss: 0.6032 - val_accuracy: 0.9211\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 0s 326us/sample - loss: 0.6695 - accuracy: 0.7768 - val_loss: 0.5871 - val_accuracy: 0.9211\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 0s 313us/sample - loss: 0.6545 - accuracy: 0.7857 - val_loss: 0.5720 - val_accuracy: 0.9211\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 0s 331us/sample - loss: 0.6405 - accuracy: 0.7857 - val_loss: 0.5574 - val_accuracy: 0.9211\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 0s 335us/sample - loss: 0.6264 - accuracy: 0.7857 - val_loss: 0.5439 - val_accuracy: 0.9211\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 0s 328us/sample - loss: 0.6133 - accuracy: 0.7857 - val_loss: 0.5305 - val_accuracy: 0.9211\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 0s 323us/sample - loss: 0.6005 - accuracy: 0.7857 - val_loss: 0.5175 - val_accuracy: 0.9211\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 0.5883 - accuracy: 0.7857 - val_loss: 0.5054 - val_accuracy: 0.9211\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 0s 350us/sample - loss: 0.5765 - accuracy: 0.8036 - val_loss: 0.4934 - val_accuracy: 0.9211\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 0s 326us/sample - loss: 0.5651 - accuracy: 0.8036 - val_loss: 0.4820 - val_accuracy: 0.9211\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 0s 308us/sample - loss: 0.5542 - accuracy: 0.8036 - val_loss: 0.4711 - val_accuracy: 0.9211\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 0s 330us/sample - loss: 0.5435 - accuracy: 0.8036 - val_loss: 0.4609 - val_accuracy: 0.9211\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 0s 320us/sample - loss: 0.5334 - accuracy: 0.8036 - val_loss: 0.4510 - val_accuracy: 0.9211\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 0.5239 - accuracy: 0.8125 - val_loss: 0.4412 - val_accuracy: 0.9211\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 0s 323us/sample - loss: 0.5143 - accuracy: 0.8214 - val_loss: 0.4321 - val_accuracy: 0.9211\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 0s 337us/sample - loss: 0.5053 - accuracy: 0.8214 - val_loss: 0.4236 - val_accuracy: 0.9211\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 0s 325us/sample - loss: 0.4967 - accuracy: 0.8214 - val_loss: 0.4151 - val_accuracy: 0.9211\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 0s 343us/sample - loss: 0.4883 - accuracy: 0.8214 - val_loss: 0.4073 - val_accuracy: 0.9211\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.4801 - accuracy: 0.8214 - val_loss: 0.3998 - val_accuracy: 0.9211\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 0s 437us/sample - loss: 0.4724 - accuracy: 0.8214 - val_loss: 0.3923 - val_accuracy: 0.9211\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.4647 - accuracy: 0.8214 - val_loss: 0.3851 - val_accuracy: 0.9211\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.4575 - accuracy: 0.8214 - val_loss: 0.3780 - val_accuracy: 0.9211\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 0s 312us/sample - loss: 0.4503 - accuracy: 0.8214 - val_loss: 0.3717 - val_accuracy: 0.9211\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 0s 326us/sample - loss: 0.4439 - accuracy: 0.8214 - val_loss: 0.3651 - val_accuracy: 0.9211\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 0s 330us/sample - loss: 0.4370 - accuracy: 0.8304 - val_loss: 0.3592 - val_accuracy: 0.9211\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 0s 317us/sample - loss: 0.4309 - accuracy: 0.8304 - val_loss: 0.3535 - val_accuracy: 0.9211\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 0s 338us/sample - loss: 0.4248 - accuracy: 0.8304 - val_loss: 0.3480 - val_accuracy: 0.9211\n"
     ]
    }
   ],
   "source": [
    "# Create the final model for evaluating the test dataset\n",
    "print('Forming the final model using: optimizer=%s, kernel=%s, epochs=%d, batch_size=%d'\n",
    "      % (best_optimizer, best_kernel_init, best_epoch, best_batch))\n",
    "reset_random(seedNum)\n",
    "final_model = create_customized_model(best_optimizer, best_kernel_init)\n",
    "final_hist = final_model.fit(X_train, y_train, epochs=best_epoch, batch_size=best_batch, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 83\n",
      "Trainable params: 83\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the final model\n",
    "print(final_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'sequential_28', 'layers': [{'class_name': 'Dense', 'config': {'name': 'dense_56', 'trainable': True, 'batch_input_shape': (None, 4), 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_57', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]}\n"
     ]
    }
   ],
   "source": [
    "# Display the configuration of the final model\n",
    "print(final_model.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAALJCAYAAACdjhTPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd5yU1fXH8c9hqQKKFEUBhfgTFaOCrr1EoygWVFQUsMaCXRM1NixgiZIYOxFLDEEWUGmiEjsIqFnACIggEYwK2AABQQSW5fz+uLO6rJSZ3Xnm2Zn5vl+vfc3OzDPPPTuzsGfunHuPuTsiIiIiIpKcGnEHICIiIiKSTZRAi4iIiIikQAm0iIiIiEgKlECLiIiIiKRACbSIiIiISAqUQIuIiIiIpEAJtEieMbMVZvarNJynt5kNSkdMUYxpZuPM7MKI4znTzF5L97FxMrNtzWy8mS03s7/GHU+mmNk9Zvb7uOOImpldaWZ9445DJNspgRbJUWb2mZn9mEiYy762d/cG7v5pxGMfbmZuZiMr3L5X4vZxUY6/KWbWv9zzscbMSspd/1cq53L3Inc/Ot3HpqrCa/2NmQ0wswaVPF1PYBGwpbtfm8Ywqy0zawacAzxe4fY2ZrbOzB6LJ7JIPAmcaWbbxB2ISDZTAi2S2zonEuayry8zOPZC4EAza1LutnOB/2Ywhl9w90vKng/gT8Cz5Z6fY8uOM7Oa8UVZKZ0TP9PeQCFwSyoPtqAGsCMw0yvRZSsLn7My5wFj3P3HCrefAywBzjCzOpkMyMwKojivu68C/kX42USkkpRAi+SZxAzw/yW+H2Bm/czs5cRH9sVmtlO5Yx8ys3lm9r2ZvW9mh6Yw1BpgFNAtca4C4AygqEI8B5nZZDNblrg8qNx9bczs7URsrwNNKzz2ADN718yWmtk0Mzs8xadjPYmZ3BvMbDrwg5nVNLMbzWxuIoaZZtal3PHnmdnEctfdzC4xs08SMfUzM6vEsQVm9lczW2Rm/zOzKxLHbzZBdfcFhATp15t7jhJlLneb2TvASmAg4U3O9YnZ7KPMrI6ZPWhmXya+HixLJhOfNMxPPGdfA/+wUGbzvJkNSjxnH5pZWzO7ycy+Tfw+HV0uht+Z2azEsZ+a2cXl7is7/7WJx35lZr8rd3+9xPP0eeL3Z6KZ1dvcz70BxwJvV/hdMEKSeQtQAnSucP9JZjY18W9jrpl1Stze2Mz+kXiulpjZqMTt673+idsq/lt8zMzGmNkPwBFmdryZfZAYY56Z9a7w+EPK/YzzEmPsa+FTiIJyx51iZtPKPXQccPwmng8R2Qwl0CLSDegDbA3MAe4ud99koD3QGBgMPG9mdVM490B+nuk6BpgB/DQLbmaNgZeBh4EmwP3Ay/bzrPVg4H1C4nwnIbkre2yLxGPvSsR3HTDcwsfxVdGdkFw0cve1wFzgUGArwvM0yMy228TjTwD2BfYETif83KkeexEhqWtPmFE+OdngzawVcBzwQZLP0dmEso2GwO8Ib3D+nJiRfwPoBRyQiGUvYD/Wn91unjj3jonzQEg2nyH8Tn0AvEr4e9MCuIP1SyW+TTwPWybGf8DM9q5w/q0Sj70A6GdmWyfuuw/YBzgoEcP1wLpK/G7sAcyucNshQEtgKPAc6//u7Uf43f4j0Ag4DPgscfczwBbA7sA2wAMbGXNDehD+/TUEJgI/EP79NCL8Tl5qZicnYtiR8EbpEaAZ4fWZ6u6TgcVA+XKhsxPxlplFeC1FpJKUQIvktlGJ2amlZTNhGzDS3SclksUiwh9iANx9kLsvdve17v5XoA6wS7KDu/u7QGMz24WQCAyscMjxwCfu/kxijCHAx0BnM9uBkFze6u6r3X088GK5x55F+Nh9jLuvc/fXgSmE5LEqHnb3eWUf57v78+7+ZWKMZ4FPCEnkxtzr7kvd/QtgLOWezxSOPR14yN3nu/sS4N4k4h5lZksJidfbhPKUZJ6jAe7+UeL5L9nAec8E7nD3b919IeFNxNnl7l8H3J54jcpKICa4+6uJ36nnCQnevYnzDwVam1kjAHd/2d3nevA28BrhDUuZksT4Je4+BlgB7GKh3OR84Gp3X+Dupe7+rruvTvLnLq8RsLzCbecC/0o8/4OBTvZz3fAFwNPu/nri/Avc/ePEG6tjgUvcfUki5rdJ3gvu/k7inKvcfZy7f5i4Ph0YAvwmcWwP4A13H5IYZ7G7T03c98/Ec1D2JvWYxM9QZjnhTYmIVJISaJHcdrK7N0p8bWwW8+ty368Eflp8ZmbXJT5eX5ZIzraiQhlFEp4BrgCOAEZWuG974PMKt31OmG3cHlji7j9UuK/MjkDXcm8QlhJmDTc1O5yMeeWvmNk5iY/qy8b4NZt+Djb6fKZw7PYV4lgvpo0oe613dPfLEslsMs/R5s5d8TX6PHFbmYWJutryvin3/Y/AIncvLXcdEj+rmR1rZv82s+8S8R3H+s/v4kQiXqbseWoK1CV8QlBRqr8bSwizviRiqgd0JVFu5O7vAV8QklaAVhsZtxXwXSLproyKv3v7m9lYM1toZsuAS/j5udlYDACDCG9C6xPejE1w96/K3d8QWFbJGEUEJdAishEW6p2vJ/wB3trdGxH+6FqKp3oGuIwwI7iywn1fEpKd8nYAFgBfAVsnkoDy95WZBzxT7g1CI3ev7+7JzNZuyk+L5xIfkz9JeAPQJPEczCD15yBVXxHKB8q0quR5knmONrdYsOJrtAPlynCSePxGWailHk4oxdg28fyOIbnndxGwCthpA/el+rsxHWhb7noXQknJ38zsawv13S34uYxj3ibGbVw2u17BD4TSDgDMrPkGjqn4XA4GRgOt3H0roD8/Pzcbi6GsDv494BTCpwXPVDhkN2BaxceJSPKUQIvIxjQE1hJ206hpZrcRkoqUuPv/CB8799rA3WOAtmbWw8KCvTOAdsBL7v454WP3PmZW28wOYf2FXGWzbMdYWHRXN7HorOUvh6m0+oSkZiGEBW8kFudF7DngajNrkUjGbqjkedLxHA0BbjGzZmbWFLgtcd50qE0oC1oIrDWzY1m/dnej3H0d8DRwv5ltn/j5Dkwk5an+3GP4uTQCQqL8NKE2un3i62BgLzPbA/g78DszO9LMaiRep10Ts7z/IiTeW5tZLTM7LHHOacDuZtY+sY6gdxI/ZkPCjPaqRN11j3L3FQFHmdnpiX87TcysfLnQQMIb4D2AERXO+5tEnCJSSUqgRWRjXgVeIWw79zlhti+ZUoJfcPeJvoEt9Nx9MWEB2bWEhU/XAye4+6LEIT2A/YHvgNspV0Pt7vOAk4CbCQnYPMKirrT9v+buM4G/EmbzviEkI++k6/yb8CShFng6YRHeGMKbmdJNPaiiND1HdxHeyEwHPgT+k7itytx9OXAV4Q3DEsLrPTqFU1yXiGky4XekL1CjEj/3QOA4C7t6tACOBB5096/Lfb1P+PdwrrtPIrHgkfCpzNv8PEt/NqFu+2PCAsnfJ37W/xIWUL5BqKNfb0eOjbgMuMPMlhPeuDxXdkeibv44wr+d74CprL8wcGQippHlP/lJJO/HEeqkRaSSzFPf6lNERDIoMTPb390rlrtImpjZn4Bv3f3BuGNJFzObC1zsYTeVstuuJJSEXB9fZCLZTwm0iEg1k1jEdgRhFnpbQp3wv90951tNS3qY2amEGfm2iXIXEUkjJdAiItWMmW1BKAvYlbBrxcuE7dq+jzUwyQpmNo6wluBsd3815nBEcpISaBERERGRFGgRoYiIiIhICmrGHUCqmjZt6q1bt447DBERERHJce+///4id29W8fasS6Bbt27NlClT4g5DRERERHKcmVXslguohENEREREJCVKoEVEREREUqAEWkREREQkBVlXAy0iIiIi0SspKWH+/PmsWrUq7lAiV7duXVq2bEmtWrWSOl4JtIiIiIj8wvz582nYsCGtW7fGzOIOJzLuzuLFi5k/fz5t2rRJ6jEq4RARERGRX1i1ahVNmjTJ6eQZwMxo0qRJSjPtSqBFREREZINyPXkuk+rPqQRaRERERCQFSqBFREREpNpZvHgx7du3p3379jRv3pwWLVr8dH3NmjWbfOyUKVO46qqrIotNiwhFREREpNpp0qQJU6dOBaB37940aNCA66677qf7165dS82aG05lCwsLKSwsjCw2zUCLiIiISFY477zzuOSSS9h///25/vrrmTRpEgceeCAdOnTgoIMOYvbs2QCMGzeOE044AQjJ9/nnn8/hhx/Or371Kx5++OEqx6EZaBHJHHe4+mp47724IxERkc3p2zf8vw38/p5tmTq7blpP336XVTx40zfJHVxa+tO38+fP591336WgoIDvv/+eCRMmULNmTd544w1uvvlmhg8f/ouHf/zxx4wdO5bly5ezyy67cOmllya95/OGKIEWkcwZNQoeeQQOPhi22iruaEREZFMKCqAsySyoAenekaOgxs/nT0HXrl0pKCgAYNmyZZx77rl88sknmBklJSUbfMzxxx9PnTp1qFOnDttssw3ffPMNLVu2rHToSqBFJDPWroVevWDXXWHcONhI3ZqIiFQTs2bBzjsD8OCAKAbYAtg6uUMTCTNA/fr1f/r+1ltv5YgjjmDkyJF89tlnHH744Rt8eJ06dcqdqoC1a9dWJuCf6C+YiGTGwIHhP+Phw5U8i4hIWixbtowWLVoAMGDAgIyNq0WEIhK9Vavg9tthv/2gS5e4oxERkRxx/fXXc9NNN9GhQ4cqzyqnwjxRHJ4tCgsLfcqUKXGHISKpuP9+uPZaeOstOOKIuKMREZEkzJo1i9122y3uMDJmQz+vmb3v7r/YD08z0CISrWXL4O674eijlTyLiEhOiDSBNrNOZjbbzOaY2Y0buH9HM3vTzKab2Tgzq/xySBGpnu67D777Du65J+5IRERE0iKyBNrMCoB+wLFAO6C7mbWrcNh9wEB33xO4A9BfWJFc8s03oXzjjDNg773jjkZERCQtopyB3g+Y4+6fuvsaYChwUoVj2gFvJb4fu4H7RSSb3XknrFkTLkVERHJElAl0C2BeuevzE7eVNw04JfF9F6ChmTWpeCIz62lmU8xsysKFCyMJVkTS7NNP4fHH4cILf9pHVEREJBfEvRnrdcCjZnYeMB5YAJRWPMjdnwCegLALRyYDFMlqixaFRXypaNUKateu+ti33ho6TN16a9XPJSIiUo1EmUAvAFqVu94ycdtP3P1LEjPQZtYAONXdl0YYk0j+ePdd+O1vYfXq1B63yy7w+ushka6sqVNh8GC48UbYfvvKn0dERPLW4sWLOfLIIwH4+uuvKSgooFmzZgBMmjSJ2puZ7Bk3bhy1a9fmoIMOSntsUSbQk4GdzawNIXHuBvQof4CZNQW+c/d1wE3A0xHGI5I/3OH666FxY7j3XjBL7nHLl8NNN8Ehh4Qkum3byo3fqxdsvTXccEPlHi8iInmvSZMmTJ06FYDevXvToEEDrrvuuqQfP27cOBo0aJBdCbS7rzWzK4BXgQLgaXf/yMzuAKa4+2jgcOAeM3NCCcflUcUjkldefhneeQf694dzzkntsQccAMccA4ceCq+9Bnvtldrjx4+HMWOgb19o1Ci1x4qIiGzC+++/zzXXXMOKFSto2rQpAwYMYLvttuPhhx+mf//+1KxZk3bt2nHvvffSv39/CgoKGDRoEI888giHHnpo2uJQJ0KRXFNaCu3bh9KNjz4Kdcip+vhj6NgRVqwIyfCBByb3OHc4+GD4/HOYMwfq1Ut9bBERqRbW68z3+9+H8rx0at8eHnwwqUN79+5N/fr1GTlyJC+88ALNmjXj2Wef5dVXX+Xpp59m++2353//+x916tRh6dKlNGrUKOVZ61Q6Eca9iFBE0m3wYJgxA559tnLJM8Cuu8LEiXDUUeHrhRfC5eaMHg3vvQdPPKHkWURE0mr16tXMmDGDjh07AlBaWsp2220HwJ577smZZ57JySefzMknnxx5LEqgRXLJ6tVw222wzz5w2mlVO9eOO8KECaGc4/jjYehQ6NJl48eXlsLNN4e66d/9rmpji4hI9ZLkTHGU3J3dd9+d99577xf3vfzyy4wfP54XX3yRu+++mw8//DDSWCJt5S0iGfb44/DZZ6Ftdo00/PNu3hzGjQtdBLt2hYEDN37soEEwcybcfTfU1HtzERFJrzp16rBw4cKfEuiSkhI++ugj1q1bx7x58zjiiCPo27cvy5YtY8WKFTRs2JDly5dHEosSaJFcsXw53HVX2LoumXKLZG29ddiR4/DD4dxz4dFHf3nMqlVh5ruwEE49NX1ji4iIJNSoUYNhw4Zxww03sNdee9G+fXveffddSktLOeuss9hjjz3o0KEDV111FY0aNaJz586MHDmS9u3bM2HChLTGomkikVxx//2wcGFq29Ylq0EDeOkl6NYNrrwyNGe5+eafx+nfH774Ap5+Ov1ji4hI3uvdu/dP348fP/4X90+cOPEXt7Vt25bp06dHEo9moEVywcKFcN99YfZ3332jGaNuXRg2DM4+G265Jewz7Q7ffx/KNo46ChIb3ouIiOQyzUCL5IK774YffwyXUapZEwYMgK22Cgn70qWw7bahZfg990Q7toiISDWhBFok2332GTz2WNj5Ypddoh+vRg14+OHQJOWuu8JtXbuG+mcREckp7o7lQWleqn1RVMIhku1uvz0ktbffnrkxzeDOO8MsdIsWPyfSIiKSM+rWrcvixYtTTi6zjbuzePFi6tatm/Rj1IlQJJvNmAF77gnXXQd//nM8Mbhr4aCISA4qKSlh/vz5rFq1Ku5QIle3bl1atmxJrQoNyNSJUCQX9eoFW24JN94YXwxKnkVEclKtWrVo06ZN3GFUSyrhEMlW77wTWmffcAM0bhx3NCIiInlDCbRINnIPs87Nm8NVV8UdjYiISF5RCYdINhozBiZOhL/9DerXjzsaERGRvKIZaJFss24d3HQT7LQTXHhh3NGIiIjkHc1Ai2SbwYPhww9hyBCosFpYREREoqcZaJFssmYN3HordOgAp58edzQiIiJ5STPQItnk8cdD58H+/UPzFBEREck4/QUWyRbLl4fuf4cfDkcfHXc0IiIieUsJtEg2cIdbboGFC+Hee9W8REREJEZKoEWqu3Xr4Oqr4eGH4fLLYf/9445IREQkr6kGWqQ6W7sWLrgABg6Ea66B++6LOyIREZG8pwRapLpavRq6dYNRo0Ltc69eKt0QERGpBpRAi1RHK1ZAly7wxhuhdOPKK+OOSERERBKUQItUN0uWwHHHwaRJ8M9/wjnnxB2RiIjIepYvh3/9C958M7QoiNp990GTJtGPkywl0CLVyddfwzHHwMcfw7BhYRZaRESkGli0CEaPhpEj4fXXQ6Vho0aw5ZbRj716dfRjpEIJtEh18fnncNRR8OWX8NJL0LFj3BGJiEiemzcvLMUZMQLGjw8bQ+24I1x2WZjjOeggKCiIO8rMUwItUh18/HFImFesCG/rDzoo7ohERCRPzZ4dEuaRI2Hy5HBbu3Zw881wyinQvr3WtCuBFonbBx+Esg0zGDcO9tor7ohERFI2d+7PCZd73NFIZbjDzJnhC2C//eCee8JM8y67xBtbdaMEWiROEyfC8cfDVluFHTfato07IhGRpLjD9OkhaR45MnwP8KtfQZ068cYmlbf99nDppXDyydCyZdzRVF9KoEU2ZMWKUJMcpZkz4dxzoVWrULaxww7RjiciUkXr1sG///3zx/uffho+PDvkELj//jBT2bp13FGKRE8JtEhFP/wAe+wBn30W/Vjt28Orr8I220Q/lohIJaxZE6rLRo4Mi8m+/hpq1YIjj4Qbb4QTT4Rtt407SpHMUgItUtFDD4Xk+eGHoXnz6MapWTPsutGwYXRjiIhUwsqV4b39iBFhU6ClS2GLLcIW9V26/Fx5JpKvlECLlLd4MfTtG6ZU1P1PRPLIkiUhWR45El55BX78ERo3hpNOCjsvdOwI9erFHaVI9aAEWqS8e+8N7ZXuvjvuSEREIvfVV/DCCyFpfustWLs2LCI7//ww03zYYaFcQ0TWF2kCbWadgIeAAuApd7+3wv07AP8EGiWOudHdx0QZk8hGzZ8PjzwCZ58Nv/513NGIiETi009DwjxiBLz3XthN4//+D665Jsw077sv1KgRd5Qi1VtkCbSZFQD9gI7AfGCymY1295nlDrsFeM7dHzOzdsAYoHVUMYlsUu/e4S9Jnz5xRyIi1cjcuXDLLaFJaLZbvBg++ih83759+O+uSxfYfXc1xhBJRZQz0PsBc9z9UwAzGwqcBJRPoB0o66C+FZAD/z1JVvr4Y/jHP0Lds/ZgEhGgpCRszda7N9SuDXvvHXdEVdeq1c/lGW3axB2NSPaKMoFuAcwrd30+sH+FY3oDr5nZlUB94KgI4xHZuFtuCUvMe/WKOxIRqQamTIELL4Rp00Ky+cgj0KJF3FGJSHURd5VTd2CAu7cEjgOeMbNfxGRmPc1siplNWbhwYcaDlBw3aRIMHw7XXQfNmsUdjYjEaMWKUAu8//7w7behTnjECCXPIrK+KBPoBUCrctdbJm4r7wLgOQB3fw+oCzSteCJ3f8LdC929sJkSHEkn99AJoFmz8FdTRPLWK6+E9cMPPAA9e8KsWWH2WUSkoigT6MnAzmbWxsxqA92A0RWO+QI4EsDMdiMk0Jpilsx5/XUYOzaUcKihiUhe+vZbOPNMOPbYsM/xhAnw2GNqFCIiGxdZAu3ua4ErgFeBWYTdNj4yszvM7MTEYdcCF5nZNGAIcJ67e1Qxiaxn3Tq46aawaPDii+OORkQyzB3++U/YbTd4/nm4/XaYOhUOOSTuyESkuot0H+jEns5jKtx2W7nvZwIHRxmDyEYNGwb/+Q8MHAh16sQdjYhk0Ny5cMkl8MYbcNBB8OST0K5d3FGJSLZQJ0LJTyUlYceNX/8aevSIOxqRjFq+HMaMCc00pk6NO5p4fP556LD3t7+FD6DUOEREUqEEWvLT00/DnDkwejQUFMQdjUjkFi4Mv+4jR4bS/zVrYJttQrlCPrZqPuqoUMGl3TVEpDKUQEv+WbkytN86+GA44YS4oxGJzBdfwKhRYRu2CRNC2X/r1nD55WF3iYMO0vtHEZHKUAIt+efhh+Grr+C559S7VnLOrFlhlnnkyNAMBEKb5l69QtLcvr1+7UVEqkoJtOSXJUugb184/ngttRcAvvkm9NAZOzbuSKqupCRsyQahEci994akuW3beOMSEck1SqAlv9x7LyxbBn/6U9yRSMzcYcAAuPZa+OEHOO20sAdwtmvfPiTNqu0VEYmOEmjJHwsWhPKNM8+EPfeMOxqJ0SefhJ0Xxo6FQw+FJ56AXXeNOyoREckW2rhH8kefPlBaCnfcEXckEpOSErjnnvD+6f33oX9/GDdOybOIiKRGM9CSH2bPDlvXXXYZtGkTdzQSg0mT4KKLYPp0OOUUeOQR2H77uKMSEZFspBloyQ+33gp164atCCSvrFgBv/89HHggLFoUdqcYPlzJs4iIVJ4SaMl906fD88+H1WLbbht3NJJBY8aELdweeijUPM+cCSefHHdUIiKS7ZRAS+577bVwedll8cYhGfPtt9C9e9itsH59mDgxtGzeaqu4IxMRkVygGmjJfcXFoe5Zs885bcUKeOWVUKLx4ouwejX07g033gh16sQdnYiI5BIl0JL7iotDz2LJOYsXh2R55MjwQcOqVdC0KXTtGpqj7LZb3BGKiEguUgItue2rr2DevNCWTXLCggUwahSMGAFvvx12JmzVCnr2DLtrHHww1NT/bCIiEiH9mZHcNmlSuNxvv3jjkCr573/DLPOIET+/pLvuCjfcELru7bMPmMUbo4iI5A8l0JLbJk2CggLYe++4I5FKmD8frrgCXnghXC8shLvvDkmzyjNERCQuSqAltxUXh7Zz9erFHYmkoLQUHnsMbr4Z1q6FO++Ec86BHXaIOzIREREl0JLL1q2DyZOhR4+4I5EUzJgROgb++9/QsWNot/2rX8UdlYiIyM+UQEvumj0bvv8+rxcQrlwZdqaIUp06Ya/lqlq1KpRn9O0LW24JAwfCWWeptllERKofJdCSu4qLw2WeLiAcNAguuADWrIl2HLOw88Upp4Ta5NatUz/H+PFhF43Zs0PSfP/90KxZ2kMVERFJCyXQkrsmTYKGDcN2DXnm8cfh0kvhsMNCYhulhQth9Gi45prw1aFDSKRPOQXatdv0DPLSpXD99fDkkyHxfuUVOOaYaOMVERGpKnP3uGNISWFhoU+ZMiXuMCQb7LMPNGoEb74ZdyQZ9cADIZE97jgYNixz6yfnzg1bzY0cCe+9B+6w884/z0zvuy/UqBGOdYfhw+HKK0Pb7T/8Afr0SU8piIiISLqY2fvuXljx9hpxBCMSuR9/hOnT86r+2T3sVnHNNXDqqSGRzeTmIzvtFLr/vfNOaHby2GOhg/pf/woHHBB20LjiCnjppZBQd+0K220XPii47z4lzyIikj2UQEtu+uCDsP9ZntQ/u8NNN8Ftt4Xt3oYOhdq144tnu+3gkkvg1VfDDPMzz4SX4umnoXPn0Hb7z38OyfM++8QXp4iISGWoBlpyU1m7ujyYgV63Dq6+Gh59NCSt/fr9XCpRHWy9dVgYeNZZYVeQ8eNDE5Qdd4w7MhERkcpRAi25qbgYWrUKU6E5rLQ07Jn8j3/AtdfCX/5Svbd922IL6NQp7ihERESqphrNU4mkUXFxzpdvlJTAmWeG5Pn226t/8iwiIpIrlEBL7lm4EP73v5wu31i1KiwUfPbZUEvcu7eSZxERkUxRCYfknrL65xydgf7hh7CLxeuvh3rnyy6LOyIREZH8ogRacs+kSWEVXQ5u7/D993D88fDuuzBgAJx7btwRiYiI5B8l0JJ7ioth992hQYO4I0mr774LXfqmToUhQ+D00+OOSEREJD+pBlpyi3uYgc6x+uc1a+DEE+HDD0ODFCXPIiIi8dEMtOSWOXNgyZKcS6DLOvwNGQInnBB3NCIiIvlNM9CSW4qLw2UOLSAcNAgeeQT+8Afo1i3uaEREREQJtOSWSZOgfv1QA50Dpk2Dnj3hN7+Bvn3jjkZEREQg4gTazNLHLl4AACAASURBVDqZ2Wwzm2NmN27g/gfMbGri679mtjTKeCQPFBeH3TcKCuKOpMqWLIFTToHGjcN+z7VqxR2RiIiIQIQ10GZWAPQDOgLzgclmNtrdZ5Yd4+5/KHf8lUCHqOKRPLB6ddii4uqr446kytatg7POgnnzYPx42HbbuCMSERGRMlHOQO8HzHH3T919DTAUOGkTx3cHhkQYj+S6adPCdhU5UP98xx0wZgw89BAccEDc0YiIiEh5USbQLYB55a7PT9z2C2a2I9AGeGsj9/c0sylmNmXhwoVpD1RyRFkHwizfgePll6FPn9Ak5ZJL4o5GREREKqouiwi7AcPcvXRDd7r7E+5e6O6FzZo1y3BokjWKi2G77aBly7gjqbS5c0PpRocO8NhjYBZ3RCIiIlJRlAn0AqBVuestE7dtSDdUviFVVVwcyjeyNOtcuTIsGjSD4cOhXr24IxIREZENiTKBngzsbGZtzKw2IUkeXfEgM9sV2Bp4L8JYJNd99x188knWlm+4h+3qPvwwNEtp0ybuiERERGRjIkug3X0tcAXwKjALeM7dPzKzO8zsxHKHdgOGurtHFYvkgcmTw2WWLiB89FEoKgqLB485Ju5oREREZFMibeXt7mOAMRVuu63C9d5RxiB5YtKkUPtQWBh3JCmbOBGuuQY6d4abb447GhEREdmc6rKIUKRqioth111hq63ijiQlX30FXbuGko1nnoEa+hcpIiJS7enPtWQ/9zADnWX1z2vWhOT5++9hxIisy/1FRETyVqQlHCIZ8dlnsHBh1iXQ110H77wDQ4fCr38ddzQiIiKSLM1AS/YrLg6XWbSAcNAgeOQR+MMf4Iwz4o5GREREUqEEWrLfpElQty7ssUfckSRl2rSwZd1hh0HfvnFHIyIiIqlSAi3Zr7gY9t4batWKO5LNWrIkNEvZemt47rmsCFlEREQqUAIt2a2kBP7zn6yof163LrTpnjcPhg2DbbeNOyIRERGpDC0ilOz24YewalVW1D/feSeMGQP9+sGBB8YdjYiIiFSWZqAlu02aFC6r+Qz0mDHQpw+ccw5cemnc0YiIiEhVKIGW7FZcDM2aQevWcUeyUXPnwplnwl57Qf/+oWGiiIiIZK/NJtBm1tnMlGhL9VRcHMo3qmlWunIlnHpqCG/ECKhXL+6IREREpKqSSYzPAD4xsz+b2a5RBySStGXL4OOPq235hjtcfDFMnw6DB4d23SIiIpL9NptAu/tZQAdgLjDAzN4zs55m1jDy6EQ2ZcqUkKVW0wWE/fqFhil9+kCnTnFHIyIiIumSVGmGu38PDAOGAtsBXYD/mNmVEcYmsmllCwj33TfeODbgnXdCl8HOnaFXr7ijERERkXRKpgb6RDMbCYwDagH7ufuxwF7AtdGGJ7IJxcWw887QuHHckazn66+ha9ewrnHgQKihFQQiIiI5JZl9oE8FHnD38eVvdPeVZnZBNGGJbIZ7SKCPOiruSNZTUgKnnx7Ks199FRo1ijsiERERSbdkEujewFdlV8ysHrCtu3/m7m9GFZjIJs2fH6Z6q9kCwj/+ESZMCIsG99gj7mhEREQkCsl8uPw8sK7c9dLEbSLxKS4Ol9VoAeGQIfDQQ3D11dC9e9zRiIiISFSSSaBruvuasiuJ72tHF5JIEiZNgtq1Q3eSamDiRLjwQjj0UPjLX+KORkRERKKUTAK90MxOLLtiZicBi6ILSSQJxcXQvj3UqRNrGMuXw5VXwmGHwTbbwHPPQa1asYYkIiIiEUsmgb4EuNnMvjCzecANwMXRhiWyCWvXhj2gY65/fvFFaNcu7Pd8+eUwbRo0bx5rSCIiIpIBm11E6O5zgQPMrEHi+orIoxLZlJkzQ4/smOqfv/4arroKnn8edt89XB5wQCyhiIiISAyS2YUDMzse2B2oa2YAuPsdEcYlsnFlDVQyPAPtDn//e9hpY+VKuPNOuP76UIotIiIi+WOzCbSZ9Qe2AI4AngJOAyZFHJfIxhUXw9Zbw//9X8aG/O9/oWdPePvtUO/8xBOwyy4ZG15ERESqkWRqoA9y93OAJe7eBzgQaBttWCIbsW4dvPJK2O4i8WlIlEpK4E9/gj33DDXOTz4JY8cqeRYREclnySTQqxKXK81se6AE2C66kEQ2Yfz40ESlW7fIhyouhn32gV694MQTYdassFWdWnOLiIjkt2RSgRfNrBHwF+A/wGfA4CiDEtmooiKoXz9ktBG69VY48EBYsgRGjw7b02mHDREREYHN1ECbWQ3gTXdfCgw3s5eAuu6+LCPRiZS3ejUMGwZduoQkOiKvvAJ33QXnnAOPPAJbbhnZUCIiIpKFNjkD7e7rgH7lrq9W8iyxGTMGli6FM8+MbIgffoBLL4Vddw0LBZU8i4iISEXJlHC8aWanmmVgxZbIphQVhXZ/Rx0V2RB9+sBnn8Hjj8fe5FBERESqqWQS6IuB54HVZva9mS03s+8jjktkfcuWwUsvwRlnQM2kti9P2bRpcP/9cMEFYas6ERERkQ1JphNhw0wEIrJJw4eHGuiIyjdKS8M+z02awJ//HMkQIiIikiOSaaSywbk4dx+f/nBENqKoCHbaKbL23Y89FhocFhVB48aRDCEiIiI5IpnPwv9Y7vu6wH7A+8BvI4lIpKIvvwzdS269NZLmKQsWwM03w9FHQ/fuaT+9iIiI5JhkSjg6l79uZq2AByOLSKSioUPBPbLyjSuvDB0H//a3jDQ3FBERkSxXmZ5q84HdkjnQzDqZ2Wwzm2NmN27kmNPNbKaZfWRmatAiv1RUBIWF0Db9HeRfeAFGjoTbbw8VIiIiIiKbk0wN9COAJ67WANoTOhJu7nEFhD2kOxKS7slmNtrdZ5Y7ZmfgJuBgd19iZtuk/iNITvv4Y/jPf+CBB9J+6uXL4YorYI894Npr0356ERERyVHJ1EBPKff9WmCIu7+TxOP2A+a4+6cAZjYUOAmYWe6Yi4B+7r4EwN2/TSpqyR9FRVCjBnTrlvZT33prqH9+/nmoVSvtpxcREZEclUwCPQxY5e6lEGaWzWwLd1+5mce1AOaVuz4f2L/CMW0T53wHKAB6u/srFU9kZj2BngA77LBDEiFLTnCHwYPhyCOhefO0nnrKlNCm+9JL4YAD0npqERERyXFJdSIE6pW7Xg94I03j1wR2Bg4HugNPmlmjige5+xPuXujuhc2aNUvT0FLt/fvf8Omn0KNHWk+7di1cdBFsuy386U9pPbWIiIjkgWRmoOu6+4qyK+6+wsy2SOJxC4BW5a63TNxW3nyg2N1LgP+Z2X8JCfXkJM4vua6oCOrWhVNOSetpH34Ypk4NpRtbbZXWU4uIiEgeSGYG+gcz27vsipntA/yYxOMmAzubWRszqw10A0ZXOGYUYfYZM2tKKOn4NIlzS64rKYFnn4XOnWHLLdN22s8/D7XPJ5wAp56attOKiIhIHklmBvr3wPNm9iVgQHPgjM09yN3XmtkVwKuE+uan3f0jM7sDmOLuoxP3HW1mM4FS4I/uvriSP4vkktdfh0WL0rr3sztcfnnY67lfP+35LCIiIpWTTCOVyWa2K7BL4qbZiZKLzXL3McCYCrfdVu57B65JfIn8rKgItt4ajj02baccNgxefhnuvx+0FlVEREQqa7MlHGZ2OVDf3We4+wyggZldFn1okrdWrIBRo6BrV6hdOy2nXLoUrroK9t47dB4UERERqaxkaqAvcvelZVcSezZfFF1IkvdeeAFWrkxr+cbNN8O338ITT0DNZAqXRERERDYimQS6wOznatFEh8H0TAuKbEhREbRqBYcckpbTTZoE/fuHGeh99knLKUVERCSPJZNAvwI8a2ZHmtmRwBDgX9GGJXnr22/htdfC3s81kvn13LybboJmzeCOO9JyOhEREclzyXyYfQOhC+AlievTCTtxiKTfc89BaWnayjfefBPeegseeggaNkzLKUVERCTPbXaKz93XAcXAZ8B+wG+BWdGGJXmrqAj22CN8VZF7qH1u1QouvjgNsYmIiIiwiRloM2tLaK/dHVgEPAvg7kdkJjTJO3Pnhvbd996bltONHh3qn//+d6hTJy2nFBEREdlkCcfHwATgBHefA2Bmf8hIVJKfBg8Ol927V/lUpaVwyy3Qti2cc06VTyciIiLyk00l0KcQ2m+PNbNXgKGEToQi6eceyjcOOywtXU6GDoUZM0I3cG1bJyIiIum00Rpodx/l7t2AXYGxhJbe25jZY2Z2dKYClDzxwQcwe3ZaFg+WlMBtt0H79nDaaWmITURERKScZBYR/uDug929M9AS+ICwM4dI+hQVQa1aacl4n34aPv0U7r47bTvhiYiIiPzE3D3uGFJSWFjoU6ZMiTsMSafS0rBVxn77hRbeVfDjj/B//wdt2sCECWAqOhIREZFKMrP33b2w4u2qDpX4jRsHX30VmqdU0d/+Bl9+CUOGKHkWERGRaOgDbolfUVHoctK5c5VO8/33cM89cMwxYS2iiIiISBQ0Ay3pVbbxciqlQc8/D6eeCvXqVWnoBx6AxYtD7bOIiIhIVJRAS3pdf31ohtK4cfKPadIELrusSsMuWgR//WvIw/fZp0qnEhEREdkkJdCSPvPmwdtvwx13wK23ZnTovn3hhx/C0CIiIiJRUg20pM+QIeEyDYsBU7FgATz6KJx9NrRrl9GhRUREJA8pgZb0KSqCAw6AnXbK6LB33RV2wrv99owOKyIiInlKCbSkx4wZMH16WjoJpmLuXHjqKejZM+z9LCIiIhI1JdCSHkVFUFAAp5+e0WF79w4NDHv1yuiwIiIikseUQEvVrVsHgwdDx46wzTYZG3bGjJC3X3UVbLddxoYVERGRPKcEWqrunXfgiy8yXr5x662h/8r112d0WBEREclzSqCl6oqKYIst4OSTMzbkpEkwahT88Y+pbTktIiIiUlVKoKVq1qwJnQRPOgkaNMjYsL16QbNmcPXVGRtSREREBFAjFamqV16B777LaPnGW2/BG2+E1t0NG2ZsWBERERFAM9BSVYMHQ9OmcPTRGRvyzjuhZUu45JKMDSkiIiLyEyXQUnnLl8Po0WHrulq1MjLkf/8L48bB5ZdD3boZGVJERERkPUqgpfJGjoQff8xo+cbf/x62mz733IwNKSIiIrIeJdBSeUVFof3fgQdmZLiSEhgwADp31r7PIiIiEh8l0FI5X38dVvL16AFmGRnyxRfh22/hwgszMpyIiIjIBimBlsp59tnQgTCD5RtPPQUtWkCnThkbUkREROQXlEBL5RQVQYcOsNtuGRnuiy/Cjnnnnx9qoEVERETiogRaUvfJJzB5ckZnn//xj3B5/vkZG1JERERkg5RAS+qKikLdc7duGRmutDTsvtGxI7RunZEhRURERDYq0gTazDqZ2Wwzm2NmN27g/vPMbKGZTU18aXlYdeceEugjjggFyRnw2mswbx5cdFFGhhMRERHZpMhaeZtZAdAP6AjMByab2Wh3n1nh0Gfd/Yqo4pA0mzwZ5syBm27K2JBPPQXNmsGJJ2ZsSBEREZGNinIGej9gjrt/6u5rgKHASRGOJ5lQVAR16sCpp2ZkuG++Cc0Ozz0XatfOyJAiIiIimxRlAt0CmFfu+vzEbRWdambTzWyYmbXa0InMrKeZTTGzKQsXLowiVknG2rUwdCiccAJstVVGhvznP8OwF1yQkeFERERENivuRYQvAq3dfU/gdeCfGzrI3Z9w90J3L2zWrFlGA5Ry3nwzdDLJ0O4b7qF849BDYdddMzKkiIiIyGZFmUAvAMrPKLdM3PYTd1/s7qsTV58C9okwHqmqoiJo1AiOOy4jw40fH3bMU+dBERERqU6iTKAnAzubWRszqw10A0aXP8DMtit39URgVoTxSFWsXAkjR8Jpp4Ua6Ax48slQKXLaaRkZTkRERCQpke3C4e5rzewK4FWgAHja3T8yszuAKe4+GrjKzE4E1gLfAedFFY9U0ejRsGIF9OiRkeGWLIFhw0Lt8xZbZGRIERERkaRElkADuPsYYEyF224r9/1NQOb2Q5PKKyoK+z7/5jcZGW7QIFi9Wns/i4iISPUT9yJCyQaLF8Mrr0D37lAj+l8Z91C+sc8+0L595MOJiIiIpEQJtGze88+HveQytPvG5Mnw4YeafRYREZHqSQm0bF5REbRrB3vtlZHhnnoq1D13756R4URERERSogRaNu3zz2HixDD7bBb5cCtWwJAhcMYZsOWWkQ8nIiIikjIl0LJpgweHywztvvHssyGJ1t7PIiIiUl0pgZaNW7MGBg6Egw+G1q0zMuSTT4ZqkQMPzMhwIiIiIimLdBs7yWIrV8Ipp8DHH8Nzz2VkyA8/hOJiuP/+jFSLiIiIiFSKEmj5pWXL4IQT4N13w4q+rl0zMuxTT0Ht2nD22RkZTkRERKRSlEDL+r79Fjp1ghkzYOjQjCXPq1bBM89Aly7QtGlGhhQRERGpFCXQ8rN586BjR/jii9C6u1OnjA09YkRo3629n0VERKS6UwItwSefwFFHwdKl8NprcMghGR3+qaegTRs44oiMDisiIiKSMu3CITB9Ohx6aFg4OHZsxpPnOXPCsBdemJFO4SIiIiJVonQl3733HvzmN1CrFkyYAHvvnfEQnnoKCgrgvPMyPrSIiIhIypRA57M33ghlG02bhm6Du+6a8RDWrIEBA+D442H77TM+vIiIiEjKlEDnq1GjQta6005h5nnHHWMJ47rr4Jtv4IorYhleREREJGVKoPPRM8/AaaeFco1x46B581jCGDQIHnkE/vCHsPmHiIiISDZQAp1vHn0UzjkHDj8cXn8dGjeOJYxp06BnTzjsMOjbN5YQRERERCpF29hlq2++gZNPhvffT+1xJSVw0kmhSUrdutHEthlLloQu4VtvHbqE16oVSxgiIiIilaIEOht9/nmoeViwAK6+OrUMtHlzuOwyqBnPS79uHZx1VujZ8vbbsO22sYQhIiIiUmlKoLPN7Nkhef7++1CCcdBBcUeUkjvvhDFjoF8/OPDAuKMRERERSZ0S6GzywQdwzDFgFhb/tW8fd0QpGTMG+vQJJdiXXhp3NCIiIiKVo0WE2eKdd0Kf67p1w7ZzWZY8z50LZ54Je+0F/fuH9wAiIiIi2UgJdDZ49dVQtrHttqHhSdu2cUeUkpUr4dRTQ9I8YgTUqxd3RCIiIiKVpwS6uhs+HDp3Dknz+PGwww5xR5QSd7j4Ypg+HQYPhjZt4o5IREREpGqUQFdn//gHnH467LtvqHnOwi0r+vULDVP69IFOneKORkRERKTqlEBXVw89BOefD0ceCa+9Bo0axR1Ryt55J3QZ7NwZevWKOxoRERGR9FACXd24h+na3/8+dBt58UWoXz/uqFL29dfQtSu0bg0DB0IN/aaJiIhIjtA2dtWJO1x7LTzwAJx3Hjz5ZGwNT6qipCRUnixbFtY/ZuHkuYiIiMhGZV92li0WLIDi4tQe88ILYbr2qqtCEp2l07Z//GPYaW/wYNhjj7ijEREREUkvJdBR6d49ZJGpuu026N07KzdKXrcOHnwwlG9ffXV4CkRERERyjRLoKHz2WUier702tN1LVsOGWbvP28yZ0LNnWDh4/PHwl7/EHZGIiIhINJRAR2Hw4HB5xRVhFV0OW70a7rkH/vSnkP8PGBDeM2ThBLqIiIhIUpRAp5s7FBXBwQfnfPI8cWKYdZ41C3r0CGXb22wTd1QiIiIi0crOVWrV2bRpoZ7hzDPjjiQyy5bBpZfCoYeGNt1jxoT3DEqeRUREJB8ogU63oqKw9VzXrnFHEomRI6FdO3jiCbjmGpgxA449Nu6oRERERDIn0gTazDqZ2Wwzm2NmN27iuFPNzM2sMMp4IldaCkOGhJ7VTZvGHU1affll6Otyyilhprm4GP76V2jQIO7IRERERDIrsgTazAqAfsCxQDugu5m128BxDYGrgRQ3Ta6Gxo8P+z/nUPnGunXQvz/sthv861/Qty9MmgSF2f1WR0RERKTSolxEuB8wx90/BTCzocBJwMwKx90J9AX+GGEsmVFUFKZkTzwx7kjWU1oatpcbMSLMHK9bl/xjlyyBTz6BI4+Exx+HnXaKLk4RERGRbBBlAt0CmFfu+nxg//IHmNneQCt3f9nMsjuBXr0ahg2DLl1giy3ijobVq+HNN0PN8gsvwMKFUKcOHHAA1KuX/HmaNoVbboGzz9bWdCIiIiIQ4zZ2ZlYDuB84L4ljewI9AXbYYYdoA6usMWPC9hQxlm8sXx7KLEaOhJdfDtcbNoQTTgh5fadO4bqIiIiIVF6UCfQCoFW56y0Tt5VpCPwaGGdharM5MNrMTnT3KeVP5O5PAE8AFBYWeoQxV17ZPm5HHpnRYRctghdfDOUZr78eZp6bNYMzzggL/n772zDzLCIiIiLpEWUCPRnY2czaEBLnbkCPsjvdfRnw01YVZjYOuK5i8pwVli2Dl16Ciy8OW9hlQGkpnH8+DBoUapp32CHszdylS+jhUlCQkTBERERE8k5k2Z67rzWzK4BXgQLgaXf/yMzuAKa4++ioxs644cPD1G+PHps/Nk369IGBA0O38N/9Djp0UI2yiIiISCaYe/WsiNiYwsJCnzKlmk1SH3kkfP552K4iA1nsiy+GjT7OPx+eekqJs4iIiEgUzOx9d//F5r3qRFhVCxbA2LFh8WAGMtlPPoGzzoJ99oF+/ZQ8i4iIiGSaEuiqGjoU3DOy+8YPP4SFgbVqhaqRunUjH1JEREREKohtG7ucUVQU2vK1bRvpMO5w4YUwcya88grsuGOkw4mIiIjIRmgGuipmzYIPPsjI7PNDD4XJ7rvugo4dIx9ORERERDZCCXRVFBVBjRrQrVukw4wfD9ddByefDDfeGOlQIiIiIrIZSqAryx0GDw47cDRvHtkwX34Jp58OO+0E//ynFg2KiIiIxE0JdGW99x7873+Rlm+sWQOnnQYrVoT23FtuGdlQIiIiIpIkLSKsrKKisA1Gly6RDXHNNSFPf+45aNcusmFEREREJAWaga6MkpKQ1Z54YmTTws88E/Z5vvZa6No1kiFEREREpBKUQFfG66/DokWRlW9MnQo9e8Lhh8O990YyhIiIiIhUkhLoyigqgsaNoVOntJ/6u+9Cs5QmTeDZZ6GmimxEREREqhWlZ6lasQJGjYKzz4batdN66nXrQpvu+fPD1nXbbJPW04uIiIhIGiiBTtULL8DKlZGUb/TpA//6Fzz2GBxwQNpPLyIiIiJpoBKOVBUVwQ47wMEHp+2UP/4YGqTccQecdx5cfHHaTi0iIiIiaaYEOhXffguvvQY9eoQOhGnw5puwxx7Qty+cfz787W9qliIiIiJSnSmBTsVzz0FpaVrKNxYvht/9Do46KiTMb70Ff/871KuXhjhFREREJDJKoFNRVBSmi3/960qfwh2GDIHddoNBg+Cmm2D6dDjiiDTGKSIiIiKR0SLCZM2dC//+d5U2Zv78c7j00rBQcN994Y03YM890xijiIiIiEROM9DJGjw4XHbvnvJDS0vhwQdh993D9nQPPhhadCt5FhEREck+moFOhnso3zjssLADRwqmTYOLLoLJk+G448IiwR13jChOEREREYmcZqCTMWsWzJ6d0uLBH38M9c2FhaF0Y8gQeOklJc8iIiIi2U4z0Mlo1y4k0M2bJ3X4okWhy/f774et6f7yl9D5W0RERESynxLoZLVtm9RhX38dtqabOxdGj4bOnSOOS0REREQySgl0Gn3xBRx5JHz1Vdhp4/DD445IRERERNJNCXSazJkTkudly8L2dAccEHdEIiIiIhIFJdBp8NFHoWxj7VoYOxY6dIg7IhERERGJinbhqKL//Ad+85vQjvvtt5U8i4iIiOQ6JdBV8N578NvfQoMGMGFC2KxDRERERHKbEuhKGjsWOnaEbbYJ3QV32inuiEREREQkE5RAV8KYMaGrYJs2IXlOsTmhiIiIiGQxJdApGj4cTj4Zdt8dxo1LureKiIiIiOQIJdApeOYZOP102HdfePNNaNIk7ohEREREJNOUQCfp8cfh3HPhiCPgtddgq63ijkhERERE4qAEOgnTpsEll4S655degvr1445IREREROKiRipJ2GsvGDUKjj0WateOOxoRERERiZMS6CSddFLcEYiIiIhIdRBpCYeZdTKz2WY2x8xu3MD9l5jZh2Y21cwmmplakYiIiIhItRZZAm1mBUA/4FigHdB9AwnyYHffw93bA38G7o8qHhERERGRdIhyBno/YI67f+rua4ChwHqFEO7+fbmr9QGPMB4RERERkSqLsga6BTCv3PX5wP4VDzKzy4FrgNrAbzd0IjPrCfQE2EFt/0REREQkRrFvY+fu/dx9J+AG4JaNHPOEuxe6e2GzZs0yG6CIiIiISDlRJtALgFblrrdM3LYxQ4GTI4xHRERERKTKokygJwM7m1kbM6sNdANGlz/AzHYud/V44JMI4xERERERqbLIaqDdfa2ZXQG8ChQAT7v7R2Z2BzDF3UcDV5jZUUAJsAQ4N6p4RERERETSIdJGKu4+BhhT4bbbyn1/dZTji4iIiIikW+yLCEVEREREsokSaBERERGRFJh7dvUuMbOFwOcxDd8UWBTT2JJ5er3zi17v/KLXO//oNc8v6Xq9d3T3X+yhnHUJdJzMbIq7F8Ydh2SGXu/8otc7v+j1zj96zfNL1K+3SjhERERERFKgBFpEREREJAVKoFPzRNwBSEbp9c4ver3zi17v/KPXPL9E+nqrBlpEREREJAWagRYRERERSYESaBERERGRFCiBToKZdbL/Z+/O46ye2z+Ov66mVUVUolJJaZFMNdKuBWkjEiJLtjv7niX3T9zWGyG37IkQJZGytCiV0EL7XnJXooUWS/vn98d1RnMnNVPnzHfmzPv5eMxj5nzPOd/vNWfGuM6n63NdZgvMbLGZ3Rl1PBJ/ZtbPzFab2ewMxw4zs1Fmtij2+dAoY5T4diMrrAAAIABJREFUMbOjzGysmc01szlmdmPsuH7mScjMCpvZZDObEft53xc7frSZfR372/6OmRWMOlaJHzNLMbNvzWx47LZ+3knKzJaZ2Swzm25mU2PHEvr3XAn0PphZCvAs0AaoCXQxs5rRRiUJ0B84fbdjdwJjQghVgTGx25IctgO3hhBqAg2Aa2P/Xetnnpy2AC1DCCcAqcDpZtYAeBR4MoRQBfgFuDzCGCX+bgTmZbitn3dyaxFCSM3Q+zmhf8+VQO9bfWBxCGFpCGEr8DZwZsQxSZyFEMYDP+92+EzgtdjXrwEdszUoSZgQwqoQwjexrzfh/5Mth37mSSm4X2M3C8Q+AtASeDd2XD/vJGJm5YF2wMux24Z+3nlNQv+eK4Het3LA8gy3V8SOSfIrE0JYFfv6R6BMlMFIYphZJaAO8DX6mSet2D/nTwdWA6OAJcD6EML22EP0tz25PAX0AHbGbpdEP+9kFoCRZjbNzK6KHUvo3/P88TyZSLIKIQQzU8/HJGNmxYAhwE0hhI2+SOX0M08uIYQdQKqZlQCGAtUjDkkSxMzaA6tDCNPMrHnU8Ui2aBJCWGlmhwOjzGx+xjsT8fdcK9D7thI4KsPt8rFjkvx+MrMjAWKfV0ccj8SRmRXAk+c3QwjvxQ7rZ57kQgjrgbFAQ6CEmaUvJOlve/JoDJxhZsvwssuWwNPo5520QggrY59X42+Q65Pgv+dKoPdtClA1tnu3IHA+MCzimCR7DAMuiX19CfBBhLFIHMXqIV8B5oUQeme4Sz/zJGRmpWMrz5hZEeBUvO59LHBO7GH6eSeJEMJdIYTyIYRK+P+zPwshXIh+3knJzIqaWfH0r4HTgNkk+O+5JhFmgpm1xeupUoB+IYQHIw5J4szMBgLNgVLAT8C9wPvAIKAC8D1wbghh942GkguZWRNgAjCLXTWSd+N10PqZJxkzq41vIkrBF44GhRDuN7PK+ArlYcC3QNcQwpboIpV4i5Vw3BZCaK+fd3KK/VyHxm7mB94KITxoZiVJ4N9zJdAiIiIiIlmgEg4RERERkSxQAi0iIiIikgVKoEVEREREskAJtIiIiIhIFiiBFhERERHJAiXQIiK5iJntMLPpGT7ujOO5K5nZ7HidT0QkWWmUt4hI7vJHCCE16iBERPIyrUCLiCQBM1tmZv82s1lmNtnMqsSOVzKzz8xsppmNMbMKseNlzGyomc2IfTSKnSrFzF4yszlmNjI2uU9ERDJQAi0ikrsU2a2E47wM920IIRwP/AefngrwDPBaCKE28CbQJ3a8D/B5COEEoC4wJ3a8KvBsCOE4YD3QKcHfj4hIrqNJhCIiuYiZ/RpCKLaH48uAliGEpWZWAPgxhFDSzNYCR4YQtsWOrwohlDKzNUD5jKOMzawSMCqEUDV2+w6gQAjhgcR/ZyIiuYdWoEVEkkf4m6+zYkuGr3egvTIiIn+hBFpEJHmcl+Hzl7GvJwHnx76+EJgQ+3oMcDWAmaWY2SHZFaSISG6nlQURkdyliJlNz3D7kxBCeiu7Q81sJr6K3CV27HrgVTO7HVgDdIsdvxF40cwux1earwZWJTx6EZEkoBpoEZEkEKuBTgshrI06FhGRZKcSDhERERGRLNAKtIiIiIhIFmgFWkREREQkC5RAi4iIiIhkgRJoEREREZEsUAItIiIiIpIFSqBFRERERLJACbSIiIiISBYogRYRERERyQIl0CIiIiIiWaAEWkREREQkC5RAi4iIiIhkgRJoEREREZEsUAItIpliZr+aWeU4nKeXmb0Rj5gScU0zG2dmVyQ4ngvNbGS8HxslMytjZuPNbJOZPRF1PNnFzB42s5siuO5kMzsuu68rIk4JtIj8DzNbZmZ/xBLm9I+yIYRiIYSlCb52czMLZjZ0t+MnxI6PS+T198bMns/wemw1s20Zbn+clXOFEN4MIZwW78dm1W4/65/MrL+ZFdvP010FrAUODiHcGscwcywzKw1cDLwQu93czFZk0+UfB+7PpmuJyG6UQIvInnSIJczpHz9k47XXAA3NrGSGY5cAC7Mxhr8IIXRPfz2Ah4B3Mrw+bdIfZ2b5o4tyv3SIfU91gTTgnqw82Vw+oCIwN4QQshpALnzN0l0KfBRC+COCaw8DWpjZERFcWyTPUwItIpkSWwGuEvu6v5k9a2YjYv9k/7WZHZPhsU+b2XIz22hm08ysaRYutRV4Hzg/dq4U4Dzgzd3iaWRmU8xsQ+xzowz3HW1mn8diGwWU2u25DcxskpmtN7MZZtY8iy/H/4it5N5hZjOB38wsv5ndaWZLYjHMNbOzMjz+UjObmOF2MLPuZrYoFtOzZmb78dgUM3vCzNaa2Xdmdl3s8ftMUEMIK4GPgVr7eo1iZS4PmtkXwO/A6/ibnB6x1exTzKyQmT1lZj/EPp4ys0Kx5zc3sxWx1+xH4FXzMpvBZvZG7DWbZWbHmtldZrY69vt0WoYYupnZvNhjl5rZPzLcl37+W2PPXWVm3TLcXyT2On0f+/2ZaGZF9vV970Eb4PN9vbax89aIvW7rzWyOmZ2R4b62sd+RTWa20sxuix0vZWbDY8/52cwmmL9ZIYSwGZgGtM7M9UUkvpRAi8j+Oh+4DzgUWAw8mOG+KUAqcBjwFjDYzApn4dyv4/80Dp4gzAb+XAU3s8OAEUAfoCTQGxhhu1at38KTi1LAv/DkLv255WLPfSAW323AEPN/jj8QXYB2QIkQwnZgCdAUOAR/nd4wsyP38vz2wIlAbeBc9p4Y/d1jr8STulR8RbljZoM3s6OAtsC3mXyNLsLLNooD3fA3OP+OrciPBnoCDWKxnADU539Xt4+Inbti7DwAHYAB+O/Ut8Cn+P+nyuHlCi9keP7q2OtwcOz6T5pZ3d3Of0jsuZcDz5rZobH7HgfqAY1iMfQAdu7H78bxwIK/ue9PZlYA+BAYCRwOXA+8aWbVYg95BfhHCKE4/gbms9jxW4EVQGmgDHA3kHGFfx7+2opINlMCLSJ78n5s1Wu9mb3/N48ZGkKYHEsW38QTJQBCCG+EENaFELaHEJ4ACgHV/uY8fxFCmAQcFkswLsYT6ozaAYtCCANi1xgIzAc6mFkFPLn8ZwhhSwhhPJ68pOuK/7P7RyGEnSGEUcBUPHk8EH1CCMvT/zk/hDA4hPBD7BrvAIvwJPLvPBJCWB9C+C8wlgyvZxYeey7wdAhhRQjhF+CRTMT9vpmtBybiq6kPkbnXqH8IYU7s9d+2h/NeCNwfQlgdQliDv4m4KMP9O4F7Yz+j9BKICSGET2O/U4PxxPGR2PnfBiqZWQmAEMKIEMKS4D7Hk9OM/9KxLXb9bSGEj4BfgWqxFdzLgBtDCCtDCDtCCJNCCFsy+X1nVALYtPeXF/A3EsVi38vWEMJnwHD8TVd6rDXN7OAQwi8hhG8yHD8SqBj7PibsViKzKRaDiGQzJdAisicdQwglYh9/t4r5Y4avf8cTBADM7LbYP69viCVnh7BbGUUmDACuA1oAQ3e7ryzw/W7HvsdXG8sCv4QQftvtvnQVgc4Z3iCsB5rgicqBWJ7xhpldbGbTM1yjFnt/Df729czCY8vuFsf/xPQ30n/WFUMI18SS2cy8Rvs69+4/o+9jx9KtiZUhZPRThq//ANaGEHZkuA2x79XM2pjZV7HShvV4kpvx9V0XS8TTpb9OpYDC+L8Q7C6rvxu/4Cvw+1IWWB5C2JnhWPrvK0CnWPzfm5ceNYwdfwz/152RsTKVO3c7b3FgfSauLyJxpgRaROLKvN65B74aemgIoQSwAbAsnmoAcA2+Ivj7bvf9gCc7GVUAVgKrgEPNrOhu96VbDgzI8AahRAihaAghM6u1e/PnyqCZVQRewt8AlIy9BrPJ+muQVauA8hluH7Wf58nMa7SvzYK7/4wqkKEMJxPP/1uxWuoheClGmdjr+xGZe33XApuBY/ZwX1Z/N2YCx2bimj8AR6XXL8ek/74SQpgSQjgTL+94HxgUO74phHBrCKEycAZwi5m1ynCOGsCMTFxfROJMCbSIxFtxYDveTSO/mf0fXqeaJSGE74CT8Vra3X0EHGtmF5hv2DsPqAkMDyF8j/+z+31mVtDMmuC1tenewEs9Wptvuisc23RW/q+X2W9F8QRxDfiGN2Kb8xJsEHCjmZWLlTrcsZ/nicdrNBC4x8xKm1kp4P9i542HgnhZ0Bpgu5m1ATLbFnAn0A/obWZlY99fw1hSntXv+yP8d/R/xJ735wcwGV8B72FmBWIbEzsAb8d+Ry80s0NipSob8fIWzKy9mVUxM8PfhO7IcF9hvI57VGa+bxGJLyXQIhJvnwKf4G3nvsdX+zJTSvAXIYSJe2qhF0JYh28guxVYh694tw8hrI095ALgJOBn4F4y1FCHEJYDZ+IbstbEYrudOP49DCHMBZ4AvsTLEo4HvojX+ffiJbwWeCa+Ce8j/M3Mjr09aXdxeo0ewN/IzARmAd/Ejh2wEMIm4Ab8DcMv+M97WBZOcVsspin478ijQL79+L5fB9qmd/CIKYeXm2T8OApPmNvgK+B9gYtDCPNjz7kIWGZmG4HueP04QFVgNF6//SXQN4QwNnZfB2Dcnv77EJHEs/1o2SkiIrlAbGX2+RDC7uUuEidm9hCwOoTwVDZf92vg8hDC7Oy8rog4JdAiIkkithLaAl+FLoPXCX8VQsj2UdMiIslMCbSISJIws4PwVnTV8dKBEXi7to2RBiYikmSUQIuIiIiIZIE2EYqIiIiIZEH+qAPIqlKlSoVKlSpFHYaIiIiIJLlp06atDSGU3v14rkugK1WqxNSpU6MOQ0RERESSnJntPvUWUAmHiIiIiEiWKIEWEREREckCJdAiIiIiIlmQ62qgRURERCTxtm3bxooVK9i8eXPUoSRc4cKFKV++PAUKFMjU45VAi4iIiMhfrFixguLFi1OpUiXMLOpwEiaEwLp161ixYgVHH310pp6jEg4RERER+YvNmzdTsmTJpE6eAcyMkiVLZmmlXQm0iIiIiOxRsifP6bL6fSqBFhERERHJAiXQIiIiIpLjrFu3jtTUVFJTUzniiCMoV67cn7e3bt261+dOnTqVG264IWGxaROhiIiIiOQ4JUuWZPr06QD06tWLYsWKcdttt/15//bt28mff8+pbFpaGmlpaQmLTSvQmbR6ddQRiIiIiORtl156Kd27d+ekk06iR48eTJ48mYYNG1KnTh0aNWrEggULABg3bhzt27cHPPm+7LLLaN68OZUrV6ZPnz4HHIdWoDNhwQKoXx9uvRX++U/II/X0IiIiIgDcdBPEFoPjJjUVnnoq689bsWIFkyZNIiUlhY0bNzJhwgTy58/P6NGjufvuuxkyZMhfnjN//nzGjh3Lpk2bqFatGldffXWmez7viRLoTKhYETp2hHvvhTlz4NVX4aCDoo5KREREJO/p3LkzKSkpAGzYsIFLLrmERYsWYWZs27Ztj89p164dhQoVolChQhx++OH89NNPlC9ffr9jUAKdCYULQ//+cNxxcOedsGQJfPABlCsXdWQiIiIiibc/K8WJUrRo0T+//uc//0mLFi0YOnQoy5Yto3nz5nt8TqFChf78OiUlhe3btx9QDKqBziQz6NHDE+cFC+DEE2HKlKijEhEREcm7NmzYQLnYimb//v2z7boJS6DNrJ+ZrTaz2X9z/4VmNtPMZpnZJDM7IVGxxFOHDjBpEhQqBM2awcCBUUckIiIikjf16NGDu+66izp16hzwqnJWWAghMSc2awb8CrweQqi1h/sbAfNCCL+YWRugVwjhpH2dNy0tLUydOjX+AWfRmjXQqRNMmAD33AP33Qf5tJ4vIiIiSWLevHnUqFEj6jCyzZ6+XzObFkL4Sz+8hKV8IYTxwM97uX9SCOGX2M2vgP2v5I5A6dIwejRcdhk88AB07gy//RZ1VCIiIiKSaDllzfRy4OOog8iqggXh5Zehd294/31o3Bj++9+ooxIRERGRRIo8gTazFngCfcdeHnOVmU01s6lr1qzJvuAywQxuvhmGD4fvvvN+0V9+GXVUIiIiIpIokSbQZlYbeBk4M4Sw7u8eF0J4MYSQFkJIK126dPYFmAVt2njiXKwYNG8OAwZEHZGIiIiIJEJkCbSZVQDeAy4KISyMKo54qlkTvv4aGjWCiy/2ntE7d0YdlYiIiIjEU8IGqZjZQKA5UMrMVgD3AgUAQgjPA/8HlAT6ms/G3r6nXY65TcmSMHIkXH89PPooLFzoq9EZen6LiIiISC6WsAQ6hNBlH/dfAVyRqOtHqUABeO45qFYNbr0VTj4Zhg2DsmWjjkxEREQkd1i3bh2tWrUC4McffyQlJYX0Ut7JkydTsGDBvT5/3LhxFCxYkEaNGsU9tsg3EeYKW7fCtdfC999n+inpmws/+ADmz/fNhd9+m8AYRURERJJIyZIlmT59OtOnT6d79+7cfPPNf97eV/IMnkBPmjQpIbEpgc6MxYvhzTehSROvyciCDh1g4kRPqJs29ZVoEREREcm6adOmcfLJJ1OvXj1at27NqlWrAOjTpw81a9akdu3anH/++Sxbtoznn3+eJ598ktTUVCZMmBDXOBJWwpFUataEcePgtNM8Cx41CmrXzvTTU1Nh8mQ44wzo2BEeewxuucWTahEREZEc76abYPr0+J4zNRWeeirTDw8hcP311/PBBx9QunRp3nnnHXr27Em/fv145JFH+O677yhUqBDr16+nRIkSdO/enWLFinHbbbfFN260Ap15qakwfrwXOJ98srfbyIIjj4TPP4ezz4bbboPu3WHbtgTFKiIiIpJktmzZwuzZszn11FNJTU3lgQceYMWKFQDUrl2bCy+8kDfeeIP8+RO/PqwV6KyoXt3rMVq1glNOgQ8/9KbPmXTQQTBoENxzDzz8MCxZAu++CyVKJC5kERERkQOWhZXiRAkhcNxxx/HlHibWjRgxgvHjx/Phhx/y4IMPMmvWrITGohXorKpUCSZMgAoVfHrKiBFZenq+fPDQQ/Dqq76g3bChJ9IiIiIi8vcKFSrEmjVr/kygt23bxpw5c9i5cyfLly+nRYsWPProo2zYsIFff/2V4sWLs2nTpoTEogR6f5Qt6/UYNWt6UfPgwVk+xaWXein16tVw0km+sC0iIiIie5YvXz7effdd7rjjDk444QRSU1OZNGkSO3bsoGvXrhx//PHUqVOHG264gRIlStChQweGDh2akE2EFkKI6wkTLS0tLUydOjXqMNyGDdC+PUyaBC+/DN26ZfkUixb5KZYtg1dega5d4x+miIiISFbNmzePGjVqRB1GttnT92tm0/Y06E8r0AfikEPgk0+8Hvqyy6BPnyyfompV+PJLaNwYLroIevSA7dsTEKuIiIiIxIUS6ANVtKg3dz7rLLjxRnjwQcjiqv5hh3kefvXV3uKuTRtYty5B8YqIiIjIAVECHQ+FCnl7jYsu8hYbd92V5SS6YEHo2xf69fM9imlpmlwoIiIi0cptpb77K6vfpxLoeMmfH/r39wbPjz4K110HO3dm+TTdunkCvX07NGoEb7wR/1BFRERE9qVw4cKsW7cu6ZPoEALr1q2jcOHCmX6O+kDHU758vox88MHw73/7JsNXXvEV6iw48USYNg3OPdcXtadO9dKOAgUSFLeIiIjIbsqXL8+KFStYs2ZN1KEkXOHChSlfvnymH68EOt7M4JFHfDrK3XfDihXw3nte6JwFhx/ube5uvx2eftqnZw4a5MdFREREEq1AgQIcffTRUYeRI6mEIxHMvA76zTe9xcZ+TkspUMAH/wwY4JPD69WDKVMSEK+IiIiIZJoS6ES64AIYM8ZbajRoAF98sV+n6drVW02npEDTpr7RUERERESioQQ60Zo08VXoQw+FVq3g7bf36zR16ngtdNOmcPnlcM01sHVrnGMVERERkX1SAp0d0qel1K8PXbrsV69ogFKl4OOPfdjKc89BixawalUC4hURERGRv6UEOruULOm7Art29V7Rl122X0vI+fN7l7x33vGNhSecAB99lIB4RURERGSPlEBnp0KF4PXXoVcv7xl9+unwyy/7dapzz/UNhUceCe3a+RDEzZvjGq2IiIiI7IES6OxmBvfe6601Jk70aSlLl+7XqWrW9O4cN94Iffp4hcjcuXGOV0RERET+hxLoqHTtCqNHw+rV3qHjq6/26zSFC3uruxEj4McfvdXd88/vV4m1iIiIiGSCEugoNWvmmwsPOcR3BA4evN+natsWZs6Ek0+Gq6+Gs86CtWvjGKuIiIiIAEqgo3fssZ5E16vnhc29esHOnft1qiOO8A2FvXv75xNOgM8+i2+4IiIiInmdEuicoFQpL+e45BK47z5fPt64cb9OlS8f3Hyz10YXLw6nnAJ33gnbtsU5ZhEREZE8Sgl0TlG4MLz6qu8GHDHC66IXLtzv09WpA9OmwZVXetu7xo1h8eI4xisiIiKSRymBzknM4PrrfTV6zRpvqzFixH6frmhReOEFePddT57r1IHXXtMGQxEREZEDoQQ6J2re3Od2V64MHTrAQw8dUNbbqRPMmOFl1pde6g1A9rNCRERERCTPUwKdU1Ws6H2iu3SBnj2hc2f49df9Pt1RR8GYMfDAAz7FsE4dmDw5jvGKiIiI5BFKoHOygw6CN96Axx+HoUOhYUNYsmS/T5eS4rn4+PGwY4fXRf/73/vd9ENEREQkT1ICndOZwa23wiefwA8/wIknwsiRB3TKRo1g+nTo2BHuuANat4ZVq+IUr4iIiEiSUwKdW5x6KkyZAuXLQ5s28NhjB1QXXaIEDBoEL74IX3zhPaM//jiO8YqIiIgkKSXQuUnlyj50pVMn6NEDLrgAfv99v09n5m3upk71ISxt28Itt8CWLXGMWURERCTJKIHObYoW9V2ADz/snxs1gu++O6BT1qzpGwqvuw6efNJPeQAtqEVERESSmhLo3MjMxwuOGAHffw9paTBq1AGdsnBheOYZeP99WLYM6tZVz2gRERGRPVECnZu1aeN10WXLwumne0uNA8x4zzzTe0anpalntIiIiMieKIHO7apU2VUXfccdcP758NtvB3TK8uW9Z/S//uVVIrVrw9ixcYpXREREJJdTAp0MihXzTPfRR31u9wH2iwbvGX3PPT7LpWBBaNkSbroJ/vgjTjGLiIiI5FJKoJOFmXfm+PhjWLHCazA++eSAT9ugAXz7rW8wfPppTTAUERERUQKdbE47zfvSVajgfekeeuiA66KLFvUNhqNHe9e8Ro3gn/+ErVvjFLOIiIhILqIEOhlVrgyTJnk9dM+ecM45sGnTAZ+2VSuYNcs3Fj7wAJx0EsyeHYd4RURERHIRJdDJqmhRePNNeOIJ703XoAEsWnTApz3kEOjf30/5ww9Qr543/9ix48BDFhEREckNlEAnMzMfLThqFPz0E5x4IgwfHpdTn3mmrz63b+/NP5o1g8WL43JqERERkRxNCXRe0LIlTJvmpR0dOngBcxyWjEuX9qYfAwbAnDlwwgnQt6+Gr4iIiEhyUwKdV1SsCF98AZdf7gXMp53mq9IHyMxromfPhiZN4Npr/dQH2EVPREREJMdSAp2XFCkCL78M/fr5JsM6dWD8+Licunx575rXty98/TXUquUNQNSpQ0RERJKNEui8qFs3z3KLFfPyjjiMAAdfjb76apg3z2uje/b0HH3ChDjELCIiIpJDKIHOq2rX9n7RZ5/tuwA7doRffonLqcuVg8GDfb/ib7/5BsMrroB16+JyehEREZFIKYHOyw4+2EeAP/20TzCsW9c3G8ZJu3a+ubBHD299V706vP66NhmKiIhI7qYEOq8zgxtu8FroHTt8zOBzz8Utyy1aFB59FL75BqpUgUsugVNOgYUL43J6ERERkWynBFpcgwbw7bdeE33NNd5a49df43b62rW9Ccjzz3syffzx0KsXbN4ct0uIiIiIZAsl0LJLyZIwYoS3uXv7bahfH+bOjdvp8+WDf/wD5s/36eL33ee9o8eOjdslRERERBJOCbT8r3z5vH3GqFG+6+/EE71wOY7KlPEp459+6lUjLVvClVfCxo1xvYyIiIhIQiQsgTazfma22sxm/839ZmZ9zGyxmc00s7qJikX2Q8uWXtJx4oleuNy1a9wz3NNOg1mzvAlIv35e1jF6dFwvISIiIhJ3iVyB7g+cvpf72wBVYx9XAc8lMBbZH2XLwpgx8K9/eUlHnTrePzqOihSBRx7xuS5FisCpp3oJdhzLr0VERETiKmEJdAhhPPDzXh5yJvB6cF8BJczsyETFI/spJQXuuWdXl44mTeDhh/3rODrpJF/wvvVW32hYuzaMGxfXS4iIiIjERZQ10OWA5Rlur4gd+wszu8rMpprZ1DVr1mRLcLKbRo1g+nTo1AnuvtuXileujOslihSBxx/3yYUpKdCihXfY++23uF5GRERE5IDkik2EIYQXQwhpIYS00qVLRx1O3lWiBAwcCK+84qUcJ5wAw4bF/TKNG8OMGZ48P/MMpKbCxIlxv4yIiIjIfokygV4JHJXhdvnYMcnJzOCyy7yZc4UKcOaZcN118Mcfcb3MQQf5gMRx47xapFkzL++I82VEREREsizKBHoYcHGsG0cDYEMIYVWE8UhWVKsGX34Jt9wCzz7rPaPnzIn7ZU4+GWbOhKuvht69fR/jV1/F/TIiIiIimZbINnYDgS+Bama2wswuN7PuZtY99pCPgKXAYuAl4JpExSIJUqgQPPEEfPwxrF4NaWlxHQOerlgxz9FHjfIV6MaNfTVafaNFREQkChbinOwkWlpaWpg6dWrUYcjufvrJ+0V/+il07AgvvQSlSsX9Mhs3wu23++kPP9xb4F18sc9/EREREYknM5sWQkjb/bjSDomPMmXgo498RXrECN9gOGZM3C9z8MHwwgu+h/Hoo6FbN2jYECZPjvulRERERPZICbTET758XhP99dee6Z56KvToAVu3xv1SJ54IX3xHVUUcAAAgAElEQVThU8aXL/c+0t26wY8/xv1SIiIiIv9DCbTEX506MG0aXHUVPPaYLxEvWBD3y+TLBxdd5Ke+4w546y049li/ZAJydhERERFACbQkykEH+UjB99+H77+HunW9cDkBNffFi3st9OzZ3rWjRw+oVcsrSkRERETiTQm0JNaZZ3ofukaNfEW6UydYty4hl6paFT780JuC5MsH7dr5x8KFCbmciIiI5FFKoCXxypb17hyPPw7Dh0Pt2gnZYJju9NM9Z08fC16rlnfuUNs7ERERiQcl0JI98uXz5s3ZsMEQoGBBv9yiRV4n/fjjvkL98ss+2VBERERkfymBluy1+wbDRo0SssEwXZky8MorMGWKJ9BXXunzXj7/PGGXFBERkSSnBFqyX/oGw6FDYdky32D4zDOwc2fCLpmW5uUcb78NP/8MzZvDOefAd98l7JIiIiKSpJRAS3Q6dvRi5WbN4IYb/HMCV6PN4LzzYP58+Ne/fLNh9epw112waVPCLisiIiJJRgm0RKtsWe8399prMHeuTzB8+GHYti1hlyxSBO65x7tznH++t8CrWhX69UvoIriIiIgkCSXQEj0zuPhimDcPOnSAu+/20YLffpvQy5Yr53n7119D5cpw+eU+4XDChIReVkRERHI5JdCSc5QpA4MHw5AhsGqVZ7N33w2bNyf0svXr+1jwt96C1au9kuS883z+i4iIiMjulEBLznP22V7OcfHFXs6RmuoZbgKZQZcuXoJ9330+kKV6dfi//4PffkvopUVERCSXUQItOdOhh3pR8qef+gp006a+0fDXXxN62YMO8qR5wQI46yzfbFi9unfvSMAUchEREcmFlEBLznbaaTB7Nlx3HfznPz5WcOTIhF/2qKO8pGPCBDj8cF+dbtYMvvkm4ZcWERGRHE4JtOR8xYpBnz4wfjwULgytW0O3bvDLLwm/dJMmMHkyvPSSr0qnpfkwltWrE35pERERyaGUQEvu0aQJTJ/ujZsHDICaNX0YS4KlpMAVV3jbu5tvhv794dhj4cknEzaJXERERHIwJdCSuxQuDA895MvCRxzhGw7PPRd++inhly5RAp54AmbNgoYN4ZZboHZt+OSThF9aREREchAl0JI71a3rSfQDD8AHH/hq9BtvZMtOv+rVffbL8OE+eKVNG2jfHhYtSvilRUREJAdQAi25V4EC0LOnD1w59li46CLPZJcvT/ilzaBdO9/f+NhjXp593HHeKET10SIiIslNCbTkfjVrwsSJ8NRTMG6cZ7IvvJAtc7kLFoTbbvP66Msug7594Zhj4P77E95xT0RERCKiBFqSQ0oK3HijFyifeCJ07w6tWsGSJdly+SOOgOefhzlzvPPevfdClSrw3HOwbVu2hCAiIiLZRAm0JJfKlWH0aO879803cPzx0Ls37NiRLZevVs0nkU+aBFWrwjXX+IL4u+9qEIuIiEiyUAItycfM+87NnQunnAK33gqNG3vBcjZp2NDroocN81Ltzp2hQQP4/PNsC0FEREQSRAm0JK9y5bxDx1tveSlH3bpw333Z1rzZDDp0gJkz4ZVXYOVKaN7c9znOmpUtIYiIiEgCKIGW5Gbmc7jnzvVl4F69PJH++utsCyElxTcYLloEjz7q+x1POMGHKf73v9kWhoiIiMSJEmjJG0qXhjff9ObNGzZ4jcXNN8Nvv2VbCEWKQI8esHSpV5UMHOjd926/HX7+OdvCEBERkQOkBFrylnbtvFXG1Vd727tatWDUqGwN4bDDvHf0woVw/vk+3fCYY3x1+o8/sjUUERER2Q9KoCXvOfhgePZZmDABChXyvnPdumX7MnCFCtC/P8yY4Xsc77zTO3f06wfbt2drKCIiIpIFSqAl72rSBKZPh7vvhgEDfCBLBP3mjj/eK0vGjYPy5eHyy71Getgwtb4TERHJiZRAS95WuDA8+CBMnepdOzp3hrPPhh9+yPZQTj4ZvvzSc/jt2+HMM6FpU/jii2wPRURERPZCCbQIQGqqd+b497/hk098NfrFF7NlHHhGZtCpk7esfuEF777XpAl07OiNRERERCR6SqBF0uXP7y0xZs6EOnXgH//w4uTp07M9lAIF4KqrYPFieOAB+OwzL/W44gpYvjzbwxEREZEMlECL7K5qVc9YX3/dl4Dr1fOWd5s2ZXsoRYtCz57e+u6GG7xUu0oVD2fNmmwPR0RERFACLbJnZnDRRbBggS8FP/00VK8OgwdHsrOvVCl48klvfXfhhdCnD1SuDPfeCxs3Zns4IiIieZoSaJG9OfRQeO45391Xpgycey60aeO1FRGoWNHb3M2eDa1bw/33eyL9xBPqIS0iIpJdlECLZMZJJ8Hkyb4SPWmSD2C57z7YvDmScGrU8G4dU6Z4hcltt3nlyYsvwrZtkYQkIiKSZyiBFsms/Pm9EHn+fG+L0auX7+zL5kmGGaWlwaefwtixcNRRvu/xuOPg7bezvYGIiIhInqEEWiSrypb1DHXkSL992mlw3nmR9I5O17y5L4x/8IEPV+zSxVemP/pIw1hERETiTQm0yP469VSYNctXoj/4wDcZPvlkZDUUZnDGGd51b8AA2LAB2rWDBg3gww+VSIuIiMSLEmiRA1G4sLfCmD3be0bfcgvUrQvjx0cWUkoKdO3qlSYvvACrV3tiXaeO102rtENEROTAKIEWiYcqVbxeYuhQ7yt38smexa5aFVlIBQt6B76FC6F/f+/S0bmz7398800fFy4iIiJZpwRaJF7MfHPhvHk+/WTwYKhWDZ56KtJstUABuOQSHwU+cCDky+e5fY0a3hJPXTtERESyRgm0SLwddJDP3549Gxo18rGBdepEWtYBXtpx/vk+qfy996B4cbj8cm9/9/zzsGVLpOGJiIjkGkqgRRKlalX4+GPPVtPLOi66CH78MdKw8uWDs86CadNgxAg48ki4+mofyPL00/D775GGJyIikuMpgRZJJDPPVtPLOgYN8rKOp5+OvAjZDNq29fZ3o0d7vn/TTZ5I9+kT2YwYERGRHE8JtEh2yFjW0bChZ6oRd+tIZwatWsG4cR5OjRpw442eUL/wAmzdGnWEIiIiOYsSaJHslLGsY8MGL+s47zz473+jjgyApk19quGYMT7ZsHt3XzDv3z/yBXMREZEcQwm0SHbLWNbRqxcMG+ZDWO67z3vN5QAtW8IXX3hnvpIloVs3HxE+cKD6SIuIiCiBFonKQQf5EJb586F9e0+mq1f39nc5YGygGbRpA1OmeHvrQoXgggugdm1fQM8BIYqIiERCCbRI1CpW9M2FY8dCiRJw7rm+BDxzZtSRAbvaW0+fDm+/7aUcnTpBvXrexUOJtIiI5DWZSqDNrKiZ5Yt9fayZnWFmBRIbmkge07y595br29eT5zp14NprYd26qCMDvP3deef5PsjXXvMS7vbtfU/k8OFKpEVEJO/I7Ar0eKCwmZUDRgIXAf339SQzO93MFpjZYjO7cw/3VzCzsWb2rZnNNLO2WQleJOnkz+9NmRctgmuu8QknVavCs8/mmF18+fPDxRd75cmLL3pb6w4dIDUV3nkHduyIOkIREZHEymwCbSGE34Gzgb4hhM7AcXt9glkK8CzQBqgJdDGzmrs97B5gUAihDnA+0DcrwYskrcMOg2ee8bqJ1FS47jpve/fZZ1FH9qcCBeDKKz3Xf+01b3d3/vlexv3KK2p/JyIiySvTCbSZNQQuBEbEjqXs4zn1gcUhhKUhhK3A28CZuz0mAAfHvj4E+CGT8YjkDccf7z3l3n3Xpxm2agVnnAELFkQd2Z8KFPAV6TlzYMgQOOQQuOIKOOYYnxfz229RRygiIhJfmU2gbwLuAoaGEOaYWWVg7D6eUw5YnuH2itixjHoBXc1sBfARcP2eTmRmV5nZVDObumbNmkyGLJIkzHzX3rx58NBDPvGkVi24/npYuzbq6P6ULx+cfbZ37fj0U0+gb7oJKlWCBx+E9eujjlBERCQ+MpVAhxA+DyGcEUJ4NLaZcG0I4YY4XL8L0D+EUB5oCwxI36y42/VfDCGkhRDSSpcuHYfLiuRCRYrAXXd5zcQVV/hmwypV4PHHYcuWqKP7kxmcdprn+RMnwkknwT33QIUKHv5PP0UdoYiIyIHJbBeOt8zsYDMrCswG5prZ7ft42krgqAy3y8eOZXQ5MAgghPAlUBgolZmYRPKsMmXguee8U0ejRnD77T5/e9CgHNcKo3Fj79Dx7bfQti08+qivSF9/PSxfvs+ni4iI5EiZLeGoGULYCHQEPgaOxjtx7M0UoKqZHW1mBfFNgsN2e8x/gVYAZlYDT6BVoyGSGccd56MCR46EYsW8x1zjxvDVV1FH9hepqd5Dev58H8by/PNe4nHllbBkSdTRiYiIZE1mE+gCsb7PHYFhIYRt+AbAvxVC2A5cB3wKzMO7bcwxs/vN7IzYw24FrjSzGcBA4NIQctgSmkhOd+qpvsT78svw3XfemPn88/3rHObYY71Dx+LFcNVVMGCAH7voIpg7N+roREREMscyk6+a2Q3AHcAMoB1QAXgjhNA0seH9VVpaWpg6dWp2X1Ykd/j1V/j3v70uescOuPFG6NnTW2PkQKtWQe/eXpHy++++CbFnT58hIyIiEjUzmxZCSPvL8f1d8DWz/LFV5mylBFokE1as8J17r78OpUrB/ff7xsP8+aOObI/WrvWWd8884xMO27b18Bs2jDoyERHJy/4ugc7sJsJDzKx3eis5M3sCKBr3KEUkPsqXh/79YepU32B49dVeiDxyZNSR7VGpUvCvf8H333vLu6+/9v2RrVrB2LE5bm+kiIjkcZmtge4HbALOjX1sBF5NVFAiEid163o/uSFD4I8/oHVraNfOd/PlQIccAnff7Yl0797e+rplS0+m3303x0wzFxGRPC6zCfQxIYR7Y1MFl4YQ7gMqJzIwEYkTMy8unjvX66MnTtw1iGXduqij26OiReHmm2HpUm93vXo1dO7sba979/YyDxERkahkNoH+w8yapN8ws8bAH4kJSUQSolAh7xm9aJH3j0sfxPLkk7B1a9TR7VHhwl59snAhDB0KFSvCrbfCUUf5lMOlS6OOUERE8qLMJtDdgWfNbJmZLQP+A/wjYVGJSOIcfri3vZgxA+rXh1tu8RXpYcNybLFxSgp07Aiff+5l3WecAc8+C1Wr+pTziRNzbOgiIpKEMjvKe0YI4QSgNlA7hFAHaJnQyEQksWrVgk8+gREjIF8+OPNMOOUUmD496sj2ql49eOMNWLYM7rjDNxk2bervBd56C7ZtizpCERFJdpldgQYghLAxNpEQ4JYExCMi2cnMe8bNmgV9+njyXKcOXHhhjh8RWK4cPPSQjwTv2xc2bvSwjz4aHnkEfv456ghFRCRZZSmB3o3FLQoRiVaBAr6pcPFiuOsuLziuXh2uvdanneRgRYt6nfS8eTB8uId9111eJ33NNbBgQdQRiohIsjmQBFoVhyLJ5tBDfVl3yRLfaPjii77RsGdPWL8+6uj2Kl8+79A3erSXd593no8Nr17dj48apTppERGJj70m0Ga2ycw27uFjE1A2m2IUkex25JFeFzFvntdGP/QQVK4Mjz3m/aRzuNq1oV8/+O9/4b77YNo0OO00OP54ePnlXPEtiIhIDrbXBDqEUDyEcPAePoqHEHLmTGARiZ8qVXxn3rffQoMG0KOHH3vppVwx1aRMGfi///PBLP37+yTzK6+EChXgn//M8dUpIiKSQx1ICYeI5BWpqfDRRz7VsGJFuOoqOO44GDwYdu6MOrp9KlQILrnE3weMHQuNG/vI8IoV4eKL4Ztvoo5QRERyEyXQIpJ5J58MX3wBH3zgGw/PPRdOPBE+/jhXFBibQfPm8P77Pk/m6qt9v2S9etCsmcaFi4hI5iiBFpGsMfNJJjNmwOuve7+4tm09A/3886ijy7RjjoGnn4YVK+CJJ/xz587eBu/hh2Ht2qgjFBGRnEoJtIjsn5QUuOgi7xPXt6937mje3HfrTZkSdXSZdsghPoxx0SJfWK9eHe6+G8qXh8su87IPERGRjJRAi8iBKVjQayGWLIHHH/eC4vr1ffb2rFlRR5dpKSm+sD5qFMyZA926wTvvQN26Pulw8GBNORQREacEWkTio0gRuPVW+O47uP9+3613wglwwQW+vJuL1KwJzz23q7xj5Uov965c2Tv6rVkTdYQiIhIlJdAiEl/Fi3uPuO++gzvu8LqIGjXgiiu8MXMucuihu8o7hg3z8o6ePX3KYbduMHVq1BGKiEgUlECLSGIcdpjvxluyxEeCDxgAVavCDTfAjz9GHV2WpKRAhw67yjsuuwwGDfIGJCedBK+9puEsIiJ5iRJoEUmsI47wdheLFnnT5b59vdXFjTd6bUQuU7Omfws//AB9+sDGjXDppb7p8Pbb/f2CiIgkNyXQIpI9KlTwCYbz53tddN++XlR87bW5rrQDvHvH9dfD3Lnw2WfQsiU8+aQPamzTBj78EHbsiDpKERFJBCXQIpK9qlSBV16BhQt96fall/zYP/4By5ZFHV2WmUGLFt6l4/vvoVcvmDnTO3occ4xXsaxeHXWUIiIST0qgRSQaRx8NL7wAixfDlVdC//5eI3355bm2DqJcObj3Xn8f8O67vsCe3lP6wgth4sRcMbBRRET2QQm0iESrQgV49llYuhSuuQbeeguqVYNLLvFV6lyoQAHo1MlLO+bOhe7dYfhw7yd93HHw1FM+wFFERHInJdAikjOUK+ebDZcu9Q2Ggwd7+7sLL/QsNJeqUcM3G65c6ZUrBx8MN98MZctC164wfrxWpUVEchsl0CKSsxx5pE8vWbYMbrvN+0jXquVLurm48XKxYt7+7quvYPp0b4v94Ydw8smeZPfuDWvXRh2liIhkhhJoEcmZDj8cHn3UE+mePWHMGG+83Lo1fP55rl62PeEE+M9/YNUqL/0uWdKHOJYr5w1Kxo7N1d+eiEjSUwItIjlbqVLwr395q7tHHvHl2+bNoXFjLyzOxZnmQQd5qfcXX8CsWV4r/fHH3hKvWjV47DF18BARyYmUQItI7nDwwT4afNkyX7794QcfD5iaCm+/neubLteq5SXgP/wAr78OZcpAjx6+Kn3OOfDpp7BzZ9RRiogIKIEWkdymSBEfvrJokc/Q3roVunSB6tW9p/SWLVFHeECKFIGLLoIJE3zv5A03wLhxcPrp3hbv/vthxYqooxQRyduUQItI7lSggI8GnzMHhgzx0YBXXeVZ5pNPwq+/Rh3hAatRw/dTrlwJ77zjbbLvvRcqVoR27eD992HbtqijFBHJe5RAi0juli8fnH02TJnidQ7HHgu33OJZ5n33JUXD5UKF4NxzYdQo7/J3111eCn7WWd5G+667cu3sGRGRXEkJtIgkBzM47TRvYTFpkm8y7NXLM8xbb/Vl3CRw9NHwwAM+NnzYMKhf3zcbVqnimw/ffBN+/z3qKEVEkpsSaBFJPg0benY5a5Yv0z79tGeeV1yRa6cb7i5/ft9D+cEH3qDkwQd9f2XXrnDEET4RXUNaREQSQwm0iCSvWrVgwADfcHjVVb48W706dO4M33wTdXRxU7Ys3H03LF7sLbLPOQcGDfIhLccc4wvxS5dGHaWISPJQAi0iye/oo7313bJlcOedMHIk1KvnQ1nGjUuaZdp8+aBZM+jXD3780d87HHOMd+445hhPqPv1g02boo5URCR3UwItInlHmTLw0EO7hrLMmAEtWkCjRt7SIokaLRct6uUco0Z5vfSDD3pSffnl/jKk35fL22eLiERCCbSI5D2HHOJDWb77Dvr2hZ9+8lrp6tXhueeSbhfeUUd5icf8+fDllz79cMQI33NZsSLcdhtMm5Y0C/EiIglnIZf9xUxLSwtTp06NOgwRSSbbt8N778Hjj3s7vJIl4ZprfGBLmTJRR5cQmzf7Pss33/Tx4du2eZ/pCy7wuTTVqkUdoYhI9MxsWggh7S/HlUCLiMSEABMn+vSSYcOgYEGvdbjlFqhZM+roEubnn/39w8CB3gUwBKhTx5Pp887zFWwRkbzo7xJolXCIiKQzg6ZNvR56/ny47DJ46y047jho2xbGjEnKOofDDvMOf2PG+JjwJ5/0QY+33+5ttJs1g+efh7Vro45URCRn0Aq0iMjerF3rddH/+Q+sXg2pqT6Y5bzzPMtMYosXw9tv+3uIefO89/Spp/rK9JlnQvHiUUcoIpJYKuEQETkQmzd7wfATT3g2Wa4cXHcdXHml10wnsRBg5kwv8Rg40JuYFCnig1y6dIE2bXzcuIhIslECLSISDzt3wiefQO/eXvNQpIjXSd94o5d6JLmdO+Grr3xVetAgWLPGm5p06uTJdIsWkJISdZQiIvGhBFpEJN5mzYI+feCNN3yF+pRTPJFu29anmiS57dv9PcRbb8HQoT6g5YgjvLqlSxeoX9/LykVEcisl0CIiibJ2Lbz0Ejz7LKxc6f3grr8eLr00zxQK//GH95Z+6y3/vHUrVK7sifT55/vivJJpEcltlECLiCTatm0wZAg8/bTXORx8sHfyuP56zybziPXrfUV64EBfod65E4491ss8OnWCunWVTItI7qAEWkQkO339tSfSgwf7vOwzzvDyjubN81T2+OOPnkwPGQLjxvlLUakSnH22J9MNGuSJahcRyaWUQIuIRGHlSh8X/sILsG4d1Krl3Tu6doWiRaOOLlutXevzaYYMgVGjfMG+bFmfot6pk7fgzp8/6ihFRHZRAi0iEqU//vCmys88A99+CyVKeHnHtdfmqfKOdBs2wPDhnkx/8om/PKVKQceOnky3bOmDIEVEoqQEWkQkJwgBJk3yRHrIEK9paNfO66RPOSVP1jP89ht8/LG/HMOHw6+/evl4u3Ze6nH66VCsWNRRikheFMkobzM73cwWmNliM7vzbx5zrpnNNbM5ZvZWIuMREYmcGTRu7KvRy5bBPffA5MnQujXUrOkTDzdtijrKbFW0KJxzjm86XLMGPvzQb48cCZ07+8r0GWfAq69qnLiI5AwJW4E2sxRgIXAqsAKYAnQJIczN8JiqwCCgZQjhFzM7PISwem/n1Qq0iCSdLVt8s+Ezz3gyXby4t8C79lqoVi3q6CKzfTtMnOibEIcOheXLfUhLs2ZeN92xIxx1VNRRikgyy/YSDjNrCPQKIbSO3b4LIITwcIbH/BtYGEJ4ObPnVQItIklt8mRPpN95x3fZtWwJV13l2WIenpcdAnzzjSfS773n09QB0tJ2JdM1auSpBicikg2iKOEoByzPcHtF7FhGxwLHmtkXZvaVmZ2ewHhERHK++vVhwABfbn3wQVi61CeRlC8PPXrAokVRRxgJM6hXDx54AObOhfnz4eGHvWS8Z08f1FK1Ktx8M4wd6+89REQSJerdKvmBqkBzoAvwkpmV2P1BZnaVmU01s6lr1qzJ5hBFRCJQpgzcfTcsWeJtKpo1g969fSJJq1a+Qr1lS9RRRqZaNbjzTm+3vXw5PPecvzR9+/qi/eGHwwUXeKn5+vVRRysiySaRCfRKIGN1WvnYsYxWAMNCCNtCCN/hNdNVdz9RCOHFEEJaCCGtdOnSCQtYRCTHyZfPNxgOGaJV6b9Rvjx07w4ffeSttt97z0s6Ro/2UeKlS/t7jqee8pdORORAJbIGOj+eELfCE+cpwAUhhDkZHnM6vrHwEjMrBXwLpIYQ1v3deVUDLSJ53s6dPonkhRd8MsmOHaqV3oMdO3yF+sMP/WWaG9vCXrOmd/Vo394nIaakRBuniORckfSBNrO2wFNACtAvhPCgmd0PTA0hDDMzA54ATgd2AA+GEN7e2zmVQIuIZLBqFfTrBy+9BN9/D4cd5rULl14KdetqV10GS5Z4Mv3hhzB+vHf5OOwwaNPGe063bu23RUTSaZCKiEgyS1+V7t/fW1Vs2QLHH++J9IUXek21/Gn9eu8zPWKEl36sXesr0Y0a+cp0u3a+Uq33HyJ5mxJoEZG84pdffJNh//5ew5CSAm3bejLdvr1mZO9mxw6YMsWT6eHDYfp0P16x4q5kukULKFw42jhFJPspgRYRyYvmzYPXXoPXX/dyj5Ild5V41KmjJdY9WLHCV6VHjPCNiL//Dgcd5GXmrVv7aPEqVaKOUkSygxJoEZG8bPt2zwb794f33//fEo8uXeDII6OOMEfavBnGjfOV6U8+8TpqgGOO8UT69NOheXMoVizKKEUkUZRAi4iISy/xePVVn3yYLx+ccgp07epj/ZQN/q3Fi+HTTz2Z/uwzX50uWBCaNvVkunVrqFVLC/siyUIJtIiI/NWCBfDGG/6xbJnXKpx1lifTp5wC+fNHHWGOtWULTJzoyfQnn8Ds2X68bNldyXSrVl41IyK5kxJoERH5eyHApEk+RnzQIF+lLlPGyzu6dlVLvExYsWLX6vSoUbBhg79kaWlw2mn+0aCB9nCK5CZKoEVEJHO2bIGPP/Zkevhw2LoVatTwRPqCC6BSpagjzPG2b/fOHiNH+sfXX3u3j2LFvGY6PaE+9li9LxHJyZRAi4hI1v3yC7z7rifTEyb4sUaN4Nxz4ZxzoFy5aOPLJdavh7FjfWV65MhdmxErVNiVTLdqpUEuIjmNEmgRETkwy5bBwIG+AXHGDF86bdLEk+lOndTJIwuWLt2VTI8Zs6vco25dLz1v1cpf2iJFoo5UJG9TAi0iIvGzYAEMHuzJ9OzZnv01awbnnQdnn63Jh1mQsdxjzBj48ks/VqgQNG7syfQpp0C9ej4TR0SyjxJoERFJjLlzfePhO+/A/PneFq95c1+ZPvtsKF066ghzlV9/9WqZ0aM9oZ4xw48fcohPRExPqKtVU/20SKIpgRYRkcQKAebM2ZVML1zoS6YtWkDnzt4eT8l0lq1e7fXT6Qn1d9/58XLlfDpi8+b+EleqpIRaJN6UQIuISPYJAWbO9ER68GCfQJK+Mt25s69MH3541FHmSkuXeiI9erRPSRXoyskAABQ+SURBVFy92o9XqOAvb/qHEmqRA6cEWkREopGeTA8e7B8LF3oy3azZrmT6iCOijjJXCgHmzfNEOv1jzRq/Lz2hbtFiV0ItIlmjBFpERKIXgm86TE+m58/3ZdKmTXcl02XLRh1lrpWeUI8duyuhXrvW76tY0RPppk29w4d6UIvsmxJoERHJeebM2ZVMz53rGV3jxt5j+uyz4aijoo4wVwvBX9aMK9TpCXXp0p5IN2niSXVqKhQoEGGwIjmQEmgREcnZ5s71oS3vvguzZvmx+vW9x3SnTnDMMdHGlwRC8AqaCRNg4kT/vHSp33fQQT5qPH2FukEDn5wokpcpgRYRkdxj4UIYMsQ/pk3zY6mpu5LpGjWijS+J/PCDJ9PpCfWMGZ5op6RAnTqeTDdr5p/VREXyGiXQIiKSOy1bBu+95yvTX37px2rU8ET6nHOgdm0V88bRhg3w1VeeTE+YAJMnw+bNfl/16r5C3bSpJ9UVK0Ybq0iiKYEWEZHcb+VKGDrUV6bHj4edO72046yzoH17r5/Onz/qKJPKli0wdequhPqLLzzJBi9Rz5hQ16ih9zKSXJRAi4hIclm9Gt5/35PpsWNh2zb+v717D47qPO84/nsihIUVmYu4movB5iqQkB2QLWx8q53BrR13Jp7aaTKTdjKTGU/bcWeatGn/6TRtZpr+kTZp84+bpvZM0iZOWlqb2C7YxrfACDA3gbhjbIONARcs7iDp6R/Pnjm7wgQ21epod7+fmXfO7jnH4tW8ePnp1XPeV6NHSw88EGF62bJ4jwHV2xsLqbzxRvwM88Yb0uHDca2xMUo92tujLVoUtdVAuSJAAwAqV3e3tGqV9Nxz0i9+EUtN1NREmnvooWizZ2fdy4rkLu3bl85Qv/mmtGdPXBs2LErX29ulJUviOG0as9QoHwRoAEB16O2Nwt0VKyJQJyt6zJqVhunbb2fNthI6ejTqqNeujbZunXTmTFy7/vp0hnrJEumWW6Rrrsm2v8DlEKABANXpwIGYlX7uuSj1uHBBGjUqSjySUo/Gxqx7WdF6emIzyrVrpTVr4vj223Ft+PBY7aOtTbr11mg33cQsNYYGAjQAAKdOpaUezz8vffhhbCu+ZEmE6QcflJqaSG+D4PDhdIa6oyMeVExmqRsbI1AnobqtjZ9xkA0CNAAA+fr6Yo3pFSuibdwY56dPjyD90EPSXXdRXzBIenpiY8p16yJQd3TE+ySmzJxZGKhbW6W6umz7jMpHgAYA4Fc5dChmpVesiFnqs2el+nrps5+NQP3AA9KkSVn3sqqcPBkz0/mh+v3349qwYVJzs7R4cdrmz2cVQwwsAjQAAFfr7Fnp1VfTBxHfey/OL1wYQXrZsij74EHEQXfwYATq9esjXG/YIJ04EddGjIh66vxQPXNmVOkAvw4CNAAAvw73WMnjxRelF16Iddp6eqSGBum++yJML1sW67Nh0PX1xTJ669enbePG+BlIkkaOjPWoFy9Oj1OnUuaOq0OABgBgIHR3S6+8kgbqd9+N801N6ez00qXUTmeop0fq6ioM1Vu3xnlJGj8+wnR+sJ44Mds+Y2giQAMAMNDcpZ07I0i/+KL02muxTN6110r33CPdf3/UUM+dy5Rnxs6dixC9YUNa/tHVFTPYkjRlSmGg/sxnWPkDBGgAAErv9OmonX7hBWnlynRLvsmT0zB9333SuHGZdhPh1Clp06bCUJ0MmRSlHjffXNgo/6guBGgAAAbbgQOxoseqVdJLL0nHj8f51tY0UN9xB+uxDSHHj8fqhps2pW3XrnQ5vTFjYvjyQ/Xs2az+UakI0AAAZKm3N55uW7kyAvWaNdLFixGely6NQH3vvZHOamqy7i3ynD4dz5Hmh+rOTun8+bg+YkQsqZcfqpub4zzKGwEaAICh5NSpqJlOZqi7uuL8qFGxgcs990RbsIB12Iagnp4of88P1Zs2SR9/HNdraqR58wpDdWtrDC/KBwEaAICh7NChqJ9evTra/v1xvrFRuvvuNFDPm0cR7hDlHlU7/UN1svmLJM2YURiom5tjBUSGdGgiQAMAUE7efTcN06tXp8vlTZiQBuq7744CXNLXkHbkSGGg3rhR2rs3vX7ddRGkm5ullpb09ciR2fUZgQANAEC5cpfefrswUCfTmhMnSnfeGe2uu2I9ako+hrzubmnbtqil7uyMJfY6O9NdFaWYmc4P1C0t8fMSG2AOHgI0AACVwj3WW3v1Ven116OW+uDBuNbYGA8l3nVXtJYWHkosE+4xjPmBeuvWqLVONoEZPjyqeFpa0tbcHD9H8YuIgUeABgCgUiUz1EmYfu21eC9FHcAdd6SB+uabmcIsMxcuRIjOD9WdnVE2nxg7tjBQt7TELyOuvTa7flcCAjQAANXkvffSQP3667GYsSTV10u3356WfCxezLbjZeqjjwpLQLZujbKQM2fi+qc+FQ8tzpt3aaO++uoQoAEAqGaHD0eQTkL1tm1xvq5Ouu22CNN33hmvmbYsW319sYBLEqh37Ii2a1fMZCcmTSoM1E1NcZwwgVKQfARoAACQOnZMevPNdIZ68+ZIX7W1UltbOkPd3h7LRKCs9fZGVU8SqHfsiKXHd+yQTp5M7xs9Wpo/P5Yfzz9W6+7zBGgAAHB5H38s/fKXaQ31hg2RusyiqLa9PdqSJdLMmUxTVgj3WNAlP1Rv3x6/oEh2npek8eMjSOeH6vnzI3BXMgI0AAC4eqdOSWvXxpbja9dG6+6Oa2PHpoG6vT3qqOvrs+0vBpR7VP1s2xYtCdXbt8dfjcT110tz50pz5sQSe3PmRLvhhspY/IUADQAAfn19fTFFmQTqNWvSBxNraqSFC2N2ur1duvVW6cYbmaWuQO6xp09+oN61K1r+GtbXXBO/qEgCddJmz5bGjMmu/8UiQAMAgIH10UdSR0caqjs6pNOn41pjY9RSt7VFoF68OGauUZHcpaNH0zCd3/bvT9exluKvQf9gPWdO/Mw1fHh238MnIUADAIDS6umJKcmODmndujhu3x7pSpJuuikN1G1tsSZ1XV22fUbJXbwYDzB+Urg+ciS9r6YmQnT/cpA5c7JbHYQADQAABt/Jk9JbbxWG6mQHkGHDovQjmaFua4uCWrYirxonTki7d18arPfskc6dS+/bvVuaNWvw+0eABgAAQ8OhQxGmk0C9YUO6llpDg7RoUYTpJFRPmUI9dZXp64u9gJJA/fjj8fPWYCNAAwCAoamvL1JSEqrXrZO2bInf/UvSxIlpPfXixRGwy+lJNJQtAjQAACgf587FVnr5oTpZ9UOSpk+PGupbbkmPkyZl1l1UpssF6AwmwwEAAK6gri6ddU6cOBHlHm+9JW3cKG3aJC1fnl6fMOHSUD1jBuUfGHAlDdBmtkzSdyXVSPqBu//tZe77vKSfS1rs7kwvAwCAS40aJd13X7REd3eUe2zalIbqVatiF0VJGjlSam2NQN3aGg8tNjUNvfXSUFZKFqDNrEbS9yXdL+mgpPVm9qy7d/W7r0HSE5I6StUXAABQoa67Tlq6NFri3LnY5SM/VD/5pHTmTFyvrY0QnQTq5EhdNa5SKWeg2yTtdff9kmRmP5H0sKSufvf9taRvS/p6CfsCAACqRV1dPGi4KK90tbdX2rtX2rw52pYt0sqV0tNPp/dMnRphOr9Nn86yerhEKQP0ZEnv5b0/KOnW/BvM7BZJU939F2Z22QBtZl+V9FVJmjZtWgm6CgAAKlpNTborx6OPpuePHIkwnQTrzZul559PS0Cuuy5mp5OZ6tZWaf58NoCpcpk9RGhmn5L0HUm/d6V73f1JSU9KsQpHaXsGAACqxvjx0v33R0ucPRs7KOaH6qeekk6dius1NdK8eYUz1QsXslV5FSllgD4kaWre+ym5c4kGSQskvWrxdOxESc+a2ed4kBAAAGRmxIhLS0D6+qT9+wtD9erV0o9+lN4zaZLU3Cy1tMSxuTmCNrPVFadk60Cb2TBJuyX9hiI4r5f0u+6+/TL3vyrpa1cKz6wDDQAAhoyjR9MSkM7OaF1d0vnzcb2mRpo9+9JgfcMN1FaXgUFfB9rde8zsDyX9j2IZux+6+3Yz+6akDe7+bKn+bAAAgEExbtylS+v19Eh79qSBeutWaf166Zln0nsaGqQFCy4N1qNHD/73gKKxEyEAAMBgOHkyaqu3bi0M18ePp/dMmZKG6SRYz53LutUZYSdCAACALDU0SLfdFi3hLr3/fhqmk2D98svShQtxz7BhEaIXLIia6rlzo82aFfXaGHQEaAAAgKyYSZMnR1u2LD1/8aK0e3fhTHVHh/TTn0boTv7bGTPSQJ3fxo3L5vupEgRoAACAoaa2Ntabnj9feuyx9PzZs1FfvXOntGNHHHfujBVBzp5N72tsjCA9b160pqY4Tp3Kw4sDgBpoAACActfXJ737bhqok4C9Y0esFJKor49gnQTqJFzfeGOUiqDA5WqgCdAAAACV7NixCNJdXYXHgwfTe4YPj+X25s6NY35rbMyu7xnjIUIAAIBqNHastHRptHzd3TFTnR+st2yRli9PtzKXpDFj0jA9a1bh6/r6wf1ehghmoAEAAJC6eFF6++14iHH37qi5Tl7nz1pL0vXXR5CeObOw3XRTrDpS5piBBgAAwJXV1qazzP2dPi3t3VsYqvfulVaskD78sPDeiRMvDdZJuB41anC+lxIhQAMAAODq1NdLCxdG6+/kSWnfvgjU+W3VKumppwrvHTMmgvQntUmThvxKIQRoAAAA/P81NEitrdH6O3NG2r8/Zq737UtbR4f0s58V1lzX1cWqIPmh+ktfGlKz1gRoAAAAlNa118ZOigsWXHrt4kXpnXcKg3XSXnop1rd+5JHB7/OvQIAGAABAdmpr0/ro/tylw4elCRMGv1+/AgEaAAAAQ5NZ1EQPMUO7QhsAAAAYYgjQAAAAQBEI0AAAAEARCNAAAABAEQjQAAAAQBEI0AAAAEARCNAAAABAEQjQAAAAQBEI0AAAAEARCNAAAABAEQjQAAAAQBHM3bPuQ1HM7KikdzL648dKOpbRn43Bx3hXF8a7ujDe1Ycxry4DNd43uPu4/ifLLkBnycw2uPuirPuBwcF4VxfGu7ow3tWHMa8upR5vSjgAAACAIhCgAQAAgCIQoIvzZNYdwKBivKsL411dGO/qw5hXl5KONzXQAAAAQBGYgQYAAACKQIAGAAAAikCAvgpmtszMdpnZXjP7Rtb9wcAzsx+a2REz25Z3boyZrTKzPbnj6Cz7iIFjZlPNbLWZdZnZdjN7IneeMa9AZlZnZuvMbEtuvP8qd36GmXXkPtt/ambDs+4rBo6Z1ZjZJjNbkXvPeFcoMztgZp1mttnMNuTOlfTznAB9BWZWI+n7kh6Q1CTpC2bWlG2vUAJPSVrW79w3JL3s7rMkvZx7j8rQI+lP3L1J0m2S/iD3/zVjXpnOS7rX3RdKapW0zMxuk/RtSX/v7jMlHZf0lQz7iIH3hKQdee8Z78p2j7u35q39XNLPcwL0lbVJ2uvu+939gqSfSHo44z5hgLn765L+t9/phyU9nXv9tKTfHtROoWTc/QN335h7fVLxj+xkMeYVycOp3NvaXHNJ90r6ee48411BzGyKpN+S9IPcexPjXW1K+nlOgL6yyZLey3t/MHcOlW+Cu3+Qe31Y0oQsO4PSMLPpkm6W1CHGvGLlfp2/WdIRSask7ZN0wt17crfw2V5Z/kHSn0rqy71vFONdyVzSSjN7y8y+mjtX0s/zYQP5xYBK5e5uZqz5WGHM7NOS/kPSH7t7d0xSBca8srh7r6RWMxslabmkuRl3CSViZg9KOuLub5nZ3Vn3B4PiDnc/ZGbjJa0ys535F0vxec4M9JUdkjQ17/2U3DlUvg/NbJIk5Y5HMu4PBpCZ1SrC84/d/T9zpxnzCufuJyStltQuaZSZJRNJfLZXjtslfc7MDijKLu+V9F0x3hXL3Q/ljkcUPyC3qcSf5wToK1svaVbu6d3hkh6T9GzGfcLgeFbSl3OvvyzpvzPsCwZQrh7yXyTtcPfv5F1izCuQmY3LzTzLzEZIul9R975a0iO52xjvCuHuf+7uU9x9uuLf7Ffc/YtivCuSmdWbWUPyWtJnJW1TiT/P2YnwKpjZbyrqqWok/dDdv5VxlzDAzOzfJd0taaykDyX9paT/kvSMpGmS3pH0O+7e/0FDlCEzu0PSG5I6ldZI/oWiDpoxrzBm1qJ4iKhGMXH0jLt/08xuVMxQjpG0SdKX3P18dj3FQMuVcHzN3R9kvCtTblyX594Ok/Rv7v4tM2tUCT/PCdAAAABAESjhAAAAAIpAgAYAAACKQIAGAAAAikCABgAAAIpAgAYAAACKQIAGgDJiZr1mtjmvfWMAv/Z0M9s2UF8PACoVW3kDQHk56+6tWXcCAKoZM9AAUAHM7ICZ/Z2ZdZrZOjObmTs/3cxeMbOtZvaymU3LnZ9gZsvNbEuuLcl9qRoz+2cz225mK3M79wEA8hCgAaC8jOhXwvFo3rWP3b1Z0j8pdk+VpH+U9LS7t0j6saTv5c5/T9Jr7r5Q0i2StufOz5L0fXefL+mEpM+X+PsBgLLDToQAUEbM7JS7f/oTzh+QdK+77zezWkmH3b3RzI5JmuTuF3PnP3D3sWZ2VNKU/K2MzWy6pFXuPiv3/s8k1br735T+OwOA8sEMNABUDr/M62Kcz3vdK56VAYBLEKABoHI8mndcm3u9RtJjuddflPRG7vXLkh6XJDOrMbORg9VJACh3zCwAQHkZYWab896/6O7JUnajzWyrYhb5C7lzfyTpX83s65KOSvr93PknJD1pZl9RzDQ/LumDkvceACoANdAAUAFyNdCL3P1Y1n0BgEpHCQcAAABQBGagAQAAgCIwAw0AAAAUgQANAAAAFIEADQAAABSBAA0AAAAUgQANAAAAFOH/ABuYs+uaXKJEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize model training hisotry\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12,12))\n",
    "plt.subplot(211)\n",
    "plt.plot(final_hist.history['accuracy'], color='blue', label='train')\n",
    "plt.plot(final_hist.history['val_accuracy'], color='red', label='test')\n",
    "plt.title('Final Model Training Performance (Accuracy)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.subplot(212)\n",
    "plt.plot(final_hist.history['loss'], color='blue', label='train')\n",
    "plt.plot(final_hist.history['val_loss'], color='red', label='test')\n",
    "plt.title('Final Model Training Performance (Loss)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 261us/sample - loss: 0.3480 - accuracy: 0.9211\n",
      "\n",
      "accuracy: 92.105263%\n",
      "\n",
      "loss: 0.348001\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Keras model on previously unseen data\n",
    "scores = final_model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %f%%\" % (final_model.metrics_names[1], scores[1]*100))\n",
    "print(\"\\n%s: %f\" % (final_model.metrics_names[0], scores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data item #0 predicted to be ['Iris-setosa'] (expected ['Iris-setosa'])\n",
      "Data item #1 predicted to be ['Iris-setosa'] (expected ['Iris-setosa'])\n",
      "Data item #2 predicted to be ['Iris-setosa'] (expected ['Iris-setosa'])\n",
      "Data item #3 predicted to be ['Iris-versicolor'] (expected ['Iris-versicolor'])\n",
      "Data item #4 predicted to be ['Iris-virginica'] (expected ['Iris-virginica'])\n",
      "Data item #5 predicted to be ['Iris-virginica'] (expected ['Iris-virginica'])\n",
      "Data item #6 predicted to be ['Iris-setosa'] (expected ['Iris-setosa'])\n",
      "Data item #7 predicted to be ['Iris-setosa'] (expected ['Iris-setosa'])\n",
      "Data item #8 predicted to be ['Iris-versicolor'] (expected ['Iris-versicolor'])\n",
      "Data item #9 predicted to be ['Iris-setosa'] (expected ['Iris-setosa'])\n",
      "Data item #10 predicted to be ['Iris-virginica'] (expected ['Iris-versicolor'])\n",
      "Data item #11 predicted to be ['Iris-versicolor'] (expected ['Iris-versicolor'])\n",
      "Data item #12 predicted to be ['Iris-virginica'] (expected ['Iris-versicolor'])\n",
      "Data item #13 predicted to be ['Iris-setosa'] (expected ['Iris-setosa'])\n",
      "Data item #14 predicted to be ['Iris-virginica'] (expected ['Iris-virginica'])\n",
      "Data item #15 predicted to be ['Iris-virginica'] (expected ['Iris-virginica'])\n",
      "Data item #16 predicted to be ['Iris-setosa'] (expected ['Iris-setosa'])\n",
      "Data item #17 predicted to be ['Iris-versicolor'] (expected ['Iris-versicolor'])\n",
      "Data item #18 predicted to be ['Iris-virginica'] (expected ['Iris-virginica'])\n",
      "Data item #19 predicted to be ['Iris-setosa'] (expected ['Iris-setosa'])\n"
     ]
    }
   ],
   "source": [
    "# Make class predictions with the model\n",
    "predictions = final_model.predict_classes(X_test)\n",
    "\n",
    "# Summarize the first 20 cases\n",
    "for i in range(20):\n",
    "\tprint('Data item #%d predicted to be %s (expected %s)' % (i, encoder.inverse_transform([predictions[i]]), encoder.inverse_transform([np.argmax(y_test[i])])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 5. Finalize Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for the script: 0:01:22.037662\n"
     ]
    }
   ],
   "source": [
    "print ('Total time for the script:',(datetime.now() - startTimeScript))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
