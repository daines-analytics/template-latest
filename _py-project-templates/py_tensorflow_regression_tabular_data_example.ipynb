{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Deep Learning Model for [PROJECT NAME] Using TensorFlow Version 6\n",
    "### David Lowe\n",
    "### April 9, 2020\n",
    "\n",
    "Template Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery. [https://machinelearningmastery.com/]\n",
    "\n",
    "SUMMARY: The purpose of this project is to construct a predictive model using various machine learning algorithms and to document the end-to-end steps using a template. The [PROJECT NAME] dataset is a regression situation where we are trying to predict the value of a continuous variable.\n",
    "\n",
    "INTRODUCTION: [Sample Paragraph - The purpose of the analysis is to predict the housing values in the suburbs of Boston by using the home sale transaction history.]\n",
    "\n",
    "ANALYSIS: [Sample Paragraph - The baseline performance of the model achieved a root mean squared error (RMSE) of 6.9113. After tuning the hyperparameters, the best model processed the training dataset with an RMSE of 3.4193. Furthermore, the final model processed the test dataset with an RMSE of 3.2451, which was consistent with the training result.]\n",
    "\n",
    "CONCLUSION: For this dataset, the model built using TensorFlow achieved a satisfactory result and should be considered for future modeling activities.\n",
    "\n",
    "Dataset Used: [PROJECT NAME] Dataset\n",
    "\n",
    "Dataset ML Model: Regression with numerical attributes\n",
    "\n",
    "Dataset Reference: [https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.data]\n",
    "\n",
    "One potential source of performance benchmarks: [https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/]\n",
    "\n",
    "A deep-learning modeling project generally can be broken down into five major tasks:\n",
    "\n",
    "1. Prepare Environment\n",
    "2. Load and Prepare Data\n",
    "3. Define and Train Model\n",
    "4. Evaluate and Optimize Model\n",
    "5. Finalize Model and Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1. Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve GPU configuration information from Colab\n",
    "# gpu_info = !nvidia-smi\n",
    "# gpu_info = '\\n'.join(gpu_info)\n",
    "# if gpu_info.find('failed') >= 0:\n",
    "#     print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "#     print('and then re-execute this cell.')\n",
    "# else:\n",
    "#     print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve memory configuration information from Colab\n",
    "# from psutil import virtual_memory\n",
    "# ram_gb = virtual_memory().total / 1e9\n",
    "# print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "# if ram_gb < 20:\n",
    "#     print('To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"')\n",
    "#     print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
    "#     print('re-execute this cell.')\n",
    "# else:\n",
    "#     print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct Colab to use TensorFlow v2\n",
    "# %tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed number for reproducible results\n",
    "seedNum = 888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and packages\n",
    "import random\n",
    "random.seed(seedNum)\n",
    "import numpy as np\n",
    "np.random.seed(seedNum)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seedNum)\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import smtplib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from email.message import EmailMessage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Begin the timer for the script processing\n",
    "startTimeScript = datetime.now()\n",
    "\n",
    "# Set up the verbose flag to print detailed messages for debugging (setting to True will activate)\n",
    "# verbose = True\n",
    "# tf.debugging.set_log_device_placement(verbose)\n",
    "\n",
    "# Set up the number of CPU cores available for multi-thread processing\n",
    "n_jobs = -1\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Set up the flag to stop sending progress emails (setting to True will send status emails!)\n",
    "notifyStatus = False\n",
    "\n",
    "# Set the number of folds for cross validation\n",
    "n_folds = 5\n",
    "\n",
    "# Set the flag for splitting the dataset\n",
    "splitDataset = True\n",
    "splitPercentage = 0.25\n",
    "\n",
    "# Set various default Keras modeling parameters\n",
    "default_loss = 'mean_squared_error'\n",
    "default_optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
    "default_kernel_init = tf.initializers.he_uniform(seed=seedNum)\n",
    "default_epoch = 50\n",
    "default_batch = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the email notification function\n",
    "def email_notify(msg_text):\n",
    "    sender = os.environ.get('MAIL_SENDER')\n",
    "    receiver = os.environ.get('MAIL_RECEIVER')\n",
    "    gateway = os.environ.get('SMTP_GATEWAY')\n",
    "    smtpuser = os.environ.get('SMTP_USERNAME')\n",
    "    password = os.environ.get('SMTP_PASSWORD')\n",
    "    if sender==None or receiver==None or gateway==None or smtpuser==None or password==None:\n",
    "        sys.exit(\"Incomplete email setup info. Script Processing Aborted!!!\")\n",
    "    msg = EmailMessage()\n",
    "    msg.set_content(msg_text)\n",
    "    msg['Subject'] = 'Notification from Keras Regression Script'\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = receiver\n",
    "    server = smtplib.SMTP(gateway, 587)\n",
    "    server.starttls()\n",
    "    server.login(smtpuser, password)\n",
    "    server.send_message(msg)\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the random number generators\n",
    "def reset_random(x):\n",
    "    random.seed(x)\n",
    "    np.random.seed(x)\n",
    "    tf.random.set_seed(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 1. Prepare Environment completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 2. Load Data has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a) Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575   65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421   78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185   61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998   45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147   54.2  6.0622    3  222.0   \n",
       "5  0.02985   0.0   2.18     0  0.458  6.430   58.7  6.0622    3  222.0   \n",
       "6  0.08829  12.5   7.87     0  0.524  6.012   66.6  5.5605    5  311.0   \n",
       "7  0.14455  12.5   7.87     0  0.524  6.172   96.1  5.9505    5  311.0   \n",
       "8  0.21124  12.5   7.87     0  0.524  5.631  100.0  6.0821    5  311.0   \n",
       "9  0.17004  12.5   7.87     0  0.524  6.004   85.9  6.5921    5  311.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  \n",
       "5     18.7  394.12   5.21  28.7  \n",
       "6     15.2  395.60  12.43  22.9  \n",
       "7     15.2  396.90  19.15  27.1  \n",
       "8     15.2  386.63  29.93  16.5  \n",
       "9     15.2  386.71  17.10  18.9  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "colNames = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV']\n",
    "Xy_original = pd.read_csv(dataset_path, names=colNames, delim_whitespace=True, header=None)\n",
    "\n",
    "# Take a peek at the dataframe after the import\n",
    "Xy_original.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    int64  \n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    int64  \n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "Xy_original.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_counts = Xy_original.isnull().sum()\n",
    "null_counts[null_counts > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of NaN in the dataframe:  0\n"
     ]
    }
   ],
   "source": [
    "print('Total number of NaN in the dataframe: ', Xy_original.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b) Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575   65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421   78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185   61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998   45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147   54.2  6.0622    3  222.0   \n",
       "5  0.02985   0.0   2.18     0  0.458  6.430   58.7  6.0622    3  222.0   \n",
       "6  0.08829  12.5   7.87     0  0.524  6.012   66.6  5.5605    5  311.0   \n",
       "7  0.14455  12.5   7.87     0  0.524  6.172   96.1  5.9505    5  311.0   \n",
       "8  0.21124  12.5   7.87     0  0.524  5.631  100.0  6.0821    5  311.0   \n",
       "9  0.17004  12.5   7.87     0  0.524  6.004   85.9  6.5921    5  311.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  \n",
       "5     18.7  394.12   5.21  28.7  \n",
       "6     15.2  395.60  12.43  22.9  \n",
       "7     15.2  396.90  19.15  27.1  \n",
       "8     15.2  386.63  29.93  16.5  \n",
       "9     15.2  386.71  17.10  18.9  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the class column to the name of targetVar if required\n",
    "# Xy_original = Xy_original.rename(columns={'old_name': 'targetVar'})\n",
    "\n",
    "# Dropping features\n",
    "# Xy_original.drop(columns=['attribute_name'], inplace=True)\n",
    "\n",
    "# Impute missing values\n",
    "# Xy_original['col_name'].fillna('someValue', inplace=True)\n",
    "# Xy_original['attribute_name'].fillna(value=Xy_original['attribute_name'].median(), inplace=True)\n",
    "\n",
    "# Convert columns from one data type to another\n",
    "# Xy_original.column_name = Xy_original.column_name.astype('int')\n",
    "# Xy_original.column_name = Xy_original.column_name.astype('category')\n",
    "\n",
    "# Convert features with Y/N levels into categorical feature of 1/0\n",
    "# def reClassSomecol(target):\n",
    "#     if (target == 'Y'): return 1\n",
    "#     else: return 0\n",
    "# Xy_original['targetVar'] = Xy_original['target'].apply(reClassSomecol)\n",
    "# Xy_original.drop(columns=['target'], inplace=True)\n",
    "\n",
    "# Take a peek at the dataframe after the cleaning\n",
    "Xy_original.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    int64  \n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    int64  \n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "Xy_original.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_counts = Xy_original.isnull().sum()\n",
    "null_counts[null_counts > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of NaN in the dataframe:  0\n"
     ]
    }
   ],
   "source": [
    "print('Total number of NaN in the dataframe: ', Xy_original.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.c) Feature Scaling and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use variable totCol to hold the number of columns in the dataframe\n",
    "totCol = len(Xy_original.columns)\n",
    "\n",
    "# Set up variable totAttr for the total number of attribute columns\n",
    "totAttr = totCol-1\n",
    "\n",
    "# targetCol variable indicates the column location of the target/class variable\n",
    "# If the first column, set targetCol to 1. If the last column, set targetCol to totCol\n",
    "# If (targetCol <> 1) and (targetCol <> totCol), be aware when slicing up the dataframes for visualization\n",
    "targetCol = totCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xy_original.shape: (506, 14) X_original.shape: (506, 13) y_original.shape: (506,)\n"
     ]
    }
   ],
   "source": [
    "# We create attribute-only and target-only datasets (X_original and y_original)\n",
    "# for various visualization and cleaning/transformation operations\n",
    "\n",
    "if targetCol == totCol:\n",
    "    X_original = Xy_original.iloc[:,0:totAttr]\n",
    "    y_original = Xy_original.iloc[:,totAttr]\n",
    "else:\n",
    "    X_original = Xy_original.iloc[:,1:totCol]\n",
    "    y_original = Xy_original.iloc[:,0]\n",
    "\n",
    "print(\"Xy_original.shape: {} X_original.shape: {} y_original.shape: {}\".format(Xy_original.shape, X_original.shape, y_original.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the number of row and columns for visualization display. dispRow * dispCol should be >= totAttr\n",
    "dispCol = 4\n",
    "if totAttr % dispCol == 0 :\n",
    "    dispRow = totAttr // dispCol\n",
    "else :\n",
    "    dispRow = (totAttr // dispCol) + 1\n",
    "    \n",
    "# Set figure width to display the data visualization plots\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = dispCol*4\n",
    "fig_size[1] = dispRow*4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histograms for each attribute before pre-processing\n",
    "X_original.hist(layout=(dispRow,dispCol))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "tobe_transformed_cols = X_original.columns.tolist()\n",
    "# tobe_transformed_cols.remove('some_column_label')\n",
    "print(tobe_transformed_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>-0.408212</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>2.422565</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.469104</td>\n",
       "      <td>-0.429726</td>\n",
       "      <td>1.074822</td>\n",
       "      <td>-0.916009</td>\n",
       "      <td>-0.637962</td>\n",
       "      <td>1.798194</td>\n",
       "      <td>0.760340</td>\n",
       "      <td>0.366604</td>\n",
       "      <td>0.759313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>-0.407563</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>2.422565</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.469104</td>\n",
       "      <td>-0.429726</td>\n",
       "      <td>0.530745</td>\n",
       "      <td>-0.801065</td>\n",
       "      <td>-0.637962</td>\n",
       "      <td>1.798194</td>\n",
       "      <td>0.760340</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>0.097692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>-0.400349</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.211099</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.261784</td>\n",
       "      <td>-0.822932</td>\n",
       "      <td>-0.518292</td>\n",
       "      <td>-0.671859</td>\n",
       "      <td>-0.408041</td>\n",
       "      <td>-0.102376</td>\n",
       "      <td>0.344213</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.090141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>-0.387983</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.211099</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.261784</td>\n",
       "      <td>-0.510932</td>\n",
       "      <td>-0.923682</td>\n",
       "      <td>-0.671859</td>\n",
       "      <td>-0.408041</td>\n",
       "      <td>-0.102376</td>\n",
       "      <td>0.344213</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>0.131334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>-0.399688</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.211099</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.261784</td>\n",
       "      <td>-0.875644</td>\n",
       "      <td>-1.414418</td>\n",
       "      <td>-0.473678</td>\n",
       "      <td>-0.408041</td>\n",
       "      <td>-0.102376</td>\n",
       "      <td>0.344213</td>\n",
       "      <td>0.401471</td>\n",
       "      <td>0.693431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0   -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1   -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2   -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3   -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4   -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "491 -0.408212 -0.487722  2.422565 -0.272599  0.469104 -0.429726  1.074822   \n",
       "492 -0.407563 -0.487722  2.422565 -0.272599  0.469104 -0.429726  0.530745   \n",
       "493 -0.400349 -0.487722 -0.211099 -0.272599  0.261784 -0.822932 -0.518292   \n",
       "494 -0.387983 -0.487722 -0.211099 -0.272599  0.261784 -0.510932 -0.923682   \n",
       "495 -0.399688 -0.487722 -0.211099 -0.272599  0.261784 -0.875644 -1.414418   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0    0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  \n",
       "1    0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  \n",
       "2    0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  \n",
       "3    1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  \n",
       "4    1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "491 -0.916009 -0.637962  1.798194  0.760340  0.366604  0.759313  \n",
       "492 -0.801065 -0.637962  1.798194  0.760340  0.441052  0.097692  \n",
       "493 -0.671859 -0.408041 -0.102376  0.344213  0.441052 -0.090141  \n",
       "494 -0.671859 -0.408041 -0.102376  0.344213  0.441052  0.131334  \n",
       "495 -0.473678 -0.408041 -0.102376  0.344213  0.401471  0.693431  \n",
       "\n",
       "[496 rows x 13 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply feature scaling and transformation\n",
    "X_original = X_original.astype(float)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_original[tobe_transformed_cols] = scaler.fit_transform(X_original[tobe_transformed_cols])\n",
    "\n",
    "X_original.head(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histograms for each attribute after pre-processing\n",
    "X_original.hist(layout=(dispRow,dispCol))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.d) Splitting Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot-encoding before splitting into trainig and test\n",
    "# X_original = pd.get_dummies(X_original)\n",
    "# print(X_original.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (379, 13) X_train.type: <class 'numpy.ndarray'>\n",
      "y_train.shape: (379,) y_train.type: <class 'numpy.ndarray'>\n",
      "X_test.shape: (127, 13) X_test.type: <class 'numpy.ndarray'>\n",
      "y_test.shape: (127,) y_test.type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X_original.to_numpy()\n",
    "y_encoded = y_original.to_numpy()\n",
    "if (splitDataset):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=splitPercentage, random_state=seedNum)\n",
    "else:\n",
    "    X_train, y_train = X_encoded, y_encoded\n",
    "    X_test, y_test = X_encoded, y_encoded\n",
    "print(\"X_train.shape: {} X_train.type: {}\".format(X_train.shape, type(X_train)))\n",
    "print(\"y_train.shape: {} y_train.type: {}\".format(y_train.shape, type(y_train)))\n",
    "print(\"X_test.shape: {} X_test.type: {}\".format(X_test.shape, type(X_test)))\n",
    "print(\"y_test.shape: {} y_test.type: {}\".format(y_test.shape, type(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 1. Load Data completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3. Define and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 3. Define and Fit Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the baseline model for benchmarking\n",
    "def create_default_model():\n",
    "    default_model = Sequential()\n",
    "    default_model.add(Dense(25, input_shape=(X_train.shape[1],), activation='relu', kernel_initializer=default_kernel_init))\n",
    "    default_model.add(Dense(1, kernel_initializer=default_kernel_init))\n",
    "    default_model.compile(loss=default_loss, optimizer=default_optimizer)\n",
    "    return default_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 676.9069 - val_loss: 686.3243\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 658.7726 - val_loss: 667.6340\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 641.5426 - val_loss: 649.5173\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 624.9274 - val_loss: 632.3510\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 609.0734 - val_loss: 615.4614\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 593.3868 - val_loss: 598.8410\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 136us/sample - loss: 578.0192 - val_loss: 582.5808\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 562.6578 - val_loss: 566.3544\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 135us/sample - loss: 547.4785 - val_loss: 549.9724\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 532.1357 - val_loss: 533.3546\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 135us/sample - loss: 516.5386 - val_loss: 516.7859\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 500.8878 - val_loss: 500.1446\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 485.3213 - val_loss: 483.1863\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 469.0661 - val_loss: 466.6486\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 453.4754 - val_loss: 449.2593\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 142us/sample - loss: 436.9926 - val_loss: 431.9881\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 136us/sample - loss: 420.6289 - val_loss: 414.3119\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 137us/sample - loss: 404.0201 - val_loss: 396.2634\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 387.1416 - val_loss: 378.0137\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 370.0795 - val_loss: 359.8927\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 134us/sample - loss: 353.1205 - val_loss: 341.5904\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 336.1324 - val_loss: 323.3639\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 318.8888 - val_loss: 305.5153\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 302.4412 - val_loss: 287.4345\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 285.4704 - val_loss: 270.0616\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 269.2488 - val_loss: 252.7682\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 139us/sample - loss: 253.4098 - val_loss: 235.7432\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 237.6089 - val_loss: 219.4628\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 222.4726 - val_loss: 203.7729\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 134us/sample - loss: 207.9145 - val_loss: 188.8880\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 136us/sample - loss: 194.1221 - val_loss: 174.6406\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 180.8129 - val_loss: 161.2966\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 168.6106 - val_loss: 148.5395\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 142us/sample - loss: 156.8429 - val_loss: 136.8718\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 145.8208 - val_loss: 126.3039\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 135.7867 - val_loss: 116.5747\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 137us/sample - loss: 126.5197 - val_loss: 107.7238\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 134us/sample - loss: 117.8952 - val_loss: 99.8275\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 140us/sample - loss: 110.2454 - val_loss: 92.4298\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 103.1662 - val_loss: 85.8300\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 134us/sample - loss: 96.7343 - val_loss: 79.8514\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 136us/sample - loss: 90.6155 - val_loss: 74.7354\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 85.5048 - val_loss: 69.9860\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 80.5684 - val_loss: 65.8078\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 76.2624 - val_loss: 61.9327\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 72.0478 - val_loss: 58.6292\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 136us/sample - loss: 68.3587 - val_loss: 55.5844\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 135us/sample - loss: 65.0748 - val_loss: 52.7254\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 62.0390 - val_loss: 50.0661\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 137us/sample - loss: 59.0361 - val_loss: 47.7662\n",
      "Total time for model fitting: 0:00:03.715543\n"
     ]
    }
   ],
   "source": [
    "startTimeModule = datetime.now()\n",
    "\n",
    "# Initialize the baseline model\n",
    "reset_random(seedNum)\n",
    "baseline_model = create_default_model()\n",
    "baseline_hist = baseline_model.fit(X_train, y_train, epochs=default_epoch, batch_size=default_batch,\n",
    "                                   validation_data=(X_test, y_test), verbose=1)\n",
    "print('Total time for model fitting:', (datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize model training hisotry\n",
    "fig, axs = plt.subplots(1, 1, figsize=(12,6))\n",
    "plt.subplot(111)\n",
    "plt.plot(baseline_hist.history['loss'], color='blue', label='train')\n",
    "plt.plot(baseline_hist.history['val_loss'], color='red', label='test')\n",
    "plt.title('Baseline Model Training Performance (Loss)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 3. Define and Fit Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4. Evaluate and Optimize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 4. Optimize Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras model required for KerasClassifier\n",
    "def create_customized_model(optimizer, kernel_init):\n",
    "    customized_model = Sequential()\n",
    "    customized_model.add(Dense(25, input_shape=(X_train.shape[1],), activation='relu', kernel_initializer=kernel_init))\n",
    "    customized_model.add(Dense(1, kernel_initializer=kernel_init))\n",
    "    customized_model.compile(loss=default_loss, optimizer=optimizer)\n",
    "    return customized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer candidate #1 has the object ID of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f6c08f41350>\n",
      "Optimizer candidate #2 has the object ID of <tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f6c08f41390>\n",
      "Optimizer candidate #3 has the object ID of <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f6c08f413d0>\n",
      "Initializer candidate #1 has the object ID of <tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7f6c08f84bd0>\n",
      "Initializer candidate #2 has the object ID of <tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7f6c08f415d0>\n",
      "Initializer candidate #3 has the object ID of <tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7f6c08f41550>\n",
      "\n",
      "Forming the grid-search model #0 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f6c08f41350>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7f6c08f84bd0>, epochs=50, batch_size=16\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 668.9629 - val_loss: 669.5553\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 241us/sample - loss: 636.2697 - val_loss: 636.8177\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 241us/sample - loss: 606.1635 - val_loss: 605.0607\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 236us/sample - loss: 577.0679 - val_loss: 574.6287\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 232us/sample - loss: 548.5579 - val_loss: 544.0643\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 234us/sample - loss: 519.5493 - val_loss: 513.0552\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 242us/sample - loss: 490.1264 - val_loss: 481.5063\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 243us/sample - loss: 460.0595 - val_loss: 449.4433\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 240us/sample - loss: 429.6316 - val_loss: 416.3182\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 245us/sample - loss: 398.5063 - val_loss: 381.9110\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 228us/sample - loss: 366.5880 - val_loss: 347.3323\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 236us/sample - loss: 334.4872 - val_loss: 313.2279\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 238us/sample - loss: 302.8563 - val_loss: 278.8982\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 231us/sample - loss: 271.1161 - val_loss: 247.0344\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 241.7182 - val_loss: 215.0441\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 241us/sample - loss: 212.8202 - val_loss: 186.2118\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 227us/sample - loss: 186.5127 - val_loss: 160.1555\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 244us/sample - loss: 162.8720 - val_loss: 136.6239\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 237us/sample - loss: 141.7250 - val_loss: 116.4776\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 234us/sample - loss: 123.7417 - val_loss: 99.7001\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 239us/sample - loss: 108.4726 - val_loss: 86.0434\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 241us/sample - loss: 95.9182 - val_loss: 75.0808\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 229us/sample - loss: 85.1364 - val_loss: 66.5879\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 241us/sample - loss: 76.5606 - val_loss: 59.4187\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 244us/sample - loss: 69.1877 - val_loss: 53.6224\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 234us/sample - loss: 62.9799 - val_loss: 48.8179\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 208us/sample - loss: 57.9009 - val_loss: 44.6835\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 234us/sample - loss: 53.3807 - val_loss: 41.3334\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 221us/sample - loss: 49.5772 - val_loss: 38.4430\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 232us/sample - loss: 46.4141 - val_loss: 35.9686\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 232us/sample - loss: 43.6677 - val_loss: 33.9135\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 237us/sample - loss: 41.2267 - val_loss: 32.2273\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 246us/sample - loss: 39.2893 - val_loss: 30.7085\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 244us/sample - loss: 37.5459 - val_loss: 29.4338\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 241us/sample - loss: 36.0153 - val_loss: 28.3451\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 243us/sample - loss: 34.7648 - val_loss: 27.4030\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 233us/sample - loss: 33.6699 - val_loss: 26.6436\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 232us/sample - loss: 32.7692 - val_loss: 25.9500\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 235us/sample - loss: 31.8925 - val_loss: 25.4002\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 240us/sample - loss: 31.2208 - val_loss: 24.8550\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 227us/sample - loss: 30.5195 - val_loss: 24.4266\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 245us/sample - loss: 29.9517 - val_loss: 24.0917\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 235us/sample - loss: 29.4966 - val_loss: 23.7574\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 233us/sample - loss: 28.9839 - val_loss: 23.4301\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 234us/sample - loss: 28.5436 - val_loss: 23.1605\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 237us/sample - loss: 28.1641 - val_loss: 22.9209\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 231us/sample - loss: 27.7378 - val_loss: 22.6585\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 238us/sample - loss: 27.4125 - val_loss: 22.4407\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 234us/sample - loss: 27.0369 - val_loss: 22.2103\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 230us/sample - loss: 26.6750 - val_loss: 21.9972\n",
      "\n",
      "Forming the grid-search model #1 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f6c08f41350>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7f6c08f84bd0>, epochs=50, batch_size=32\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 651.5171 - val_loss: 618.5244\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 567.6171 - val_loss: 536.0211\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 494.8069 - val_loss: 465.0377\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 431.3828 - val_loss: 402.0129\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 374.1049 - val_loss: 343.6720\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 320.9139 - val_loss: 290.1562\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 136us/sample - loss: 272.9945 - val_loss: 241.7702\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 229.4835 - val_loss: 199.3334\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 139us/sample - loss: 192.3938 - val_loss: 162.7432\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 160.4162 - val_loss: 132.4051\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 134.1962 - val_loss: 108.0452\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 112.7904 - val_loss: 89.2624\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 96.0612 - val_loss: 74.9755\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 82.7802 - val_loss: 64.4169\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 119us/sample - loss: 72.8925 - val_loss: 56.1371\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 134us/sample - loss: 64.5435 - val_loss: 49.7492\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 119us/sample - loss: 57.8195 - val_loss: 44.8525\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 134us/sample - loss: 52.6814 - val_loss: 40.6726\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 135us/sample - loss: 48.1914 - val_loss: 37.3698\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 44.7794 - val_loss: 34.5437\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 41.6589 - val_loss: 32.3070\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 140us/sample - loss: 39.2868 - val_loss: 30.4402\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 37.1406 - val_loss: 29.0243\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 35.5051 - val_loss: 27.7802\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 34.1093 - val_loss: 26.7282\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 32.8292 - val_loss: 25.9084\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 134us/sample - loss: 31.9069 - val_loss: 25.1702\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 31.0436 - val_loss: 24.5609\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 142us/sample - loss: 30.2697 - val_loss: 24.0602\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 29.6720 - val_loss: 23.5919\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 137us/sample - loss: 29.0943 - val_loss: 23.2217\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 28.5340 - val_loss: 22.9001\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 136us/sample - loss: 28.0674 - val_loss: 22.5885\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 27.6186 - val_loss: 22.2915\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 27.2209 - val_loss: 22.0009\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 134us/sample - loss: 26.8387 - val_loss: 21.7337\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 26.4790 - val_loss: 21.4817\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 137us/sample - loss: 26.1475 - val_loss: 21.2590\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 25.7918 - val_loss: 21.0249\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 135us/sample - loss: 25.4775 - val_loss: 20.8173\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 25.1461 - val_loss: 20.5984\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 135us/sample - loss: 24.8527 - val_loss: 20.3864\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 24.5854 - val_loss: 20.2116\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 24.2668 - val_loss: 20.0019\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 136us/sample - loss: 23.9928 - val_loss: 19.7870\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 23.7318 - val_loss: 19.6203\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 23.4405 - val_loss: 19.4345\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 135us/sample - loss: 23.1971 - val_loss: 19.2489\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 135us/sample - loss: 22.9447 - val_loss: 19.0841\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 117us/sample - loss: 22.6648 - val_loss: 18.9227\n",
      "\n",
      "Forming the grid-search model #2 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f6c08f41350>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7f6c08f84bd0>, epochs=50, batch_size=64\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 670.2784 - val_loss: 660.9240\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 623.1192 - val_loss: 608.4590\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 575.2937 - val_loss: 559.9822\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 531.3349 - val_loss: 515.9827\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 491.0553 - val_loss: 475.0543\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 452.7190 - val_loss: 436.7324\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 417.1504 - val_loss: 400.1951\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 88us/sample - loss: 383.0237 - val_loss: 365.3862\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 86us/sample - loss: 351.0584 - val_loss: 332.0813\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 320.6099 - val_loss: 300.3430\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 291.5927 - val_loss: 270.5075\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 264.2977 - val_loss: 242.6559\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 91us/sample - loss: 238.9264 - val_loss: 216.7939\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 214.9582 - val_loss: 193.3049\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 193.9635 - val_loss: 171.6620\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 173.8348 - val_loss: 152.4309\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 88us/sample - loss: 156.2140 - val_loss: 135.3293\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 140.6260 - val_loss: 120.1975\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 126.5872 - val_loss: 107.0464\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 114.4563 - val_loss: 95.6655\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 103.7406 - val_loss: 85.9015\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 94.5845 - val_loss: 77.5136\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 86us/sample - loss: 86.0660 - val_loss: 70.5432\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 79.2382 - val_loss: 64.4927\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 73.0720 - val_loss: 59.3220\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 86us/sample - loss: 67.7189 - val_loss: 54.8532\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 63.2769 - val_loss: 50.9058\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 59.0505 - val_loss: 47.4963\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 55.3609 - val_loss: 44.5112\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 94us/sample - loss: 52.2035 - val_loss: 41.8433\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 49.3023 - val_loss: 39.5265\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 46.7265 - val_loss: 37.4822\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 44.5401 - val_loss: 35.6542\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 42.5513 - val_loss: 34.0210\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 40.7334 - val_loss: 32.5860\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 86us/sample - loss: 39.1320 - val_loss: 31.3293\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 37.7237 - val_loss: 30.2125\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 86us/sample - loss: 36.5225 - val_loss: 29.2139\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 35.3580 - val_loss: 28.3260\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 86us/sample - loss: 34.4608 - val_loss: 27.5134\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 33.5426 - val_loss: 26.7928\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 32.6924 - val_loss: 26.1854\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 91us/sample - loss: 32.0173 - val_loss: 25.6407\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 31.3862 - val_loss: 25.1349\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 30.7720 - val_loss: 24.6866\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 86us/sample - loss: 30.2554 - val_loss: 24.2949\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 29.7509 - val_loss: 23.9308\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 89us/sample - loss: 29.3290 - val_loss: 23.6027\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 28.9626 - val_loss: 23.2946\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 28.5491 - val_loss: 23.0254\n",
      "\n",
      "Forming the grid-search model #3 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f6c08f41350>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7f6c08f415d0>, epochs=50, batch_size=16\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 540.1797 - val_loss: 473.4565\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 233us/sample - loss: 405.4021 - val_loss: 316.6755\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 244us/sample - loss: 273.5788 - val_loss: 192.5788\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 229us/sample - loss: 182.0458 - val_loss: 124.7327\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 239us/sample - loss: 128.6957 - val_loss: 88.0418\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 229us/sample - loss: 93.9491 - val_loss: 65.0242\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 233us/sample - loss: 70.9298 - val_loss: 49.6283\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 236us/sample - loss: 55.7298 - val_loss: 39.8031\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 239us/sample - loss: 45.9456 - val_loss: 33.7920\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 232us/sample - loss: 39.8386 - val_loss: 29.8983\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 236us/sample - loss: 36.1098 - val_loss: 27.3911\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 234us/sample - loss: 33.5359 - val_loss: 26.0813\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 233us/sample - loss: 31.6756 - val_loss: 25.1072\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 246us/sample - loss: 30.3747 - val_loss: 24.4139\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 247us/sample - loss: 29.3434 - val_loss: 23.8126\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 227us/sample - loss: 28.3696 - val_loss: 23.3288\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 235us/sample - loss: 27.6374 - val_loss: 22.8338\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 240us/sample - loss: 26.8328 - val_loss: 22.3842\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 231us/sample - loss: 26.1933 - val_loss: 22.0301\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 231us/sample - loss: 25.6159 - val_loss: 21.6149\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 236us/sample - loss: 24.9609 - val_loss: 21.2748\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 242us/sample - loss: 24.4209 - val_loss: 21.0441\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 234us/sample - loss: 23.9930 - val_loss: 20.6214\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 232us/sample - loss: 23.4860 - val_loss: 20.3164\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 243us/sample - loss: 23.0376 - val_loss: 19.9904\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 237us/sample - loss: 22.5441 - val_loss: 19.7154\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 221us/sample - loss: 22.1263 - val_loss: 19.4131\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 247us/sample - loss: 21.7556 - val_loss: 19.1465\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 240us/sample - loss: 21.3986 - val_loss: 18.8617\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 202us/sample - loss: 21.0335 - val_loss: 18.5998\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 232us/sample - loss: 20.7517 - val_loss: 18.3077\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 231us/sample - loss: 20.3208 - val_loss: 18.0997\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 251us/sample - loss: 19.9833 - val_loss: 17.8661\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 246us/sample - loss: 19.6779 - val_loss: 17.5997\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 227us/sample - loss: 19.3715 - val_loss: 17.3388\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 231us/sample - loss: 19.0844 - val_loss: 17.1096\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 243us/sample - loss: 18.8174 - val_loss: 16.7875\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 238us/sample - loss: 18.5350 - val_loss: 16.6130\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 232us/sample - loss: 18.3318 - val_loss: 16.3497\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 235us/sample - loss: 17.9905 - val_loss: 16.1154\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 234us/sample - loss: 17.6810 - val_loss: 15.8443\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 240us/sample - loss: 17.4590 - val_loss: 15.5944\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 238us/sample - loss: 17.2468 - val_loss: 15.4053\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 278us/sample - loss: 16.9575 - val_loss: 15.2114\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 227us/sample - loss: 16.7530 - val_loss: 14.9845\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 233us/sample - loss: 16.5790 - val_loss: 14.8057\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 16.2654 - val_loss: 14.5998\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 240us/sample - loss: 16.1591 - val_loss: 14.3097\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 235us/sample - loss: 15.8213 - val_loss: 14.1522\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 239us/sample - loss: 15.6462 - val_loss: 13.9624\n",
      "\n",
      "Forming the grid-search model #4 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f6c08f41350>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7f6c08f415d0>, epochs=50, batch_size=32\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 566.3316 - val_loss: 540.5802\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 136us/sample - loss: 501.3522 - val_loss: 459.8638\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 423.6423 - val_loss: 369.0183\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 342.3474 - val_loss: 284.1338\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 270.9430 - val_loss: 213.4474\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 135us/sample - loss: 212.4480 - val_loss: 162.8630\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 170.1129 - val_loss: 128.3253\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 138.9916 - val_loss: 104.1767\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 114.9163 - val_loss: 86.0730\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 95.3360 - val_loss: 71.5195\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 79.9169 - val_loss: 59.8177\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 67.3868 - val_loss: 50.8634\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 57.8044 - val_loss: 43.9939\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 50.3974 - val_loss: 38.9339\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 45.1819 - val_loss: 35.0750\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 41.0603 - val_loss: 32.1772\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 37.9857 - val_loss: 30.0969\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 35.6728 - val_loss: 28.4696\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 33.9131 - val_loss: 27.3190\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 140us/sample - loss: 32.5515 - val_loss: 26.3990\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 31.4000 - val_loss: 25.6660\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 30.4631 - val_loss: 25.1177\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 29.6891 - val_loss: 24.6437\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 28.9766 - val_loss: 24.2104\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 28.3534 - val_loss: 23.7928\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 137us/sample - loss: 27.7277 - val_loss: 23.4585\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 27.2191 - val_loss: 23.1240\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 26.7573 - val_loss: 22.8231\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 134us/sample - loss: 26.2762 - val_loss: 22.5514\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 138us/sample - loss: 25.8541 - val_loss: 22.2734\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 134us/sample - loss: 25.4723 - val_loss: 21.9770\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 25.0262 - val_loss: 21.7552\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 24.6273 - val_loss: 21.5248\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 137us/sample - loss: 24.2801 - val_loss: 21.2912\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 23.9521 - val_loss: 21.0586\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 23.6227 - val_loss: 20.8375\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 23.3211 - val_loss: 20.5931\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 23.0198 - val_loss: 20.4214\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 22.7443 - val_loss: 20.2124\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 147us/sample - loss: 22.4283 - val_loss: 20.0076\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 22.1322 - val_loss: 19.7738\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 21.8721 - val_loss: 19.5544\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 21.6265 - val_loss: 19.3561\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 135us/sample - loss: 21.3277 - val_loss: 19.1506\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 21.0856 - val_loss: 18.9489\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 20.8691 - val_loss: 18.7646\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 20.5922 - val_loss: 18.5843\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 20.4059 - val_loss: 18.3550\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 20.1348 - val_loss: 18.1530\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 137us/sample - loss: 19.8970 - val_loss: 17.9744\n",
      "\n",
      "Forming the grid-search model #5 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f6c08f41350>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7f6c08f415d0>, epochs=50, batch_size=64\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 579.0744 - val_loss: 572.8818\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 550.5308 - val_loss: 537.6990\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 516.0306 - val_loss: 496.7762\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 476.9806 - val_loss: 451.7129\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 435.5474 - val_loss: 404.2666\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 391.9073 - val_loss: 356.5398\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 349.4286 - val_loss: 310.2411\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 308.3930 - val_loss: 267.6083\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 271.8193 - val_loss: 229.8295\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 239.0296 - val_loss: 197.9182\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 211.1396 - val_loss: 171.8062\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 187.3193 - val_loss: 150.8640\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 167.6051 - val_loss: 133.8336\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 150.5139 - val_loss: 119.8562\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 136.5240 - val_loss: 107.8437\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 123.2090 - val_loss: 97.5271\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 111.5214 - val_loss: 88.4954\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 88us/sample - loss: 101.5808 - val_loss: 80.3127\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 92.0529 - val_loss: 73.1657\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 84.2531 - val_loss: 66.6229\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 76.8088 - val_loss: 60.9149\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 70.5573 - val_loss: 55.8614\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 64.6717 - val_loss: 51.5404\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 59.8860 - val_loss: 47.7599\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 55.7049 - val_loss: 44.4536\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 51.9336 - val_loss: 41.6519\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 49.0495 - val_loss: 39.1543\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 46.3005 - val_loss: 37.0551\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 43.9490 - val_loss: 35.2544\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 42.0180 - val_loss: 33.6774\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 40.2986 - val_loss: 32.3190\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 38.7426 - val_loss: 31.1787\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 37.4994 - val_loss: 30.1801\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 36.3456 - val_loss: 29.3399\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 91us/sample - loss: 35.3525 - val_loss: 28.6090\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 34.4867 - val_loss: 27.9648\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 33.6784 - val_loss: 27.4056\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 33.0384 - val_loss: 26.9092\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 32.3090 - val_loss: 26.4817\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 31.7748 - val_loss: 26.0809\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 31.2110 - val_loss: 25.7151\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 86us/sample - loss: 30.6933 - val_loss: 25.3943\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 89us/sample - loss: 30.2423 - val_loss: 25.0980\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 29.7787 - val_loss: 24.8194\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 29.3484 - val_loss: 24.5580\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 28.9621 - val_loss: 24.3236\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 28.5582 - val_loss: 24.0979\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 72us/sample - loss: 28.2118 - val_loss: 23.8700\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 27.8907 - val_loss: 23.6422\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 89us/sample - loss: 27.5291 - val_loss: 23.4428\n",
      "\n",
      "Forming the grid-search model #6 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f6c08f41350>, kernel=<tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7f6c08f41550>, epochs=50, batch_size=16\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 570.8983 - val_loss: 536.1458\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 237us/sample - loss: 446.0606 - val_loss: 349.6538\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 239us/sample - loss: 267.8414 - val_loss: 182.4627\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 233us/sample - loss: 149.4694 - val_loss: 95.3061\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 234us/sample - loss: 91.9953 - val_loss: 60.6296\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 237us/sample - loss: 64.4973 - val_loss: 45.2145\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 227us/sample - loss: 49.9171 - val_loss: 36.2738\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 241us/sample - loss: 41.4213 - val_loss: 31.3896\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 214us/sample - loss: 36.3897 - val_loss: 28.4437\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 231us/sample - loss: 33.3989 - val_loss: 26.5500\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 238us/sample - loss: 31.5736 - val_loss: 25.4609\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 242us/sample - loss: 30.2454 - val_loss: 24.6785\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 231us/sample - loss: 29.2312 - val_loss: 24.0861\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 236us/sample - loss: 28.4464 - val_loss: 23.6906\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 233us/sample - loss: 27.8809 - val_loss: 23.3090\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 27.3325 - val_loss: 22.9670\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 218us/sample - loss: 26.8908 - val_loss: 22.6873\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 236us/sample - loss: 26.4641 - val_loss: 22.4667\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 232us/sample - loss: 26.0919 - val_loss: 22.3644\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 234us/sample - loss: 25.8122 - val_loss: 22.1352\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 263us/sample - loss: 25.4198 - val_loss: 21.9355\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 25.1646 - val_loss: 21.7891\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 235us/sample - loss: 24.9932 - val_loss: 21.5961\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 239us/sample - loss: 24.7197 - val_loss: 21.4959\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 248us/sample - loss: 24.5074 - val_loss: 21.3126\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 228us/sample - loss: 24.1833 - val_loss: 21.1666\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 229us/sample - loss: 23.9418 - val_loss: 21.0660\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 250us/sample - loss: 23.7304 - val_loss: 20.8873\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 235us/sample - loss: 23.5641 - val_loss: 20.6959\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 246us/sample - loss: 23.3274 - val_loss: 20.5760\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 241us/sample - loss: 23.2049 - val_loss: 20.4251\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 252us/sample - loss: 22.8922 - val_loss: 20.2554\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 235us/sample - loss: 22.6965 - val_loss: 20.1435\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 231us/sample - loss: 22.5047 - val_loss: 19.9993\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 236us/sample - loss: 22.3327 - val_loss: 19.7834\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 235us/sample - loss: 22.1655 - val_loss: 19.6779\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 236us/sample - loss: 22.0107 - val_loss: 19.4884\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 227us/sample - loss: 21.8606 - val_loss: 19.3686\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 242us/sample - loss: 21.7604 - val_loss: 19.1939\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 238us/sample - loss: 21.4851 - val_loss: 19.0720\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 241us/sample - loss: 21.2276 - val_loss: 18.9184\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 21.1010 - val_loss: 18.7710\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 243us/sample - loss: 20.9598 - val_loss: 18.5937\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 231us/sample - loss: 20.7193 - val_loss: 18.4368\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 236us/sample - loss: 20.5486 - val_loss: 18.2757\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 236us/sample - loss: 20.4478 - val_loss: 18.1027\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 233us/sample - loss: 20.2023 - val_loss: 17.9870\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 241us/sample - loss: 20.1299 - val_loss: 17.8781\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 243us/sample - loss: 19.8609 - val_loss: 17.7159\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 242us/sample - loss: 19.7389 - val_loss: 17.5177\n",
      "\n",
      "Forming the grid-search model #7 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f6c08f41350>, kernel=<tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7f6c08f41550>, epochs=50, batch_size=32\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 584.5358 - val_loss: 586.2405\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 135us/sample - loss: 553.8779 - val_loss: 532.5332\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 483.2883 - val_loss: 440.8889\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 388.5210 - val_loss: 339.1551\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 296.7505 - val_loss: 248.5708\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 219.9652 - val_loss: 176.4841\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 139us/sample - loss: 161.0180 - val_loss: 124.3735\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 119.3980 - val_loss: 90.3298\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 92.3242 - val_loss: 69.6536\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 136us/sample - loss: 74.1358 - val_loss: 56.6301\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 62.2419 - val_loss: 47.5386\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 53.1055 - val_loss: 41.0857\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 46.3934 - val_loss: 36.4407\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 41.6024 - val_loss: 33.1174\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 38.1460 - val_loss: 30.6267\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 135us/sample - loss: 35.4848 - val_loss: 28.7450\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 33.5343 - val_loss: 27.3388\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 32.0324 - val_loss: 26.2848\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 30.8974 - val_loss: 25.5265\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 138us/sample - loss: 30.0198 - val_loss: 24.8440\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 134us/sample - loss: 29.2229 - val_loss: 24.3022\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 140us/sample - loss: 28.6358 - val_loss: 23.8468\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 141us/sample - loss: 28.1446 - val_loss: 23.4921\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 27.6475 - val_loss: 23.2174\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 134us/sample - loss: 27.2968 - val_loss: 22.9188\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 135us/sample - loss: 26.8688 - val_loss: 22.6781\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 135us/sample - loss: 26.5499 - val_loss: 22.4993\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 134us/sample - loss: 26.2909 - val_loss: 22.3077\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 136us/sample - loss: 26.0341 - val_loss: 22.1203\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 25.7916 - val_loss: 21.9829\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 143us/sample - loss: 25.5945 - val_loss: 21.8356\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 137us/sample - loss: 25.3194 - val_loss: 21.7140\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 25.1000 - val_loss: 21.6136\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 136us/sample - loss: 24.9091 - val_loss: 21.5127\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 24.7551 - val_loss: 21.3766\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 135us/sample - loss: 24.5879 - val_loss: 21.2868\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 137us/sample - loss: 24.4446 - val_loss: 21.1652\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 142us/sample - loss: 24.2819 - val_loss: 21.0690\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 24.1786 - val_loss: 20.9679\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 136us/sample - loss: 23.9671 - val_loss: 20.8871\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 137us/sample - loss: 23.8013 - val_loss: 20.7904\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 23.6667 - val_loss: 20.7044\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 23.5552 - val_loss: 20.6112\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 23.3777 - val_loss: 20.5113\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 23.2299 - val_loss: 20.4271\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 23.1507 - val_loss: 20.3197\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 142us/sample - loss: 22.9839 - val_loss: 20.2387\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 22.8819 - val_loss: 20.1824\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 135us/sample - loss: 22.7276 - val_loss: 20.1150\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 22.5972 - val_loss: 19.9954\n",
      "\n",
      "Forming the grid-search model #8 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f6c08f41350>, kernel=<tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7f6c08f41550>, epochs=50, batch_size=64\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 587.8696 - val_loss: 597.7522\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 580.8099 - val_loss: 586.2391\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 565.4898 - val_loss: 564.4380\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 539.3782 - val_loss: 531.0424\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 502.2280 - val_loss: 487.7507\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 456.6240 - val_loss: 437.8463\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 407.4894 - val_loss: 385.6263\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 101us/sample - loss: 357.7878 - val_loss: 334.6150\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 311.4523 - val_loss: 286.7482\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 268.9748 - val_loss: 242.7443\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 230.6730 - val_loss: 203.3959\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 196.4087 - val_loss: 169.2069\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 166.7921 - val_loss: 140.4791\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 141.4593 - val_loss: 117.3983\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 121.8893 - val_loss: 99.0138\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 88us/sample - loss: 105.3411 - val_loss: 84.7997\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 92.0529 - val_loss: 73.9631\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 81.9877 - val_loss: 65.2970\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 73.4284 - val_loss: 58.4120\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 66.4418 - val_loss: 52.7377\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 88us/sample - loss: 60.4533 - val_loss: 48.0489\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 86us/sample - loss: 55.5436 - val_loss: 44.0633\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 50.9057 - val_loss: 40.8551\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 47.3815 - val_loss: 38.1125\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 44.3250 - val_loss: 35.7802\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 86us/sample - loss: 41.6720 - val_loss: 33.8324\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 39.6298 - val_loss: 32.1639\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 37.8056 - val_loss: 30.7426\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 96us/sample - loss: 36.1720 - val_loss: 29.5680\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 34.9393 - val_loss: 28.5628\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 33.7950 - val_loss: 27.7094\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 93us/sample - loss: 32.7817 - val_loss: 27.0005\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 31.9999 - val_loss: 26.3856\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 94us/sample - loss: 31.2748 - val_loss: 25.8626\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 30.6858 - val_loss: 25.3917\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 89us/sample - loss: 30.1477 - val_loss: 24.9837\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 86us/sample - loss: 29.6560 - val_loss: 24.6335\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 90us/sample - loss: 29.2785 - val_loss: 24.3104\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 28.8747 - val_loss: 24.0310\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 86us/sample - loss: 28.5366 - val_loss: 23.7778\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 28.2085 - val_loss: 23.5507\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 27.9241 - val_loss: 23.3551\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 27.6804 - val_loss: 23.1757\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 27.4353 - val_loss: 23.0049\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 27.1861 - val_loss: 22.8640\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 27.0069 - val_loss: 22.7137\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 88us/sample - loss: 26.7878 - val_loss: 22.5853\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 86us/sample - loss: 26.6063 - val_loss: 22.4705\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 86us/sample - loss: 26.4428 - val_loss: 22.3557\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 26.2618 - val_loss: 22.2343\n",
      "\n",
      "Forming the grid-search model #9 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f6c08f41390>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7f6c08f84bd0>, epochs=50, batch_size=16\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 659.8093 - val_loss: 657.6788\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 218us/sample - loss: 625.2044 - val_loss: 624.7565\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 193us/sample - loss: 594.8994 - val_loss: 592.9017\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 216us/sample - loss: 565.8528 - val_loss: 562.8585\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 202us/sample - loss: 538.3119 - val_loss: 533.8398\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 216us/sample - loss: 510.7855 - val_loss: 504.7417\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 483.9616 - val_loss: 477.0157\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 229us/sample - loss: 457.5760 - val_loss: 448.7111\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 202us/sample - loss: 430.8523 - val_loss: 420.2520\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 253us/sample - loss: 403.7922 - val_loss: 391.4924\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 376.4127 - val_loss: 362.5431\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 206us/sample - loss: 349.1928 - val_loss: 332.7513\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 208us/sample - loss: 321.7064 - val_loss: 303.5497\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 229us/sample - loss: 293.9935 - val_loss: 273.4312\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 229us/sample - loss: 266.9678 - val_loss: 245.0589\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 239.7843 - val_loss: 216.5062\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 239us/sample - loss: 213.7567 - val_loss: 188.9773\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 232us/sample - loss: 188.7652 - val_loss: 163.4135\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 236us/sample - loss: 165.6515 - val_loss: 140.2582\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 229us/sample - loss: 145.2177 - val_loss: 120.1389\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 126.6436 - val_loss: 102.0417\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 227us/sample - loss: 110.2242 - val_loss: 86.7194\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 95.3839 - val_loss: 73.2643\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 224us/sample - loss: 83.0100 - val_loss: 62.3625\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 72.1860 - val_loss: 53.6075\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 218us/sample - loss: 63.3574 - val_loss: 46.8573\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 215us/sample - loss: 56.4909 - val_loss: 41.6795\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 222us/sample - loss: 50.9777 - val_loss: 37.7037\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 227us/sample - loss: 46.3863 - val_loss: 34.4880\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 192us/sample - loss: 42.8293 - val_loss: 31.9798\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 217us/sample - loss: 39.8681 - val_loss: 29.9454\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 37.4170 - val_loss: 28.1825\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 224us/sample - loss: 35.4655 - val_loss: 26.8903\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 217us/sample - loss: 33.8878 - val_loss: 25.8161\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 216us/sample - loss: 32.5774 - val_loss: 24.9368\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 221us/sample - loss: 31.5935 - val_loss: 24.3001\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 30.7062 - val_loss: 23.7457\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 229us/sample - loss: 29.9604 - val_loss: 23.2050\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 29.2716 - val_loss: 22.6671\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 245us/sample - loss: 28.5851 - val_loss: 22.1767\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 207us/sample - loss: 27.9551 - val_loss: 21.7265\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 227us/sample - loss: 27.2933 - val_loss: 21.2688\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 229us/sample - loss: 26.6879 - val_loss: 20.8562\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 245us/sample - loss: 26.1066 - val_loss: 20.4538\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 217us/sample - loss: 25.5613 - val_loss: 20.0494\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 24.9712 - val_loss: 19.6252\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 218us/sample - loss: 24.4137 - val_loss: 19.2275\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 227us/sample - loss: 23.8713 - val_loss: 18.8992\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 189us/sample - loss: 23.4090 - val_loss: 18.6194\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 220us/sample - loss: 22.9443 - val_loss: 18.2867\n",
      "\n",
      "Forming the grid-search model #10 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f6c08f41390>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7f6c08f84bd0>, epochs=50, batch_size=32\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 669.6863 - val_loss: 674.8987\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 117us/sample - loss: 647.5907 - val_loss: 655.1220\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 629.8913 - val_loss: 637.2263\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 122us/sample - loss: 613.4086 - val_loss: 619.9411\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 597.5997 - val_loss: 603.2651\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 582.1033 - val_loss: 586.8512\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 566.9209 - val_loss: 570.7955\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 551.8848 - val_loss: 555.0372\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 537.1706 - val_loss: 539.4767\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 522.4823 - val_loss: 524.2197\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 507.9536 - val_loss: 508.9563\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 493.6023 - val_loss: 493.7411\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 113us/sample - loss: 479.3455 - val_loss: 478.8458\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 465.1171 - val_loss: 463.5731\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 450.8817 - val_loss: 448.7800\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 436.5752 - val_loss: 433.4577\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 422.1777 - val_loss: 418.1389\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 407.7893 - val_loss: 402.9573\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 393.4488 - val_loss: 387.6806\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 379.0862 - val_loss: 372.2726\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 364.5385 - val_loss: 356.8175\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 350.1013 - val_loss: 341.2410\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 335.4418 - val_loss: 325.5368\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 122us/sample - loss: 321.0149 - val_loss: 310.2621\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 306.4914 - val_loss: 294.4614\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 291.7592 - val_loss: 278.9001\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 277.4409 - val_loss: 263.6882\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 263.2706 - val_loss: 248.6149\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 249.1176 - val_loss: 233.6646\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 119us/sample - loss: 235.2423 - val_loss: 218.8808\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 221.5910 - val_loss: 204.6951\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 208.3020 - val_loss: 190.7403\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 195.4944 - val_loss: 177.4705\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 122us/sample - loss: 183.0783 - val_loss: 164.4125\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 170.9154 - val_loss: 151.6930\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 159.1441 - val_loss: 139.6526\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 147.8818 - val_loss: 128.2595\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 137.1323 - val_loss: 117.5139\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 127.2336 - val_loss: 107.8788\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 118.1393 - val_loss: 98.8723\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 109.5758 - val_loss: 90.6137\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 101.3368 - val_loss: 82.8117\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 93.8308 - val_loss: 76.0056\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 86.9732 - val_loss: 69.6827\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 80.7159 - val_loss: 64.2487\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 74.9428 - val_loss: 59.1049\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 69.4673 - val_loss: 54.3979\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 64.5600 - val_loss: 50.4897\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 60.4482 - val_loss: 47.1619\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 56.6937 - val_loss: 44.0869\n",
      "\n",
      "Forming the grid-search model #11 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f6c08f41390>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7f6c08f84bd0>, epochs=50, batch_size=64\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 676.1284 - val_loss: 685.8295\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 661.5309 - val_loss: 673.4554\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 74us/sample - loss: 650.7307 - val_loss: 662.8264\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 641.0813 - val_loss: 652.9231\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 632.0800 - val_loss: 643.5566\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 623.3286 - val_loss: 634.4176\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 614.8733 - val_loss: 625.4308\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 606.4920 - val_loss: 616.5104\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 598.3328 - val_loss: 607.7567\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 590.2267 - val_loss: 599.1897\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 582.2487 - val_loss: 590.6923\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 574.3732 - val_loss: 582.2420\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 69us/sample - loss: 566.4653 - val_loss: 573.8862\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 558.6234 - val_loss: 565.4963\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 550.8061 - val_loss: 557.3027\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 543.0458 - val_loss: 549.0493\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 535.3148 - val_loss: 540.9117\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 527.6076 - val_loss: 532.8502\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 519.9784 - val_loss: 524.8215\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 512.3887 - val_loss: 516.8077\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 504.7937 - val_loss: 508.8256\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 497.3222 - val_loss: 500.9230\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 489.8134 - val_loss: 493.0068\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 482.4174 - val_loss: 485.2557\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 475.0115 - val_loss: 477.3833\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 467.5593 - val_loss: 469.5739\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 460.1747 - val_loss: 461.7609\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 452.7812 - val_loss: 453.9354\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 445.3457 - val_loss: 446.0753\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 437.8865 - val_loss: 438.1330\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 430.3855 - val_loss: 430.2103\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 422.9065 - val_loss: 422.2735\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 415.4726 - val_loss: 414.4655\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 408.0351 - val_loss: 406.5117\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 400.5352 - val_loss: 398.5214\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 393.0035 - val_loss: 390.5283\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 385.4154 - val_loss: 382.4164\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 377.8044 - val_loss: 374.3453\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 370.2236 - val_loss: 366.3348\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 362.7279 - val_loss: 358.3153\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 355.2195 - val_loss: 350.2347\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 347.6451 - val_loss: 342.1748\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 340.1155 - val_loss: 334.1738\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 332.5952 - val_loss: 326.0838\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 325.0626 - val_loss: 318.1346\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 317.5573 - val_loss: 310.1032\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 309.9338 - val_loss: 301.8792\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 302.3172 - val_loss: 293.8177\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 294.8348 - val_loss: 285.9003\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 287.3697 - val_loss: 277.8450\n",
      "\n",
      "Forming the grid-search model #12 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f6c08f41390>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7f6c08f415d0>, epochs=50, batch_size=16\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 574.0782 - val_loss: 572.2619\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 215us/sample - loss: 553.8431 - val_loss: 551.0908\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 218us/sample - loss: 533.8259 - val_loss: 528.6200\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 226us/sample - loss: 512.5762 - val_loss: 504.8110\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 226us/sample - loss: 490.6243 - val_loss: 479.6405\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 238us/sample - loss: 466.7743 - val_loss: 452.4653\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 224us/sample - loss: 442.0299 - val_loss: 424.6118\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 218us/sample - loss: 415.8339 - val_loss: 394.7291\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 220us/sample - loss: 388.5281 - val_loss: 364.0717\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 227us/sample - loss: 360.1709 - val_loss: 332.6819\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 228us/sample - loss: 331.2530 - val_loss: 301.4352\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 221us/sample - loss: 302.6306 - val_loss: 269.9091\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 274.1252 - val_loss: 240.1071\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 246.2017 - val_loss: 210.9022\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 228us/sample - loss: 220.1787 - val_loss: 185.0271\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 220us/sample - loss: 194.8637 - val_loss: 160.5084\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 220us/sample - loss: 171.4100 - val_loss: 137.9577\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 226us/sample - loss: 149.9466 - val_loss: 118.8106\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 228us/sample - loss: 130.5395 - val_loss: 101.7390\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 189us/sample - loss: 114.1854 - val_loss: 88.6012\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 186us/sample - loss: 99.8630 - val_loss: 76.7042\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 218us/sample - loss: 87.4261 - val_loss: 66.6907\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 220us/sample - loss: 76.1842 - val_loss: 57.9466\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 231us/sample - loss: 67.0738 - val_loss: 50.7972\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 220us/sample - loss: 59.3251 - val_loss: 44.9716\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 222us/sample - loss: 52.8691 - val_loss: 39.9895\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 47.6747 - val_loss: 35.9742\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 222us/sample - loss: 43.6250 - val_loss: 32.8427\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 40.3249 - val_loss: 30.3938\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 221us/sample - loss: 37.7405 - val_loss: 28.5194\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 222us/sample - loss: 35.6855 - val_loss: 27.1221\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 221us/sample - loss: 33.9565 - val_loss: 25.8830\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 32.5365 - val_loss: 24.9816\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 232us/sample - loss: 31.3541 - val_loss: 24.2784\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 226us/sample - loss: 30.3310 - val_loss: 23.6534\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 198us/sample - loss: 29.5565 - val_loss: 23.2138\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 28.7829 - val_loss: 22.8464\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 28.0921 - val_loss: 22.3916\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 221us/sample - loss: 27.4940 - val_loss: 21.9951\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 226us/sample - loss: 26.8356 - val_loss: 21.5702\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 227us/sample - loss: 26.2745 - val_loss: 21.2697\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 217us/sample - loss: 25.6796 - val_loss: 20.9736\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 232us/sample - loss: 25.1466 - val_loss: 20.7268\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 229us/sample - loss: 24.6637 - val_loss: 20.4326\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 24.2251 - val_loss: 20.1485\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 23.7142 - val_loss: 19.8374\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 230us/sample - loss: 23.2768 - val_loss: 19.4616\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 226us/sample - loss: 22.8101 - val_loss: 19.3359\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 22.4800 - val_loss: 19.1245\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 195us/sample - loss: 22.1182 - val_loss: 18.8369\n",
      "\n",
      "Forming the grid-search model #13 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f6c08f41390>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7f6c08f415d0>, epochs=50, batch_size=32\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 579.4352 - val_loss: 582.2223\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 120us/sample - loss: 567.3287 - val_loss: 570.8131\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 556.9352 - val_loss: 559.6353\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 119us/sample - loss: 546.4682 - val_loss: 548.0694\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 535.7646 - val_loss: 536.3269\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 524.7653 - val_loss: 524.1855\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 513.5371 - val_loss: 511.6298\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 501.8635 - val_loss: 498.6942\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 489.9766 - val_loss: 485.3477\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 477.6151 - val_loss: 471.7097\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 464.9013 - val_loss: 457.3078\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 120us/sample - loss: 451.7724 - val_loss: 442.4591\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 438.2687 - val_loss: 427.5239\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 424.4636 - val_loss: 411.6859\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 410.2959 - val_loss: 396.1532\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 395.8641 - val_loss: 379.8432\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 122us/sample - loss: 381.1219 - val_loss: 363.3832\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 366.2217 - val_loss: 346.9259\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 351.2323 - val_loss: 330.4981\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 336.2389 - val_loss: 313.9735\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 321.0815 - val_loss: 297.6571\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 306.1229 - val_loss: 281.4127\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 134us/sample - loss: 291.0238 - val_loss: 265.2417\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 276.2662 - val_loss: 249.7881\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 261.5505 - val_loss: 234.0887\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 246.8761 - val_loss: 219.1964\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 232.9528 - val_loss: 204.9425\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 219.3861 - val_loss: 191.1878\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 206.0757 - val_loss: 178.0289\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 119us/sample - loss: 193.2665 - val_loss: 165.3379\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 180.9257 - val_loss: 153.5076\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 169.0646 - val_loss: 142.1601\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 157.7609 - val_loss: 131.6760\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 122us/sample - loss: 147.1296 - val_loss: 121.9278\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 136.8779 - val_loss: 112.4298\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 126.8727 - val_loss: 103.4955\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 117.6348 - val_loss: 95.6726\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 109.1342 - val_loss: 88.3989\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 101.2642 - val_loss: 81.8069\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 94.0811 - val_loss: 75.8375\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 87.5207 - val_loss: 70.4781\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 81.3067 - val_loss: 65.4020\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 75.6914 - val_loss: 60.9728\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 70.7172 - val_loss: 56.9273\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 66.0010 - val_loss: 53.0241\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 122us/sample - loss: 61.6203 - val_loss: 49.4625\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 57.5179 - val_loss: 46.0580\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 53.8080 - val_loss: 43.0373\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 50.6937 - val_loss: 40.5047\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 47.8611 - val_loss: 38.0911\n",
      "\n",
      "Forming the grid-search model #14 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f6c08f41390>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7f6c08f415d0>, epochs=50, batch_size=64\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 582.8632 - val_loss: 588.1273\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 575.0232 - val_loss: 581.3508\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 569.0154 - val_loss: 575.3212\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 563.4980 - val_loss: 569.4106\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 74us/sample - loss: 558.1042 - val_loss: 563.5711\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 552.6353 - val_loss: 557.6197\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 547.1293 - val_loss: 551.6353\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 541.5436 - val_loss: 545.5473\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 535.9483 - val_loss: 539.4130\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 530.2785 - val_loss: 533.2802\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 524.5833 - val_loss: 527.0070\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 518.8166 - val_loss: 520.5770\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 512.8882 - val_loss: 514.0418\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 506.8666 - val_loss: 507.2845\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 500.7039 - val_loss: 500.5414\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 494.4735 - val_loss: 493.5805\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 488.1417 - val_loss: 486.5487\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 481.6945 - val_loss: 479.3513\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 475.1453 - val_loss: 472.0484\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 468.4861 - val_loss: 464.5545\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 461.6447 - val_loss: 456.9713\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 454.8100 - val_loss: 449.3230\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 447.8603 - val_loss: 441.5242\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 440.9243 - val_loss: 433.8049\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 433.8794 - val_loss: 425.8327\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 86us/sample - loss: 426.7081 - val_loss: 417.8753\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 419.5299 - val_loss: 409.8191\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 412.2466 - val_loss: 401.6796\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 404.8728 - val_loss: 393.4385\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 397.4265 - val_loss: 385.0791\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 389.8742 - val_loss: 376.6763\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 382.2890 - val_loss: 368.2646\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 374.7218 - val_loss: 359.9556\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 367.1036 - val_loss: 351.4765\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 359.3920 - val_loss: 342.9581\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 351.6244 - val_loss: 334.4586\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 343.7998 - val_loss: 325.8543\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 335.9191 - val_loss: 317.2872\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 328.0938 - val_loss: 308.8663\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 320.3702 - val_loss: 300.4711\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 312.6612 - val_loss: 292.1029\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 304.9017 - val_loss: 283.7621\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 297.2008 - val_loss: 275.5831\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 289.5620 - val_loss: 267.3446\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 281.9537 - val_loss: 259.4059\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 274.4164 - val_loss: 251.4037\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 266.7893 - val_loss: 243.3269\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 259.2404 - val_loss: 235.5330\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 251.8638 - val_loss: 227.9333\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 244.5600 - val_loss: 220.2955\n",
      "\n",
      "Forming the grid-search model #15 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f6c08f41390>, kernel=<tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7f6c08f41550>, epochs=50, batch_size=16\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 586.4425 - val_loss: 596.1640\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 579.4390 - val_loss: 586.3900\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 222us/sample - loss: 568.4597 - val_loss: 571.8674\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 220us/sample - loss: 553.2469 - val_loss: 553.1188\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 227us/sample - loss: 534.5017 - val_loss: 529.9979\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 511.5054 - val_loss: 502.7509\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 224us/sample - loss: 485.9660 - val_loss: 473.3720\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 457.5339 - val_loss: 440.5270\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 220us/sample - loss: 426.9863 - val_loss: 406.1129\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 229us/sample - loss: 394.5722 - val_loss: 370.3043\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 361.1419 - val_loss: 334.1522\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 213us/sample - loss: 327.7253 - val_loss: 297.3628\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 226us/sample - loss: 294.4371 - val_loss: 262.4105\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 221us/sample - loss: 261.7530 - val_loss: 228.0130\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 231.4964 - val_loss: 197.8030\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 221us/sample - loss: 202.7020 - val_loss: 169.6982\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 215us/sample - loss: 176.6162 - val_loss: 144.5373\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 224us/sample - loss: 153.3391 - val_loss: 123.7115\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 132.9561 - val_loss: 105.9581\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 212us/sample - loss: 116.4249 - val_loss: 92.9058\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 198us/sample - loss: 102.3420 - val_loss: 81.3767\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 90.5327 - val_loss: 72.1984\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 196us/sample - loss: 80.0295 - val_loss: 64.2382\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 215us/sample - loss: 71.6708 - val_loss: 57.8041\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 229us/sample - loss: 64.5727 - val_loss: 52.5548\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 222us/sample - loss: 58.6420 - val_loss: 47.9537\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 222us/sample - loss: 53.7357 - val_loss: 43.8061\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 49.6945 - val_loss: 40.4841\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 46.3976 - val_loss: 37.7070\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 43.7551 - val_loss: 35.5215\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 220us/sample - loss: 41.5435 - val_loss: 33.6592\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 232us/sample - loss: 39.7419 - val_loss: 32.1874\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 222us/sample - loss: 38.2943 - val_loss: 30.9215\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 203us/sample - loss: 37.1438 - val_loss: 29.8199\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 233us/sample - loss: 36.1955 - val_loss: 29.0509\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 226us/sample - loss: 35.5593 - val_loss: 28.4570\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 220us/sample - loss: 34.8868 - val_loss: 27.9090\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 224us/sample - loss: 34.3161 - val_loss: 27.4730\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 224us/sample - loss: 33.7801 - val_loss: 26.9509\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 33.2121 - val_loss: 26.5916\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 221us/sample - loss: 32.7439 - val_loss: 26.1594\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 222us/sample - loss: 32.2008 - val_loss: 25.6947\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 31.7249 - val_loss: 25.3507\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 31.2938 - val_loss: 25.0182\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 230us/sample - loss: 30.9105 - val_loss: 24.6527\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 229us/sample - loss: 30.4377 - val_loss: 24.3305\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 30.0101 - val_loss: 24.0112\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 227us/sample - loss: 29.5831 - val_loss: 23.5875\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 244us/sample - loss: 29.2277 - val_loss: 23.3347\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 231us/sample - loss: 28.8931 - val_loss: 23.0706\n",
      "\n",
      "Forming the grid-search model #16 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f6c08f41390>, kernel=<tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7f6c08f41550>, epochs=50, batch_size=32\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 587.8084 - val_loss: 599.2663\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 584.7991 - val_loss: 595.9262\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 119us/sample - loss: 581.2171 - val_loss: 591.3675\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 120us/sample - loss: 576.3448 - val_loss: 585.3250\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 122us/sample - loss: 570.3865 - val_loss: 578.2264\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 133us/sample - loss: 563.3557 - val_loss: 569.9570\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 555.3451 - val_loss: 560.4924\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 546.1523 - val_loss: 549.8998\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 536.0852 - val_loss: 538.3334\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 525.0267 - val_loss: 525.9123\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 513.1224 - val_loss: 512.4270\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 500.4140 - val_loss: 497.9895\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 486.9467 - val_loss: 483.1221\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 472.8335 - val_loss: 467.1029\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 458.0404 - val_loss: 451.0045\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 442.6711 - val_loss: 433.8013\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 426.7563 - val_loss: 416.2897\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 410.5224 - val_loss: 398.5513\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 394.0358 - val_loss: 380.6358\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 377.3848 - val_loss: 362.4071\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 122us/sample - loss: 360.4113 - val_loss: 344.1457\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 343.4635 - val_loss: 325.7768\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 326.3383 - val_loss: 307.4282\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 309.5625 - val_loss: 289.7111\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 292.8277 - val_loss: 271.6583\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 276.0737 - val_loss: 254.2734\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 260.0821 - val_loss: 237.5883\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 244.5161 - val_loss: 221.3971\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 229.2523 - val_loss: 205.8163\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 214.6131 - val_loss: 190.8024\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 200.5699 - val_loss: 176.8526\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 187.1974 - val_loss: 163.5384\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 174.5789 - val_loss: 151.3642\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 162.7715 - val_loss: 140.0501\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 151.4694 - val_loss: 129.1714\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 140.5681 - val_loss: 119.0315\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 130.4705 - val_loss: 110.0834\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 121.1549 - val_loss: 101.7852\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 177us/sample - loss: 112.7042 - val_loss: 94.5214\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 105.1161 - val_loss: 88.0092\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 98.2316 - val_loss: 82.3042\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 116us/sample - loss: 91.7445 - val_loss: 76.9841\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 86.0319 - val_loss: 72.5284\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 81.0859 - val_loss: 68.5903\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 119us/sample - loss: 76.5226 - val_loss: 64.8704\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 72.2412 - val_loss: 61.4392\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 68.2003 - val_loss: 58.1924\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 122us/sample - loss: 64.5007 - val_loss: 55.2429\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 61.3714 - val_loss: 52.7467\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 148us/sample - loss: 58.4770 - val_loss: 50.2734\n",
      "\n",
      "Forming the grid-search model #17 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f6c08f41390>, kernel=<tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7f6c08f41550>, epochs=50, batch_size=64\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 588.5658 - val_loss: 600.7031\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 586.9145 - val_loss: 599.1607\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 585.4215 - val_loss: 597.5017\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 583.7519 - val_loss: 595.5640\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 581.8435 - val_loss: 593.3558\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 579.6212 - val_loss: 590.7766\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 74us/sample - loss: 577.0874 - val_loss: 587.8464\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 574.2286 - val_loss: 584.5880\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 571.1246 - val_loss: 581.0644\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 567.7607 - val_loss: 577.2982\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 98us/sample - loss: 564.1624 - val_loss: 573.2337\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 560.3174 - val_loss: 568.8854\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 556.2098 - val_loss: 564.3004\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 551.8662 - val_loss: 559.3403\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 547.2135 - val_loss: 554.1737\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 542.3261 - val_loss: 548.6472\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 537.1788 - val_loss: 542.9340\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 531.8006 - val_loss: 536.9396\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 526.1724 - val_loss: 530.7082\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 520.3123 - val_loss: 524.1675\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 514.1890 - val_loss: 517.4295\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 507.9158 - val_loss: 510.5044\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 501.4256 - val_loss: 503.3670\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 91us/sample - loss: 494.8235 - val_loss: 496.1553\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 488.0172 - val_loss: 488.6130\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 480.9687 - val_loss: 480.9346\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 473.8188 - val_loss: 473.0922\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 466.4911 - val_loss: 465.0757\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 458.9786 - val_loss: 456.8658\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 451.3114 - val_loss: 448.4412\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 74us/sample - loss: 443.4686 - val_loss: 439.9222\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 435.5454 - val_loss: 431.2919\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 427.5621 - val_loss: 422.6850\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 69us/sample - loss: 419.4751 - val_loss: 413.8333\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 71us/sample - loss: 411.2407 - val_loss: 404.8821\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 402.9227 - val_loss: 395.9022\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 394.4932 - val_loss: 386.7278\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 385.9702 - val_loss: 377.5486\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 377.4582 - val_loss: 368.4281\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 368.9881 - val_loss: 359.2730\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 360.4860 - val_loss: 350.0736\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 351.9183 - val_loss: 340.8897\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 343.4071 - val_loss: 331.7901\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 334.9223 - val_loss: 322.6051\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 326.4300 - val_loss: 313.6158\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 317.9780 - val_loss: 304.5511\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 309.4254 - val_loss: 295.3181\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 96us/sample - loss: 300.9008 - val_loss: 286.3364\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 292.5568 - val_loss: 277.5328\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 284.2532 - val_loss: 268.6350\n",
      "\n",
      "Forming the grid-search model #18 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f6c08f413d0>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7f6c08f84bd0>, epochs=50, batch_size=16\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 101.9401 - val_loss: 19.7664\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 220us/sample - loss: 23.9916 - val_loss: 11.9112\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 213us/sample - loss: 18.6678 - val_loss: 11.6341\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 226us/sample - loss: 15.9325 - val_loss: 12.6047\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 14.4156 - val_loss: 10.1476\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 14.5387 - val_loss: 15.5928\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 220us/sample - loss: 18.0391 - val_loss: 16.7544\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 221us/sample - loss: 15.0599 - val_loss: 12.3878\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 221us/sample - loss: 13.8345 - val_loss: 12.3459\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 233us/sample - loss: 12.6881 - val_loss: 9.4165\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 224us/sample - loss: 12.0333 - val_loss: 11.9668\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 11.0132 - val_loss: 10.5564\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 214us/sample - loss: 12.0332 - val_loss: 9.1793\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 12.2674 - val_loss: 13.0255\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 208us/sample - loss: 12.0801 - val_loss: 8.3256\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 216us/sample - loss: 10.7050 - val_loss: 8.2725\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 224us/sample - loss: 11.9590 - val_loss: 8.4048\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 228us/sample - loss: 10.3929 - val_loss: 7.9091\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 235us/sample - loss: 11.1312 - val_loss: 8.4600\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 203us/sample - loss: 11.4447 - val_loss: 10.6968\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 215us/sample - loss: 11.0625 - val_loss: 11.9488\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 216us/sample - loss: 10.9508 - val_loss: 20.4587\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 11.0180 - val_loss: 8.6275\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 10.2681 - val_loss: 7.6895\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 222us/sample - loss: 11.6921 - val_loss: 10.5313\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 224us/sample - loss: 10.1470 - val_loss: 8.3197\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 209us/sample - loss: 9.8019 - val_loss: 9.3377\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 9.4618 - val_loss: 8.1057\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 201us/sample - loss: 9.6454 - val_loss: 9.9371\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 220us/sample - loss: 9.4841 - val_loss: 13.1938\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 215us/sample - loss: 10.4111 - val_loss: 8.4300\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 210us/sample - loss: 9.7969 - val_loss: 8.9852\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 217us/sample - loss: 9.5977 - val_loss: 7.5060\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 215us/sample - loss: 10.7067 - val_loss: 8.4406\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 9.1571 - val_loss: 7.3064\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 208us/sample - loss: 9.6384 - val_loss: 8.4550\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 9.3998 - val_loss: 10.5892\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 8.3314 - val_loss: 9.8474\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 226us/sample - loss: 8.2447 - val_loss: 8.4693\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 222us/sample - loss: 8.8513 - val_loss: 9.9753\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 218us/sample - loss: 8.5168 - val_loss: 10.4376\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 213us/sample - loss: 9.1154 - val_loss: 12.6691\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 9.4958 - val_loss: 8.5251\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 211us/sample - loss: 8.8275 - val_loss: 9.7498\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 208us/sample - loss: 9.4999 - val_loss: 8.5364\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 214us/sample - loss: 9.0191 - val_loss: 8.1658\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 215us/sample - loss: 8.8455 - val_loss: 8.7425\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 206us/sample - loss: 8.5757 - val_loss: 7.5277\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 222us/sample - loss: 9.7901 - val_loss: 8.5026\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 8.8957 - val_loss: 7.3600\n",
      "\n",
      "Forming the grid-search model #19 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f6c08f413d0>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7f6c08f84bd0>, epochs=50, batch_size=32\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 0s 1ms/sample - loss: 165.8836 - val_loss: 25.3564\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 119us/sample - loss: 29.2079 - val_loss: 16.4808\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 22.5905 - val_loss: 14.3173\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 17.2394 - val_loss: 12.3839\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 139us/sample - loss: 16.6783 - val_loss: 11.4315\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - ETA: 0s - loss: 13.08 - 0s 121us/sample - loss: 14.7328 - val_loss: 11.9278\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 15.4971 - val_loss: 12.8408\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 120us/sample - loss: 14.5609 - val_loss: 15.8317\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 14.2638 - val_loss: 14.0884\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 110us/sample - loss: 13.8033 - val_loss: 9.8627\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 120us/sample - loss: 12.0593 - val_loss: 10.2752\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 11.7936 - val_loss: 10.1329\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 114us/sample - loss: 12.1653 - val_loss: 9.4091\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 11.3138 - val_loss: 9.9124\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 11.8137 - val_loss: 8.8963\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 118us/sample - loss: 11.0485 - val_loss: 9.2037\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 115us/sample - loss: 11.1426 - val_loss: 10.4129\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 10.7139 - val_loss: 8.6609\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 11.8379 - val_loss: 9.8531\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 122us/sample - loss: 10.5978 - val_loss: 9.0579\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 119us/sample - loss: 10.9236 - val_loss: 8.9939\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 10.8284 - val_loss: 9.7664\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 10.2368 - val_loss: 8.2529\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 120us/sample - loss: 10.3303 - val_loss: 8.3577\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 10.9065 - val_loss: 8.1008\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 122us/sample - loss: 10.1931 - val_loss: 8.5646\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 120us/sample - loss: 9.8399 - val_loss: 8.2165\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 9.6752 - val_loss: 8.7352\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 11.0874 - val_loss: 9.7213\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 9.7618 - val_loss: 10.6716\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 118us/sample - loss: 10.4467 - val_loss: 8.7439\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 11.0030 - val_loss: 7.9175\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 9.6144 - val_loss: 7.5090\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 138us/sample - loss: 10.6515 - val_loss: 8.8635\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 117us/sample - loss: 9.5228 - val_loss: 7.6344\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 9.9385 - val_loss: 8.6652\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 10.3691 - val_loss: 13.2686\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 122us/sample - loss: 9.2797 - val_loss: 8.3650\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 8.9266 - val_loss: 8.6380\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 120us/sample - loss: 9.4632 - val_loss: 7.0180\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 9.3893 - val_loss: 8.2604\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 9.2156 - val_loss: 10.3222\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 9.4173 - val_loss: 8.0532\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 131us/sample - loss: 8.7891 - val_loss: 7.8137\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 9.9020 - val_loss: 7.4884\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 120us/sample - loss: 9.2748 - val_loss: 7.0258\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 122us/sample - loss: 9.3522 - val_loss: 8.3861\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 8.8434 - val_loss: 7.6353\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 118us/sample - loss: 9.2658 - val_loss: 7.8332\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 115us/sample - loss: 9.1445 - val_loss: 7.4151\n",
      "\n",
      "Forming the grid-search model #20 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f6c08f413d0>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7f6c08f84bd0>, epochs=50, batch_size=64\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 0s 1ms/sample - loss: 287.5303 - val_loss: 34.7185\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 36.9232 - val_loss: 23.0405\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 28.3038 - val_loss: 18.5298\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 23.9533 - val_loss: 15.6042\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 74us/sample - loss: 20.4059 - val_loss: 14.0156\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 74us/sample - loss: 18.8780 - val_loss: 13.4487\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 17.3708 - val_loss: 12.9040\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 16.1054 - val_loss: 11.7097\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 15.1422 - val_loss: 12.5806\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 73us/sample - loss: 15.5143 - val_loss: 11.2366\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 13.5248 - val_loss: 12.1553\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 13.5328 - val_loss: 10.7155\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 13.2412 - val_loss: 10.8154\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 12.5742 - val_loss: 10.0511\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 12.8671 - val_loss: 9.9289\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 73us/sample - loss: 12.7747 - val_loss: 10.0922\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 12.2732 - val_loss: 10.1549\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 11.7559 - val_loss: 10.2939\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 12.0578 - val_loss: 9.8747\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 11.4628 - val_loss: 9.6105\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 11.5227 - val_loss: 9.3378\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 74us/sample - loss: 11.4562 - val_loss: 9.5216\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 11.1256 - val_loss: 9.4927\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 11.5090 - val_loss: 8.9082\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 10.8543 - val_loss: 9.2297\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 87us/sample - loss: 12.0317 - val_loss: 8.8676\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 89us/sample - loss: 10.8106 - val_loss: 9.0194\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 10.6989 - val_loss: 8.8293\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 10.8758 - val_loss: 8.6400\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 10.7224 - val_loss: 9.0414\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 10.3847 - val_loss: 9.6162\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 73us/sample - loss: 11.0343 - val_loss: 8.3287\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 11.2528 - val_loss: 8.4434\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 10.1276 - val_loss: 8.3666\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 10.4175 - val_loss: 8.2543\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 73us/sample - loss: 10.1205 - val_loss: 8.5901\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 9.8645 - val_loss: 8.1958\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 9.9333 - val_loss: 8.0112\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 10.1466 - val_loss: 8.5088\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 9.7221 - val_loss: 8.0449\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 10.1398 - val_loss: 8.1638\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 9.9839 - val_loss: 9.0931\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 9.9138 - val_loss: 7.9544\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 9.9571 - val_loss: 8.2978\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 9.3841 - val_loss: 7.9325\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 9.2232 - val_loss: 7.6392\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 9.7435 - val_loss: 8.4622\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 9.4768 - val_loss: 10.2905\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 10.7411 - val_loss: 7.5662\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 9.3649 - val_loss: 7.7838\n",
      "\n",
      "Forming the grid-search model #21 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f6c08f413d0>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7f6c08f415d0>, epochs=50, batch_size=16\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 0s 1ms/sample - loss: 119.7094 - val_loss: 21.9018\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 207us/sample - loss: 24.0823 - val_loss: 15.4587\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 221us/sample - loss: 19.8968 - val_loss: 12.1564\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 209us/sample - loss: 15.8474 - val_loss: 12.9107\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 220us/sample - loss: 14.9339 - val_loss: 10.1524\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 203us/sample - loss: 15.1026 - val_loss: 19.6088\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 195us/sample - loss: 18.7557 - val_loss: 12.3278\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 217us/sample - loss: 15.7442 - val_loss: 15.4790\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 14.1009 - val_loss: 13.9714\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 231us/sample - loss: 13.2098 - val_loss: 9.6947\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 218us/sample - loss: 11.9963 - val_loss: 13.2759\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 11.3406 - val_loss: 12.2979\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 206us/sample - loss: 12.9208 - val_loss: 8.9200\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 222us/sample - loss: 12.2747 - val_loss: 13.7610\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 220us/sample - loss: 12.2425 - val_loss: 7.5339\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 217us/sample - loss: 11.1473 - val_loss: 8.1273\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 12.7226 - val_loss: 8.1589\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 226us/sample - loss: 10.8994 - val_loss: 7.8638\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 203us/sample - loss: 11.5369 - val_loss: 8.4778\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 242us/sample - loss: 12.1042 - val_loss: 11.1926\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 241us/sample - loss: 11.1698 - val_loss: 9.8375\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 239us/sample - loss: 11.2239 - val_loss: 20.1140\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 200us/sample - loss: 11.3041 - val_loss: 8.3646\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 216us/sample - loss: 10.6166 - val_loss: 7.3201\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 216us/sample - loss: 11.8980 - val_loss: 8.9087\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 216us/sample - loss: 10.2837 - val_loss: 9.3126\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 201us/sample - loss: 10.0759 - val_loss: 8.1774\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 207us/sample - loss: 9.8389 - val_loss: 7.4086\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 222us/sample - loss: 9.7815 - val_loss: 9.4498\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 214us/sample - loss: 9.6199 - val_loss: 14.2693\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 202us/sample - loss: 11.6427 - val_loss: 7.4391\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 9.7708 - val_loss: 10.7415\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 204us/sample - loss: 10.1398 - val_loss: 7.0994\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 230us/sample - loss: 11.4716 - val_loss: 8.0016\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 222us/sample - loss: 9.6443 - val_loss: 6.9557\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 222us/sample - loss: 9.8561 - val_loss: 7.9212\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 211us/sample - loss: 10.2627 - val_loss: 10.2117\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 221us/sample - loss: 8.6945 - val_loss: 9.6121\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 227us/sample - loss: 8.7010 - val_loss: 7.7909\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 224us/sample - loss: 9.2401 - val_loss: 9.6455\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 240us/sample - loss: 9.0075 - val_loss: 11.0823\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 227us/sample - loss: 9.6271 - val_loss: 11.0264\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 227us/sample - loss: 9.6765 - val_loss: 8.1868\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 9.0518 - val_loss: 7.9880\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 208us/sample - loss: 9.5296 - val_loss: 7.9793\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 217us/sample - loss: 9.0949 - val_loss: 7.6067\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 221us/sample - loss: 9.5201 - val_loss: 7.8059\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 218us/sample - loss: 9.2231 - val_loss: 7.5908\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 204us/sample - loss: 10.5899 - val_loss: 7.5465\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 204us/sample - loss: 9.1582 - val_loss: 8.2900\n",
      "\n",
      "Forming the grid-search model #22 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f6c08f413d0>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7f6c08f415d0>, epochs=50, batch_size=32\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 0s 1ms/sample - loss: 199.3392 - val_loss: 21.7243\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 122us/sample - loss: 27.0965 - val_loss: 17.3049\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 122us/sample - loss: 21.5534 - val_loss: 13.7432\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 16.6765 - val_loss: 12.8239\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 16.5520 - val_loss: 11.6586\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 14.8619 - val_loss: 11.6785\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 15.7225 - val_loss: 13.4614\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 15.0571 - val_loss: 15.3025\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 132us/sample - loss: 14.5591 - val_loss: 12.7863\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 119us/sample - loss: 14.2455 - val_loss: 9.8859\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 12.1587 - val_loss: 10.6932\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 120us/sample - loss: 12.4379 - val_loss: 10.6769\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 147us/sample - loss: 11.9564 - val_loss: 9.2848\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 11.3012 - val_loss: 9.5016\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 118us/sample - loss: 11.9152 - val_loss: 9.0609\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 106us/sample - loss: 11.2715 - val_loss: 9.1164\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 11.4317 - val_loss: 9.5532\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 120us/sample - loss: 10.7490 - val_loss: 8.6782\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 12.0813 - val_loss: 10.7604\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 10.7815 - val_loss: 10.0248\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 117us/sample - loss: 10.9766 - val_loss: 9.0745\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 11.0139 - val_loss: 9.4153\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 10.2339 - val_loss: 8.6929\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 10.7101 - val_loss: 8.5502\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 10.9620 - val_loss: 8.2120\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 119us/sample - loss: 10.7022 - val_loss: 8.8810\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 100us/sample - loss: 10.3284 - val_loss: 7.8334\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 118us/sample - loss: 10.1205 - val_loss: 7.8633\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 11.7653 - val_loss: 10.2330\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 10.1959 - val_loss: 10.3009\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 10.7216 - val_loss: 7.8175\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 129us/sample - loss: 11.3511 - val_loss: 8.1397\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 9.9105 - val_loss: 7.5765\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 120us/sample - loss: 11.3062 - val_loss: 8.3010\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 9.5189 - val_loss: 7.7014\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 10.2218 - val_loss: 8.2749\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 148us/sample - loss: 10.7501 - val_loss: 14.0662\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 119us/sample - loss: 9.3741 - val_loss: 9.3622\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 8.9093 - val_loss: 8.4107\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 119us/sample - loss: 9.4774 - val_loss: 7.1103\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 140us/sample - loss: 9.5586 - val_loss: 8.2374\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 128us/sample - loss: 9.4745 - val_loss: 10.4536\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 9.4085 - val_loss: 8.3193\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 8.8887 - val_loss: 7.5327\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 9.6236 - val_loss: 7.5024\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 9.2685 - val_loss: 7.2949\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 122us/sample - loss: 9.6634 - val_loss: 9.7031\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 113us/sample - loss: 9.0366 - val_loss: 7.7666\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 9.5602 - val_loss: 7.3176\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 113us/sample - loss: 9.3392 - val_loss: 7.6657\n",
      "\n",
      "Forming the grid-search model #23 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f6c08f413d0>, kernel=<tensorflow.python.ops.init_ops_v2.Orthogonal object at 0x7f6c08f415d0>, epochs=50, batch_size=64\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 0s 1ms/sample - loss: 347.2263 - val_loss: 45.6951\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 86us/sample - loss: 40.4650 - val_loss: 19.5577\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 25.3744 - val_loss: 16.9557\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 21.9983 - val_loss: 16.0156\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 19.1652 - val_loss: 14.4754\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 64us/sample - loss: 18.2660 - val_loss: 14.0396\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 69us/sample - loss: 16.9280 - val_loss: 13.8350\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 72us/sample - loss: 15.9117 - val_loss: 12.1411\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 15.1758 - val_loss: 13.1307\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 16.1702 - val_loss: 11.6673\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 13.6725 - val_loss: 12.7301\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 13.5548 - val_loss: 10.7304\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 13.3394 - val_loss: 11.3849\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 12.7353 - val_loss: 10.1665\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 74us/sample - loss: 13.1989 - val_loss: 10.0785\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 74us/sample - loss: 12.9529 - val_loss: 9.7905\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 72us/sample - loss: 12.7010 - val_loss: 10.6623\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 11.8767 - val_loss: 9.6822\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 96us/sample - loss: 12.5063 - val_loss: 10.0421\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 74us/sample - loss: 11.4028 - val_loss: 10.0411\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 11.8499 - val_loss: 9.1479\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 72us/sample - loss: 11.4753 - val_loss: 9.5108\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 73us/sample - loss: 11.1980 - val_loss: 9.5590\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 12.0528 - val_loss: 9.0008\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 11.0749 - val_loss: 9.3718\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 13.0441 - val_loss: 8.8637\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 11.3190 - val_loss: 9.0745\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 10.8184 - val_loss: 8.9237\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 11.0499 - val_loss: 8.7305\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 71us/sample - loss: 10.8058 - val_loss: 9.2400\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 10.5947 - val_loss: 8.6016\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 10.8542 - val_loss: 8.3710\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 11.5839 - val_loss: 8.2558\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 10.3662 - val_loss: 8.8598\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 73us/sample - loss: 10.5063 - val_loss: 8.2827\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 10.1992 - val_loss: 8.3032\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 84us/sample - loss: 9.9178 - val_loss: 8.3196\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 10.0236 - val_loss: 8.2372\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 10.1050 - val_loss: 8.7253\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 9.8092 - val_loss: 8.2483\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 10.2605 - val_loss: 8.3390\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 70us/sample - loss: 9.8951 - val_loss: 8.7441\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 10.0154 - val_loss: 8.1119\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 10.1908 - val_loss: 8.6952\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 74us/sample - loss: 9.7933 - val_loss: 8.1196\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 9.2226 - val_loss: 7.8377\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 9.9990 - val_loss: 9.0231\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 9.5602 - val_loss: 10.3269\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 11.3917 - val_loss: 8.0789\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 9.3680 - val_loss: 7.7126\n",
      "\n",
      "Forming the grid-search model #24 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f6c08f413d0>, kernel=<tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7f6c08f41550>, epochs=50, batch_size=16\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 0s 1ms/sample - loss: 217.6292 - val_loss: 23.1098\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 221us/sample - loss: 29.4084 - val_loss: 19.1511\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 201us/sample - loss: 23.1269 - val_loss: 14.0634\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 208us/sample - loss: 18.6386 - val_loss: 14.0318\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 218us/sample - loss: 17.8433 - val_loss: 11.7232\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 221us/sample - loss: 16.2587 - val_loss: 14.3963\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 215us/sample - loss: 20.6388 - val_loss: 13.3883\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 208us/sample - loss: 17.7650 - val_loss: 15.4603\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 212us/sample - loss: 16.0596 - val_loss: 14.0157\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 212us/sample - loss: 15.1796 - val_loss: 9.5135\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 207us/sample - loss: 13.3656 - val_loss: 11.2133\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 206us/sample - loss: 12.3540 - val_loss: 12.3369\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 13.9939 - val_loss: 9.3957\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 203us/sample - loss: 13.1514 - val_loss: 12.8103\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 222us/sample - loss: 14.4076 - val_loss: 8.2214\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 235us/sample - loss: 12.6154 - val_loss: 8.4101\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 221us/sample - loss: 13.2720 - val_loss: 9.3872\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 213us/sample - loss: 12.2578 - val_loss: 8.3107\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 214us/sample - loss: 13.3639 - val_loss: 9.1858\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 224us/sample - loss: 13.0881 - val_loss: 10.3142\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 12.7034 - val_loss: 10.0217\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 228us/sample - loss: 12.2816 - val_loss: 16.4000\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 12.4389 - val_loss: 8.6841\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 226us/sample - loss: 12.1663 - val_loss: 8.5055\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 217us/sample - loss: 13.7304 - val_loss: 9.5283\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 190us/sample - loss: 11.2955 - val_loss: 9.2886\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 220us/sample - loss: 11.6739 - val_loss: 8.8491\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 192us/sample - loss: 10.9538 - val_loss: 7.9621\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 204us/sample - loss: 11.1892 - val_loss: 10.5035\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 198us/sample - loss: 11.0137 - val_loss: 11.0741\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 216us/sample - loss: 12.2394 - val_loss: 7.2874\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 209us/sample - loss: 11.1944 - val_loss: 10.5657\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 222us/sample - loss: 11.5889 - val_loss: 7.6377\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 197us/sample - loss: 12.1278 - val_loss: 8.5110\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 235us/sample - loss: 10.9119 - val_loss: 7.7814\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 201us/sample - loss: 10.7875 - val_loss: 8.2860\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 11.2244 - val_loss: 12.8785\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 214us/sample - loss: 9.5868 - val_loss: 10.7161\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 211us/sample - loss: 9.9361 - val_loss: 8.5987\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 206us/sample - loss: 10.3157 - val_loss: 8.8063\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 215us/sample - loss: 10.0000 - val_loss: 12.2929\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 204us/sample - loss: 11.0140 - val_loss: 10.1877\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 190us/sample - loss: 10.8548 - val_loss: 8.9458\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 186us/sample - loss: 9.8697 - val_loss: 8.6804\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 192us/sample - loss: 10.6063 - val_loss: 8.7268\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 203us/sample - loss: 10.3937 - val_loss: 8.4423\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 210us/sample - loss: 10.4140 - val_loss: 8.0772\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 203us/sample - loss: 10.0451 - val_loss: 8.3337\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 213us/sample - loss: 11.7499 - val_loss: 7.8683\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 201us/sample - loss: 10.0621 - val_loss: 7.6014\n",
      "\n",
      "Forming the grid-search model #25 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f6c08f413d0>, kernel=<tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7f6c08f41550>, epochs=50, batch_size=32\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 0s 1ms/sample - loss: 387.9512 - val_loss: 50.9947\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 40.2864 - val_loss: 22.9432\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 114us/sample - loss: 28.0606 - val_loss: 17.4673\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 22.1997 - val_loss: 17.0311\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 118us/sample - loss: 21.1597 - val_loss: 14.6594\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 19.1249 - val_loss: 15.3933\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 18.8067 - val_loss: 15.1695\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 17.8970 - val_loss: 15.1195\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 118us/sample - loss: 16.2620 - val_loss: 14.7014\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 16.7166 - val_loss: 10.8471\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 116us/sample - loss: 14.2172 - val_loss: 11.3963\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 14.0140 - val_loss: 11.4429\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 114us/sample - loss: 14.0289 - val_loss: 10.5738\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 117us/sample - loss: 13.2762 - val_loss: 11.9514\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 14.5339 - val_loss: 9.8468\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 120us/sample - loss: 12.6961 - val_loss: 9.7188\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 13.1727 - val_loss: 11.5191\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 119us/sample - loss: 12.5326 - val_loss: 9.0905\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 130us/sample - loss: 13.9027 - val_loss: 10.1884\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 115us/sample - loss: 11.9862 - val_loss: 9.8816\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 109us/sample - loss: 12.8323 - val_loss: 9.3243\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 93us/sample - loss: 12.5701 - val_loss: 9.4178\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 110us/sample - loss: 11.7607 - val_loss: 8.4816\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 113us/sample - loss: 12.0561 - val_loss: 8.7555\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 12.5700 - val_loss: 8.3059\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 11.9170 - val_loss: 9.1271\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 116us/sample - loss: 11.7162 - val_loss: 8.2262\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 114us/sample - loss: 11.4823 - val_loss: 8.2256\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 13.1433 - val_loss: 9.7783\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 117us/sample - loss: 11.6163 - val_loss: 10.4145\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 120us/sample - loss: 12.0542 - val_loss: 8.0509\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 121us/sample - loss: 12.5195 - val_loss: 9.0672\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 122us/sample - loss: 11.4068 - val_loss: 7.9892\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 119us/sample - loss: 11.9608 - val_loss: 8.4922\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 113us/sample - loss: 10.9182 - val_loss: 8.3240\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 11.8134 - val_loss: 8.4276\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 126us/sample - loss: 12.5154 - val_loss: 15.2583\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 124us/sample - loss: 10.6659 - val_loss: 9.2436\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 125us/sample - loss: 10.4215 - val_loss: 8.9520\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 123us/sample - loss: 11.2186 - val_loss: 7.4918\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 120us/sample - loss: 11.1048 - val_loss: 8.7133\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 118us/sample - loss: 11.0990 - val_loss: 10.7723\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 117us/sample - loss: 11.1819 - val_loss: 8.7001\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 118us/sample - loss: 10.4837 - val_loss: 8.0350\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 120us/sample - loss: 11.1099 - val_loss: 7.9914\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 119us/sample - loss: 10.8904 - val_loss: 7.6144\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 120us/sample - loss: 11.2488 - val_loss: 8.5077\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 117us/sample - loss: 10.3032 - val_loss: 8.3299\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 127us/sample - loss: 11.2891 - val_loss: 7.8896\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 122us/sample - loss: 10.6874 - val_loss: 7.6249\n",
      "\n",
      "Forming the grid-search model #26 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f6c08f413d0>, kernel=<tensorflow.python.ops.init_ops_v2.RandomUniform object at 0x7f6c08f41550>, epochs=50, batch_size=64\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 0s 1ms/sample - loss: 536.7119 - val_loss: 436.2470\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 0s 93us/sample - loss: 236.1974 - val_loss: 50.6574\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 42.8214 - val_loss: 25.9468\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 31.7394 - val_loss: 22.0193\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 0s 74us/sample - loss: 26.7095 - val_loss: 19.5736\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 24.5574 - val_loss: 18.1288\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 0s 74us/sample - loss: 22.3590 - val_loss: 18.6476\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 21.1433 - val_loss: 15.7742\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 20.1384 - val_loss: 15.6273\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 20.4283 - val_loss: 14.4786\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 0s 74us/sample - loss: 17.9350 - val_loss: 15.6249\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 0s 74us/sample - loss: 17.4903 - val_loss: 13.9157\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 16.6842 - val_loss: 14.3063\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 16.1301 - val_loss: 12.7169\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 0s 74us/sample - loss: 16.4235 - val_loss: 12.5927\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 0s 81us/sample - loss: 15.8255 - val_loss: 12.2826\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 0s 72us/sample - loss: 15.1865 - val_loss: 12.1975\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 14.1823 - val_loss: 12.2934\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 0s 70us/sample - loss: 14.4491 - val_loss: 11.7910\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 0s 68us/sample - loss: 13.7209 - val_loss: 12.2384\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 13.9936 - val_loss: 11.2492\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 13.8088 - val_loss: 10.9936\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 13.3638 - val_loss: 11.0463\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 0s 83us/sample - loss: 13.1929 - val_loss: 10.7281\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 13.0777 - val_loss: 10.9986\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 14.2928 - val_loss: 10.5462\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 13.0286 - val_loss: 10.4553\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 12.6352 - val_loss: 9.9852\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 13.0748 - val_loss: 9.8584\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 0s 75us/sample - loss: 12.6146 - val_loss: 9.8404\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 0s 89us/sample - loss: 12.5025 - val_loss: 9.6254\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 12.5100 - val_loss: 9.6150\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 13.2103 - val_loss: 9.2879\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 0s 85us/sample - loss: 11.8525 - val_loss: 9.5811\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 0s 72us/sample - loss: 12.2506 - val_loss: 9.4045\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 0s 73us/sample - loss: 12.1928 - val_loss: 9.1484\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 0s 80us/sample - loss: 11.4821 - val_loss: 9.4212\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 11.5829 - val_loss: 9.1305\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 0s 74us/sample - loss: 11.8484 - val_loss: 9.4927\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 0s 82us/sample - loss: 11.3114 - val_loss: 9.0749\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 11.6749 - val_loss: 9.4495\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 11.7451 - val_loss: 9.2195\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 0s 73us/sample - loss: 11.5480 - val_loss: 8.7720\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 0s 74us/sample - loss: 11.8047 - val_loss: 9.1880\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 11.1738 - val_loss: 8.8041\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 0s 78us/sample - loss: 10.6688 - val_loss: 8.6214\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 0s 73us/sample - loss: 11.2441 - val_loss: 8.9127\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 0s 79us/sample - loss: 11.0216 - val_loss: 11.5244\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 0s 76us/sample - loss: 12.8843 - val_loss: 8.7591\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 0s 77us/sample - loss: 10.9791 - val_loss: 8.4835\n",
      "\n",
      "Best score (lowest validation loss) found via grid search: loss=7.359964 RMSE=2.712925 from model iteration #18\n",
      "The best modeling parameters are: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f6c08f413d0>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7f6c08f84bd0>, epochs=50, batch_size=16\n",
      "Total time for performing grid-search of the best parameters: 0:01:37.645764\n"
     ]
    }
   ],
   "source": [
    "startTimeModule = datetime.now()\n",
    "\n",
    "# Set up grid search using different epochs, batch sizes, and optimizers\n",
    "optz_1 = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "optz_2 = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "optz_3 = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "optimizer_grid = [optz_1, optz_2, optz_3]\n",
    "print('Optimizer candidate #1 has the object ID of', optz_1)\n",
    "print('Optimizer candidate #2 has the object ID of', optz_2)\n",
    "print('Optimizer candidate #3 has the object ID of', optz_3)\n",
    "\n",
    "init_1 = tf.keras.initializers.he_uniform(seed=seedNum)\n",
    "init_2 = tf.keras.initializers.Orthogonal(seed=seedNum)\n",
    "init_3 = tf.keras.initializers.RandomUniform(seed=seedNum)\n",
    "init_grid = [init_1, init_2, init_3]\n",
    "print('Initializer candidate #1 has the object ID of', init_1)\n",
    "print('Initializer candidate #2 has the object ID of', init_2)\n",
    "print('Initializer candidate #3 has the object ID of', init_3)\n",
    "\n",
    "epoch_grid = [default_epoch]\n",
    "batch_grid = [int(default_batch/2), default_batch, int(default_batch*2)]\n",
    "\n",
    "best_score = float('inf')\n",
    "grid_iteration = 0\n",
    "best_iteration = 0\n",
    "best_optimizer = default_optimizer\n",
    "best_kernel_init = default_kernel_init\n",
    "best_epoch = default_epoch\n",
    "best_batch = default_batch\n",
    "\n",
    "for optimizer in optimizer_grid:\n",
    "    for kernel_init in init_grid:\n",
    "        for epoch_num in epoch_grid:\n",
    "            for batch_num in batch_grid:\n",
    "                print('\\nForming the grid-search model #%d using: optimizer=%s, kernel=%s, epochs=%d, batch_size=%d'\n",
    "                      % (grid_iteration, optimizer, kernel_init, epoch_num, batch_num))\n",
    "                reset_random(seedNum)\n",
    "                grid_model = create_customized_model(optimizer, kernel_init)\n",
    "                grid_hist = grid_model.fit(X_train, y_train, epochs=epoch_num, batch_size=batch_num, \n",
    "                                       validation_data=(X_test, y_test), verbose=1)\n",
    "                if(grid_hist.history['val_loss'][-1] < best_score):\n",
    "                    best_score = grid_hist.history['val_loss'][-1]\n",
    "                    best_iteration = grid_iteration\n",
    "                    best_optimizer = optimizer\n",
    "                    best_kernel_init = kernel_init\n",
    "                    best_epoch = epoch_num\n",
    "                    best_batch = batch_num\n",
    "                grid_iteration = grid_iteration + 1\n",
    "\n",
    "# summarize results\n",
    "print(\"\\nBest score (lowest validation loss) found via grid search: loss=%f RMSE=%f from model iteration #%d\"\n",
    "      % (best_score, math.sqrt(best_score), best_iteration))\n",
    "print('The best modeling parameters are: optimizer=%s, kernel=%s, epochs=%d, batch_size=%d'\n",
    "      % (best_optimizer, best_kernel_init, best_epoch, best_batch))\n",
    "print('Total time for performing grid-search of the best parameters:', (datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "best_kernel_init = tf.keras.initializers.he_uniform(seed=seedNum)\n",
    "best_epoch = 25\n",
    "best_batch = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 4. Optimize Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5. Finalize Model and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 5. Finalize Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forming the final model using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f6c183cf210>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7f6c183cf250>, epochs=25, batch_size=16\n",
      "Train on 379 samples, validate on 127 samples\n",
      "Epoch 1/25\n",
      "379/379 [==============================] - 1s 2ms/sample - loss: 101.9401 - val_loss: 19.7664\n",
      "Epoch 2/25\n",
      "379/379 [==============================] - 0s 209us/sample - loss: 23.9916 - val_loss: 11.9112\n",
      "Epoch 3/25\n",
      "379/379 [==============================] - 0s 208us/sample - loss: 18.6678 - val_loss: 11.6341\n",
      "Epoch 4/25\n",
      "379/379 [==============================] - 0s 219us/sample - loss: 15.9325 - val_loss: 12.6047\n",
      "Epoch 5/25\n",
      "379/379 [==============================] - 0s 205us/sample - loss: 14.4156 - val_loss: 10.1476\n",
      "Epoch 6/25\n",
      "379/379 [==============================] - 0s 214us/sample - loss: 14.5387 - val_loss: 15.5928\n",
      "Epoch 7/25\n",
      "379/379 [==============================] - 0s 225us/sample - loss: 18.0391 - val_loss: 16.7544\n",
      "Epoch 8/25\n",
      "379/379 [==============================] - 0s 245us/sample - loss: 15.0599 - val_loss: 12.3878\n",
      "Epoch 9/25\n",
      "379/379 [==============================] - 0s 253us/sample - loss: 13.8345 - val_loss: 12.3459\n",
      "Epoch 10/25\n",
      "379/379 [==============================] - 0s 203us/sample - loss: 12.6881 - val_loss: 9.4165\n",
      "Epoch 11/25\n",
      "379/379 [==============================] - 0s 404us/sample - loss: 12.0333 - val_loss: 11.9668\n",
      "Epoch 12/25\n",
      "379/379 [==============================] - 0s 206us/sample - loss: 11.0132 - val_loss: 10.5564\n",
      "Epoch 13/25\n",
      "379/379 [==============================] - 0s 211us/sample - loss: 12.0332 - val_loss: 9.1793\n",
      "Epoch 14/25\n",
      "379/379 [==============================] - 0s 242us/sample - loss: 12.2674 - val_loss: 13.0255\n",
      "Epoch 15/25\n",
      "379/379 [==============================] - 0s 223us/sample - loss: 12.0801 - val_loss: 8.3256\n",
      "Epoch 16/25\n",
      "379/379 [==============================] - 0s 213us/sample - loss: 10.7050 - val_loss: 8.2725\n",
      "Epoch 17/25\n",
      "379/379 [==============================] - 0s 239us/sample - loss: 11.9590 - val_loss: 8.4048\n",
      "Epoch 18/25\n",
      "379/379 [==============================] - 0s 202us/sample - loss: 10.3929 - val_loss: 7.9091\n",
      "Epoch 19/25\n",
      "379/379 [==============================] - 0s 215us/sample - loss: 11.1312 - val_loss: 8.4600\n",
      "Epoch 20/25\n",
      "379/379 [==============================] - 0s 207us/sample - loss: 11.4447 - val_loss: 10.6968\n",
      "Epoch 21/25\n",
      "379/379 [==============================] - 0s 189us/sample - loss: 11.0625 - val_loss: 11.9488\n",
      "Epoch 22/25\n",
      "379/379 [==============================] - 0s 216us/sample - loss: 10.9508 - val_loss: 20.4587\n",
      "Epoch 23/25\n",
      "379/379 [==============================] - 0s 228us/sample - loss: 11.0180 - val_loss: 8.6275\n",
      "Epoch 24/25\n",
      "379/379 [==============================] - 0s 203us/sample - loss: 10.2681 - val_loss: 7.6895\n",
      "Epoch 25/25\n",
      "379/379 [==============================] - 0s 220us/sample - loss: 11.6921 - val_loss: 10.5313\n"
     ]
    }
   ],
   "source": [
    "# Create the final model for evaluating the test dataset\n",
    "print('Forming the final model using: optimizer=%s, kernel=%s, epochs=%d, batch_size=%d'\n",
    "      % (best_optimizer, best_kernel_init, best_epoch, best_batch))\n",
    "reset_random(seedNum)\n",
    "final_model = create_customized_model(best_optimizer, best_kernel_init)\n",
    "final_hist = final_model.fit(X_train, y_train, epochs=best_epoch, batch_size=best_batch, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 25)                350       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 376\n",
      "Trainable params: 376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the final model\n",
    "print(final_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'sequential_28', 'layers': [{'class_name': 'Dense', 'config': {'name': 'dense_56', 'trainable': True, 'batch_input_shape': (None, 13), 'dtype': 'float32', 'units': 25, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'uniform', 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_57', 'trainable': True, 'dtype': 'float32', 'units': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'uniform', 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]}\n"
     ]
    }
   ],
   "source": [
    "# Display the configuration of the final model\n",
    "print(final_model.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize model training hisotry\n",
    "fig, axs = plt.subplots(1, 1, figsize=(12,6))\n",
    "plt.subplot(111)\n",
    "plt.plot(final_hist.history['loss'], color='blue', label='train')\n",
    "plt.plot(final_hist.history['val_loss'], color='red', label='test')\n",
    "plt.title('Final Model Training Performance (Loss)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s 89us/sample - loss: 10.5313\n",
      "Final MSE of the model: 10.531313\n",
      "Final RMSE of the model: 3.245199\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Keras model on previously unseen data\n",
    "scores = final_model.evaluate(X_test, y_test)\n",
    "print(\"Final MSE of the model: %f\" % (scores))\n",
    "print(\"Final RMSE of the model: %f\" % (math.sqrt(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data item #0 predicted to be 20.77 (expected 22.40)\n",
      "Data item #1 predicted to be 32.14 (expected 32.40)\n",
      "Data item #2 predicted to be 18.85 (expected 21.70)\n",
      "Data item #3 predicted to be 19.55 (expected 24.50)\n",
      "Data item #4 predicted to be 22.76 (expected 16.80)\n",
      "Data item #5 predicted to be 20.56 (expected 21.10)\n",
      "Data item #6 predicted to be 29.24 (expected 29.40)\n",
      "Data item #7 predicted to be 24.86 (expected 28.70)\n",
      "Data item #8 predicted to be 20.62 (expected 21.50)\n",
      "Data item #9 predicted to be 13.55 (expected 13.60)\n",
      "Data item #10 predicted to be 20.71 (expected 21.40)\n",
      "Data item #11 predicted to be 21.59 (expected 24.80)\n",
      "Data item #12 predicted to be 16.19 (expected 16.80)\n",
      "Data item #13 predicted to be 18.10 (expected 19.40)\n",
      "Data item #14 predicted to be 19.85 (expected 21.70)\n",
      "Data item #15 predicted to be 12.90 (expected 17.20)\n",
      "Data item #16 predicted to be 12.90 (expected 17.10)\n",
      "Data item #17 predicted to be 18.89 (expected 18.70)\n",
      "Data item #18 predicted to be 19.84 (expected 22.30)\n",
      "Data item #19 predicted to be 25.36 (expected 25.00)\n"
     ]
    }
   ],
   "source": [
    "# Make class predictions with the model\n",
    "predictions = final_model.predict(X_test)\n",
    "\n",
    "# Summarize the first 20 cases\n",
    "for i in range(20):\n",
    "\tprint('Data item #%d predicted to be %.2f (expected %.2f)' % (i, predictions[i], y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 5. Finalize Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for the script: 0:03:42.878484\n"
     ]
    }
   ],
   "source": [
    "print ('Total time for the script:',(datetime.now() - startTimeScript))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
