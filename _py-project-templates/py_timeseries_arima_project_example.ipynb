{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Model for [PROJECT NAME] Using Python Version 7\n",
    "### David Lowe\n",
    "### July 15, 2020\n",
    "\n",
    "Template Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery. https://machinelearningmastery.com/\n",
    "\n",
    "SUMMARY: [Sample Paragraph - The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The [PROJECT NAME] dataset is a time series situation where we are trying to forecast future outcomes based on past data points.]\n",
    "\n",
    "INTRODUCTION: [Sample Paragraph - The problem is to forecast the monthly number of airline passenger miles traveled in the United States. The dataset describes a time-series of miles (in millions) over 18 years (1960-1977), and there are 216 observations. We used the first 80% of the observations for training various models while holding back the remaining observations for validating the final model.]\n",
    "\n",
    "ANALYSIS: [Sample Paragraph - The baseline prediction (or persistence) for the dataset resulted in an RMSE of 1.770. After performing a grid search for the most optimal ARIMA parameters, the final ARIMA non-seasonal order was (1, 1, 1) with the seasonal order being (0, 1, 2, 12). Furthermore, the chosen model processed the validation data with an RMSE of 0.447, which was better than the baseline model as expected.]\n",
    "\n",
    "CONCLUSION: For this dataset, the chosen ARIMA model achieved a satisfactory result and should be considered for further modeling.\n",
    "\n",
    "Dataset Used: [Sample Paragraph - Monthly U.S Air Passenger Miles January 1960 through December 1977]\n",
    "\n",
    "Dataset ML Model: Time series forecast with numerical attributes\n",
    "\n",
    "Dataset Reference: Rob Hyndman and Yangzhuoran Yang (2018). tsdl: Time Series Data Library. v0.1.0. https://pkg.yangzhuoranyang./tsdl/.\n",
    "\n",
    "The project aims to touch on the following areas:\n",
    "\n",
    "* Document a predictive modeling problem end-to-end\n",
    "* Explore data cleaning and transformation options\n",
    "* Explore various algorithms for baselining the model performance\n",
    "* Explore tuning techniques for improving the model performance\n",
    "\n",
    "A time series predictive modeling project genrally can be broken down into about five major tasks:\n",
    "\n",
    "1. Define Problem and Acquire Data\n",
    "2. Inspect and Explore Data\n",
    "3. Clean and Pre-Process Data\n",
    "4. Fit and Evaluate Models\n",
    "5. Finalize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Define Problem and Acquire Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the necessary packages for Colab\n",
    "# !pip install python-dotenv PyMySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the GPU information from Colab\n",
    "# gpu_info = !nvidia-smi\n",
    "# gpu_info = '\\n'.join(gpu_info)\n",
    "# if gpu_info.find('failed') >= 0:\n",
    "#     print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "#     print('and then re-execute this cell.')\n",
    "# else:\n",
    "#     print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the memory configuration from Colab\n",
    "# from psutil import virtual_memory\n",
    "# ram_gb = virtual_memory().total / 1e9\n",
    "# print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "# if ram_gb < 20:\n",
    "#     print('To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"')\n",
    "#     print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
    "#     print('re-execute this cell.')\n",
    "# else:\n",
    "#     print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of available CPUs is: 4\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the CPU information\n",
    "ncpu = !nproc\n",
    "print(\"The number of available CPUs is:\", ncpu[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a) Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random seed number for reproducible results\n",
    "seedNum = 888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pmdarima as pm\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "# import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b) Set up the controlling parameters and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin the timer for the script processing\n",
    "startTimeScript = datetime.now()\n",
    "\n",
    "# Set up the number of CPU cores available for multi-thread processing\n",
    "n_jobs = 1\n",
    "\n",
    "# Set up the flag to stop sending progress emails (setting to True will send status emails!)\n",
    "notifyStatus = True\n",
    "\n",
    "# Set up the parent directory location for loading the dotenv files\n",
    "useColab = False\n",
    "if useColab:\n",
    "    # Mount Google Drive locally for storing files\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    gdrivePrefix = '/content/gdrive/My Drive/Colab_Downloads/'\n",
    "    env_path = '/content/gdrive/My Drive/Colab Notebooks/'\n",
    "    dotenv_path = env_path + \"python_script.env\"\n",
    "    load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "# Set up the dotenv file for retrieving environment variables\n",
    "useLocalPC = False\n",
    "if useLocalPC:\n",
    "    env_path = \"/Users/david/PycharmProjects/\"\n",
    "    dotenv_path = env_path + \"python_script.env\"\n",
    "    load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "# Configure the plotting style\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# Set Pandas options\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.width\", 140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the email notification function\n",
    "def status_notify(msg_text):\n",
    "    access_key = os.environ.get('SNS_ACCESS_KEY')\n",
    "    secret_key = os.environ.get('SNS_SECRET_KEY')\n",
    "    aws_region = os.environ.get('SNS_AWS_REGION')\n",
    "    topic_arn = \"arn:aws:sns:us-east-1:072417399597:PythonMLScriptNotification\"\n",
    "    if (access_key is None) or (secret_key is None) or (aws_region is None):\n",
    "        sys.exit(\"Incomplete notification setup info. Script Processing Aborted!!!\")\n",
    "    sns = boto3.client('sns', aws_access_key_id=access_key, aws_secret_access_key=secret_key, region_name=aws_region)\n",
    "    response = sns.publish(TopicArn=topic_arn, Message=msg_text)\n",
    "    if response['ResponseMetadata']['HTTPStatusCode'] != 200 :\n",
    "        print('Status notification not OK with HTTP status code:', response['ResponseMetadata']['HTTPStatusCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'boto3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5ecf881c3b05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mnotifyStatus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstatus_notify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Library and Data Loading has begun! \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%a %B %d, %Y %I:%M:%S %p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-7f10320cd5ce>\u001b[0m in \u001b[0;36mstatus_notify\u001b[0;34m(msg_text)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccess_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msecret_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maws_region\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Incomplete notification setup info. Script Processing Aborted!!!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maws_access_key_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccess_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maws_secret_access_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecret_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maws_region\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTopicArn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopic_arn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ResponseMetadata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HTTPStatusCode'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'boto3' is not defined"
     ]
    }
   ],
   "source": [
    "if notifyStatus: status_notify(\"Library and Data Loading has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c) Acquire and Load the Data\n",
    "\n",
    "Since the dataset is not current, this means that we cannot easily collect updated data to validate the model. Therefore, we will withhold a portion of the data towards the end from analysis and model selection. This very segment of data will be used to validate the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset and the necessary data structure\n",
    "time_series = pd.read_csv('https://dainesanalytics.com/datasets/time-series-data-library/tsdl200.csv', index_col='idx', parse_dates=True)\n",
    "\n",
    "# Load the dataset from the Federal Reserve Bank's FRED Database\n",
    "# starting = datetime(1990, 1, 1)\n",
    "# ending = datetime.now()\n",
    "# fred_data = 'SMU06000007072251101'\n",
    "# time_series = web.DataReader(fred_data, 'fred', starting, ending)\n",
    "# time_series.rename(columns={fred_data: 'value'}, inplace=True)\n",
    "\n",
    "# Sample code for subsetting the time-series data\n",
    "# time_series = original_series['1986':'1990']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = time_series.columns[0]\n",
    "lower_bound = 'lower ' + target_col\n",
    "upper_bound = 'upper ' + target_col\n",
    "print('The target column of the time series is:', target_col)\n",
    "print('The forecast boundary columns are:', lower_bound, '&', upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if notifyStatus: status_notify(\"Library and Data Loading completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2. Inspect and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if notifyStatus: status_notify(\"Data Inspection and Exploration has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a) Summary Statistics of the Time Series Data\n",
    "\n",
    "Summary statistics provide a quick look at the limits of observed values. It can help to get a quick idea of what we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics of time series\n",
    "print(time_series.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b) Line Plot of the Time Series Data\n",
    "\n",
    "A line plot of a time series can provide a lot of insight into the problem. Some observations from the plot can include:\n",
    "\n",
    "* Whether the trend appears to be level around the mean\n",
    "* Whether there appear to be any obvious outliers\n",
    "\n",
    "The ARIMA(p,d,q) model requires three parameters and assumes that we are working with a stationary time series.\n",
    "\n",
    "The ADF results should show that the test statistic value is smaller than the critical value at 5% if the time series is stationary. This suggests that we can reject the null hypothesis (i.e. a low probability that the result is a statistical fluke)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plots of time series\n",
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "fig.suptitle('Line Plot of the Time Series Data')\n",
    "time_series.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.c) Histogram and Density Plots of the Time Series Data\n",
    "\n",
    "Reviewing plots of the density of observations can provide further insight into the structure of the data. Some observations from the plots can include:\n",
    "\n",
    "* Whether the distribution is Gaussian\n",
    "* Whether the distribution has a long tail and may suggest the need for data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plots of time series\n",
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "fig.suptitle('Histogram of the Time Series Data')\n",
    "time_series.hist(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plots of time series\n",
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "fig.suptitle('Density Plot of the Time Series Data')\n",
    "time_series.plot(kind='kde', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.d) Box and Whisker Plots of the Time Series Data\n",
    "\n",
    "We can group or aggregate the data and get a better idea of the spread of observations. Some observations from reviewing the plot can include:\n",
    "\n",
    "* Whether the median values for each grouping shows any significant trend\n",
    "* Whether the spread, or middle 50% of the data, shows any significant variability\n",
    "* Whether there are outliers in some grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplots of time series\n",
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "fig.suptitle('Box and Whisker Plots of the Time Series Data')\n",
    "squeezed = time_series.squeeze()\n",
    "sns.boxplot(squeezed.index.year, squeezed, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if notifyStatus: status_notify(\"Data Inspection and Exploration completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3. Data Transformation and Stationarity Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if notifyStatus: status_notify(\"Data Cleaning and Pre-Processing has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.a) Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the time series into monthly average for the ease of modeling\n",
    "# original_series = time_series\n",
    "# resample = original_series.resample('M')\n",
    "# time_series = resample.mean()\n",
    "# time_series.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plots of the transformed time series\n",
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "fig.suptitle('Line Plot of the Non-Seasonal Time Series Data')\n",
    "time_series.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.b) Test for Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if stationary\n",
    "result = adfuller(time_series[target_col])\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Test Statistics Values:')\n",
    "for key, value in result[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF and PACF plots of the time series data\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12,12))\n",
    "plot_acf(time_series, ax=ax1)\n",
    "plot_pacf(time_series, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c) Test for Stationarity of Non-Seasonal Time Series Data\n",
    "\n",
    "Occasionally a time series may look non-stationary on the first look. We can make it stationary by differencing the series and using a statistical test to confirm that the differenced result is stationary. Rejecting the null hypothesis means that the process has no unit root, and in turn that the time series is stationary or does not have time-dependent structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a differenced series\n",
    "stationary_ns = time_series.diff().dropna()\n",
    "\n",
    "# Plot differenced data\n",
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "fig.suptitle('Line Plot of the Stationary Time Series Data')\n",
    "stationary_ns.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for stationarity\n",
    "result = adfuller(stationary_ns[target_col])\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Test Statistics Values:')\n",
    "for key, value in result[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF and PACF plots of the stationary time series\n",
    "lags = 25\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12,12))\n",
    "plot_acf(stationary_ns, lags=lags, ax=ax1)\n",
    "plot_pacf(stationary_ns, lags=lags, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.d) Seasonal Decomposition for Seasonal Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the initial seasonal frequency parameter\n",
    "seasonal_freq = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform seasonal decomposition to observe the seasonal frequency\n",
    "decomp_results = seasonal_decompose(time_series, period=seasonal_freq)\n",
    "decomp_results.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a seasonal series\n",
    "N = seasonal_freq\n",
    "seasonal_series = time_series - time_series.rolling(N).mean()\n",
    "seasonal_series = seasonal_series.dropna()\n",
    "\n",
    "# Line plots of the seasonal time series\n",
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "fig.suptitle('Line Plot of the Seasonal Time Series Data')\n",
    "seasonal_series.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for stationarity\n",
    "result = adfuller(seasonal_series[target_col])\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Test Statistics Values:')\n",
    "for key, value in result[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF and PACF plots of the time series data\n",
    "lag = seasonal_freq * 2\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12,12))\n",
    "plot_acf(seasonal_series, lags=lag, ax=ax1)\n",
    "plot_pacf(seasonal_series, lags=lag, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.e) Test for Stationarity of Seasonal Time Series Data\n",
    "\n",
    "Occasionally a time series may look non-stationary on the first look. We can make it stationary by differencing the series and using a statistical test to confirm that the differenced result is stationary. Rejecting the null hypothesis means that the process has no unit root, and in turn that the time series is stationary or does not have time-dependent structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a differenced series\n",
    "stationary_ss = time_series.diff(seasonal_freq).dropna()\n",
    "\n",
    "# Plot differenced data\n",
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "fig.suptitle('Line Plot of the Stationary Seasonal Time Series Data')\n",
    "stationary_ss.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for stationarity\n",
    "result = adfuller(stationary_ss[target_col])\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Test Statistics Values:')\n",
    "for key, value in result[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF and PACF plots of the stationary time series\n",
    "lags = seasonal_freq * 2\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12,12))\n",
    "plot_acf(stationary_ss, lags=lags, ax=ax1)\n",
    "plot_pacf(stationary_ss, lags=lags, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if notifyStatus: status_notify(\"Data Cleaning and Pre-Processing completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4. Fit and Evaluate Models\n",
    "\n",
    "In this section, we will develop Autoregressive Integrated Moving Average or ARIMA models for the problem. We will first establish a persistent model. Next we will use a grid search approach to look for an optimal ARIMA model. This will be followed by a third step of investigating the residual errors of the chosen model.\n",
    "\n",
    "* Establish the Persistent Model\n",
    "* Automatically Configure the ARIMA\n",
    "* Review Residual Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if notifyStatus: status_notify(\"Model Fitting and Evaluation has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.a) Establish the Persistent Model\n",
    "\n",
    "The first step before getting bogged down in data analysis and modeling is to establish a baseline of performance. This will provide both a template for evaluating models using the proposed test harness and a performance measure by which all more elaborate predictive models can be compared.\n",
    "\n",
    "The baseline prediction for time series forecasting is called the naive forecast, or persistence. This is where the observation from the previous time step is used as the prediction for the observation at the next time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.a.iii) Establish the Persistent Model as Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and evaluate a persistence model\n",
    "X = time_series.values\n",
    "X = X.astype('float32')\n",
    "train_pct = 0.80\n",
    "train_size = int(len(X) * train_pct)\n",
    "test_size = len(X) - train_size\n",
    "train_ts, test_ts = X[0:train_size], X[train_size:]\n",
    "\n",
    "# walk-forward validation\n",
    "history = [x for x in train_ts]\n",
    "predictions = list()\n",
    "for i in range(len(test_ts)):\n",
    "    yhat = history[-1]\n",
    "    predictions.append(yhat)\n",
    "    obs = test_ts[i]\n",
    "    history.append(obs)\n",
    "    print('>Predicted=%.3f, Expected=%3.f' % (yhat, obs))\n",
    "\n",
    "# Calculate performance\n",
    "rmse = math.sqrt(mean_squared_error(test_ts, predictions))\n",
    "print('RMSE for the persistent model is: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.b) Grid Search of ARIMA Hyperparameters\n",
    "\n",
    "We want to find a model that can do better than the persistence model on this dataset. To confirm this analysis, we can grid search a suite of ARIMA hyperparameters.\n",
    "\n",
    "In this section, we will search values of p, d, and q for combinations (skipping those that fail to converge), and find the combination that results in the best performance. We will use a grid search to explore all combinations in a subset of integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if notifyStatus: email_notify(\"ARIMA Hyperparameters Search has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the initial P, D, and Q order parameters for non-seasonal ARIMA modeling\n",
    "start_p = 0\n",
    "start_q = 0\n",
    "max_p = 4\n",
    "max_d = 2\n",
    "max_q = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the initial P, D, and Q order parameters for seasonal ARIMA modeling\n",
    "start_P = 0\n",
    "start_D = None\n",
    "start_Q = 0\n",
    "max_P = 2\n",
    "max_D = 1\n",
    "max_Q = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the time series data for suggestions on the differencing term\n",
    "start_d = pm.arima.ndiffs(train_ts)\n",
    "print('The suggested non-seasonal differencing term is:', start_d)\n",
    "if seasonal_freq != 0:\n",
    "    start_D = pm.arima.nsdiffs(train_ts, m = seasonal_freq)\n",
    "    print('The suggested seasonal differencing term is:', start_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The initial non-seasonal parameters are: p =', start_p, '| d =', start_d, '| q =', start_q)\n",
    "print('The maximum non-seasonal parameters are: max_p =', max_p, '| max_d =', max_d, '| max_q =', max_q)\n",
    "if seasonal_freq != 0:\n",
    "    print('The initial seasonal parameters are: P =', start_P, '| D =', start_D, '| Q =', start_Q, '| m =', seasonal_freq)\n",
    "    print('The maximum seasonal parameters are: max_P =', max_P, '| max_D =', max_D, '| max_Q =', max_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do an automated stepwise search of ARIMA parameters\n",
    "if seasonal_freq == 0:\n",
    "    stepwise_results = pm.auto_arima(train_ts, seasonal = False, stepwise = True, trace = True, suppress_warnings = True, random_state = seedNum)\n",
    "else:\n",
    "    stepwise_results = pm.auto_arima(train_ts, seasonal = True, m = seasonal_freq, stepwise = True, trace = True, suppress_warnings = True, random_state = seedNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize residual errors for the automated grid search ARIMA model\n",
    "print(stepwise_results.summary())\n",
    "stepwise_results.plot_diagnostics(figsize=(12,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if notifyStatus: email_notify(\"ARIMA automated stepwise search completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do an automated random search of ARIMA parameters\n",
    "n_fits = int(max_p * max_d * max_q * max_P * max_D * max_Q * 0.30)\n",
    "if seasonal_freq == 0:\n",
    "    randgrid_results = pm.auto_arima(train_ts, start_p = start_p, d = start_d, start_q = start_q, max_p = max_p, max_d = max_d, max_q = max_q,\n",
    "                                     seasonal = False, stepwise = False, random = True, n_fits = n_fits, max_order = None,\n",
    "                                     trace = True, suppress_warnings = True, random_state = seedNum)\n",
    "else:\n",
    "    randgrid_results = pm.auto_arima(train_ts, start_p = start_p, d = start_d, start_q = start_q, max_p = max_p, max_d = max_d, max_q = max_q,\n",
    "                                     seasonal = True, m = seasonal_freq, start_P = start_P, D = start_D, start_Q = start_Q, max_P = max_P, max_D = max_D, max_Q = max_Q,\n",
    "                                     stepwise = False, random = True, n_fits = n_fits, max_order = None,\n",
    "                                     trace = True, suppress_warnings = True, random_state = seedNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize residual errors for the automated grid search ARIMA model\n",
    "print(randgrid_results.summary())\n",
    "randgrid_results.plot_diagnostics(figsize=(12,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if notifyStatus: status_notify(\"ARIMA automated random search completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do an automated grid search of ARIMA parameters\n",
    "# if (seasonal_freq == 0):\n",
    "#     autogrid_results = pm.auto_arima(train_ts, start_p = start_p, d = start_d, start_q = start_q, max_p = max_p, max_d = max_d, max_q = max_q,\n",
    "#                                      seasonal = False, stepwise = False, max_order = None, trace = True, suppress_warnings = True, random_state = seedNum)\n",
    "# else:\n",
    "#     autogrid_results = pm.auto_arima(train_ts, start_p = start_p, d = start_d, start_q = start_q, max_p = max_p, max_d = max_d, max_q = max_q,\n",
    "#                                      seasonal = True, m = seasonal_freq, start_P = start_P, D = start_D, start_Q = start_Q, max_P = max_P, max_D = max_D, max_Q = max_Q,\n",
    "#                                      stepwise = False, max_order = None, trace = True, suppress_warnings = True, random_state = seedNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize residual errors for the automated grid search ARIMA model\n",
    "# print(autogrid_results.summary())\n",
    "# autogrid_results.plot_diagnostics(figsize=(12,12))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if notifyStatus: status_notify(\"ARIMA automated grid search completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not applicable for this iteration of the project\n",
    "\n",
    "# Set up the function to handle the ARIMA calculation\n",
    "# def Calculate_ARIMA(ns_order, ss_order):\n",
    "#     startTimeModel = datetime.now()\n",
    "#     aic_score, bic_score = float(\"inf\"), float(\"inf\")\n",
    "#     if (verbose): print('Trying to fit the model with parameters:', ns_order, ss_order)\n",
    "#     try:\n",
    "#         if (ss_order[3] == 0): grid_model = SARIMAX(train_ts, order=ns_order)\n",
    "#         else: grid_model = SARIMAX(train_ts, order=ns_order, seasonal_order=ss_order)\n",
    "#         with warnings.catch_warnings():\n",
    "#             warnings.simplefilter(\"ignore\")\n",
    "#             grid_results = grid_model.fit(disp = False)\n",
    "#         aic_score = grid_results.aic\n",
    "#         bic_score = grid_results.bic\n",
    "#         if (verbose): print('Fit ARIMA: order=%s seasonal_order=%s; AIC=%.3f, BIC=%.3f, Fit time=%s' % \n",
    "#               (ns_order, ss_order, aic_score, bic_score, (datetime.now() - startTimeModel)))\n",
    "#         return(aic_score, bic_score)\n",
    "#     except:\n",
    "#         return(float(\"inf\"), float(\"inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not applicable for this iteration of the project\n",
    "\n",
    "# Do a manual grid search of ARIMA parameters\n",
    "# best_score, best_ns_cfg, best_ss_cfg = float(\"inf\"), None, None\n",
    "# for p in range(start_p, max_p+1):\n",
    "#     for d in range(start_d, max_d+1):\n",
    "#         for q in range(start_q, max_q+1):\n",
    "#             for P in range(start_P, max_P+1):\n",
    "#                 for D in range(start_D, max_D+1):\n",
    "#                     for Q in range(start_Q, max_Q+1):\n",
    "#                         ns_order = (p, d, q)\n",
    "#                         ss_order = (P, D, Q, seasonal_freq)\n",
    "#                         aic_score, bic_score = Calculate_ARIMA(ns_order, ss_order)\n",
    "#                         if (aic_score < best_score):\n",
    "#                             best_ns_cfg, best_ss_cfg, best_score = ns_order, ss_order, aic_score\n",
    "#                             print('A better model found: order=%s seasonal_order=%s; AIC=%.3f, BIC=%.3f' % (ns_order, ss_order, aic_score, bic_score))\n",
    "# print('Best ARIMA model via manual search: order=%s seasonal_order=%s; AIC=%f' % (best_ns_cfg, best_ss_cfg, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize residual errors for the manual ARIMA model\n",
    "# manual_model = SARIMAX(train_ts, order=best_ns_cfg, seasonal_order=best_ss_cfg)\n",
    "# manual_results = manual_model.fit(disp = False)\n",
    "# print(manual_results.summary())\n",
    "# manual_results.plot_diagnostics(figsize=(12,12))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if notifyStatus: status_notify(\"ARIMA Hyperparameters Search completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.c) Evaluate the Residual Errors\n",
    "\n",
    "A good final check of a model is to review residual forecast errors. Ideally, the distribution of residual errors should be a Gaussian with a zero mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ARIMA order parameters for validation and forecasting\n",
    "final_ns_order = stepwise_results.order\n",
    "# final_ns_order = randgrid_results.order\n",
    "# final_ns_order = autogrid_results.order\n",
    "# final_ns_order = best_ns_cfg\n",
    "if seasonal_freq != 0:\n",
    "    final_ss_order = stepwise_results.seasonal_order\n",
    "#     final_ss_order = randgrid_results.seasonal_order\n",
    "#     final_ss_order = autogrid_results.seasonal_order\n",
    "#     final_ss_order = best_ss_cfg\n",
    "    print(\"Final Non-season order:\", final_ns_order, 'Final Seasonal Order:', final_ss_order)\n",
    "else:\n",
    "    print(\"Final Non-season order:\", final_ns_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize residual errors for the final ARIMA model\n",
    "if seasonal_freq != 0:\n",
    "    final_model = SARIMAX(time_series, order=final_ns_order, seasonal_order=final_ss_order)\n",
    "else:\n",
    "    final_model = SARIMAX(time_series, order=final_ns_order)\n",
    "final_results = final_model.fit(disp = False)\n",
    "print(final_results.summary())\n",
    "final_results.plot_diagnostics(figsize=(12,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if notifyStatus: status_notify(\"Model Fitting and Evaluation completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5. Finalize Model\n",
    "\n",
    "After models have been developed and a final model selected, it must be validated and finalized. Validation is an optional part of the process, but one that provides a ‘last check’ to ensure we have not fooled or lied to ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if notifyStatus: status_notify(\"Model Finalization has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.a) Validation via In-sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_forecast = final_results.get_prediction(start = -test_size)\n",
    "mean_validate_forecast = validate_forecast.predicted_mean\n",
    "validate_confidence_intervals = validate_forecast.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occasionally some predicted values turned out to be < 0 but they should not be (e.g. rainfall, disease cases, etc.)\n",
    "# If we have those values, we will need to set them to 0\n",
    "# print(mean_validate_forecast[mean_validate_forecast < 0])\n",
    "# mean_validate_forecast[mean_validate_forecast < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(time_series.index, time_series[target_col], label='observed')\n",
    "plt.plot(mean_validate_forecast.index, mean_validate_forecast.values, color='red', label='forecast')\n",
    "plt.fill_between(validate_confidence_intervals.index, validate_confidence_intervals[lower_bound], \n",
    "                 validate_confidence_intervals[upper_bound], color='pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate RMSE for the validation data\n",
    "y_test = time_series[-test_size:]\n",
    "predictions = mean_validate_forecast.values\n",
    "for i in range(y_test.shape[0]):\n",
    "    print(y_test.index[i], ' | ', y_test.iloc[i,0], ' | ', predictions[i])\n",
    "print('RMSE from the validation data is: %.3f' % math.sqrt(mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.b) Forecasting Out-of-Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if seasonal_freq != 0:\n",
    "    forecast_size = seasonal_freq\n",
    "else:\n",
    "    forecast_size = 1\n",
    "final_forecast = final_results.get_forecast(steps = forecast_size)\n",
    "mean_final_forecast = final_forecast.predicted_mean\n",
    "final_confidence_intervals = final_forecast.conf_int()\n",
    "print(\"The forecasted values are:\\n\\n\", mean_final_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occasionally some predicted values turned out to be < 0 but they should not be (e.g. rainfall, disease cases, etc.)\n",
    "# If we have those values, we will need to set them to 0\n",
    "# print(mean_final_forecast[mean_final_forecast < 0])\n",
    "# mean_final_forecast[mean_final_forecast < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "halfway_point = int(time_series.index.size / 2)\n",
    "plt.plot(time_series.index[halfway_point:], time_series[target_col][halfway_point:], label='observed')\n",
    "plt.plot(mean_final_forecast.index, mean_final_forecast.values, color='red', label='forecast')\n",
    "plt.fill_between(final_confidence_intervals.index, final_confidence_intervals[lower_bound], \n",
    "                 final_confidence_intervals[upper_bound], color='pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if notifyStatus: status_notify(\"Model Finalization completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Total time for the script:',(datetime.now() - startTimeScript))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
